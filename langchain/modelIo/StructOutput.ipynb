{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# LangChain 0.3 ç»“æ„åŒ–è¾“å‡ºè¯¦è§£\n",
    "> ç»“æ„åŒ–è¾“å‡ºæ˜¯ LangChain 0.3 çš„æ ¸å¿ƒåŠŸèƒ½ï¼Œè®© LLM è¿”å›ç¬¦åˆé¢„å®šä¹‰æ ¼å¼çš„æ•°æ®ç»“æ„ï¼Œè€Œä¸æ˜¯çº¯æ–‡æœ¬ã€‚è¿™å¯¹äºæ„å»ºå¯é çš„ AI åº”ç”¨è‡³å…³é‡è¦ã€‚\n",
    "\n",
    "æ ¸å¿ƒæ¦‚å¿µ\n",
    "LangChain 0.3 æä¾›äº†ä¸¤ç§ä¸»è¦çš„ç»“æ„åŒ–è¾“å‡ºæ–¹å¼ï¼š\n",
    "1. .withStructuredOutput() - æ¨èæ–¹å¼ï¼Œç®€å•æ˜“ç”¨\n",
    "2. StructuredOutputParser - ä¼ ç»Ÿæ–¹å¼ï¼Œæ›´çµæ´»"
   ],
   "id": "f5aa18bf827eaf1e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1. åŸºç¡€ç»“æ„åŒ–è¾“å‡º - withStructuredOutput()",
   "id": "f296c0482810316c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T08:26:51.335678Z",
     "start_time": "2025-07-22T08:26:40.864561Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 1. åŸºç¡€ç»“æ„åŒ–è¾“å‡ºç¤ºä¾‹\n",
    "from langchain_ollama import ChatOllama\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Optional\n",
    "\n",
    "# å®šä¹‰æ•°æ®ç»“æ„\n",
    "class Person(BaseModel):\n",
    "    \"\"\"äººç‰©ä¿¡æ¯ç»“æ„\"\"\"\n",
    "    name: str = Field(description=\"äººç‰©å§“å\")\n",
    "    age: int = Field(description=\"å¹´é¾„\")\n",
    "    occupation: str = Field(description=\"èŒä¸š\")\n",
    "    skills: List[str] = Field(description=\"æŠ€èƒ½åˆ—è¡¨\")\n",
    "    location: Optional[str] = Field(description=\"å±…ä½åœ°\", default=None)\n",
    "\n",
    "def basic_structured_output():\n",
    "    \"\"\"åŸºç¡€ç»“æ„åŒ–è¾“å‡ºç¤ºä¾‹\"\"\"\n",
    "    print(\"=\" * 50)\n",
    "    print(\"1. åŸºç¡€ç»“æ„åŒ–è¾“å‡º\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    model = ChatOllama(\n",
    "        base_url=\"http://localhost:11434\",\n",
    "        model=\"qwen2.5:3b\"\n",
    "    )\n",
    "\n",
    "    # ä½¿ç”¨ withStructuredOutput ç»‘å®šç»“æ„\n",
    "    structured_model = model.with_structured_output(Person)\n",
    "\n",
    "    # ç›´æ¥è°ƒç”¨ï¼Œè¿”å›ç»“æ„åŒ–å¯¹è±¡\n",
    "    result = structured_model.invoke(\"è¯·ä»‹ç»ä¸€ä¸‹é©¬äº‘çš„åŸºæœ¬ä¿¡æ¯\")\n",
    "\n",
    "    print(f\"ç»“æœç±»å‹: {type(result)}\")\n",
    "    print(f\"å§“å: {result.name}\")\n",
    "    print(f\"å¹´é¾„: {result.age}\")\n",
    "    print(f\"èŒä¸š: {result.occupation}\")\n",
    "    print(f\"æŠ€èƒ½: {result.skills}\")\n",
    "    print(f\"å±…ä½åœ°: {result.location}\")\n",
    "\n",
    "    return result\n",
    "\n",
    "basic_structured_output()"
   ],
   "id": "bb78b8f031be1df9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "1. åŸºç¡€ç»“æ„åŒ–è¾“å‡º\n",
      "==================================================\n",
      "ç»“æœç±»å‹: <class '__main__.Person'>\n",
      "å§“å: é©¬äº‘\n",
      "å¹´é¾„: 65\n",
      "èŒä¸š: å‰é˜¿é‡Œå·´å·´è‘£äº‹å±€ä¸»å¸­ã€æ·˜å®ç½‘åˆ›å§‹äºº\n",
      "æŠ€èƒ½: ['ä¼ä¸šå®¶', 'åˆ›ä¸šè€…', 'å…¬å…±æ¼”è®²å®¶', 'ç¤¾ä¼šæ´»åŠ¨å®¶']\n",
      "å±…ä½åœ°: ä¸­å›½æ­å·\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Person(name='é©¬äº‘', age=65, occupation='å‰é˜¿é‡Œå·´å·´è‘£äº‹å±€ä¸»å¸­ã€æ·˜å®ç½‘åˆ›å§‹äºº', skills=['ä¼ä¸šå®¶', 'åˆ›ä¸šè€…', 'å…¬å…±æ¼”è®²å®¶', 'ç¤¾ä¼šæ´»åŠ¨å®¶'], location='ä¸­å›½æ­å·')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2. å¤æ‚åµŒå¥—ç»“æ„",
   "id": "c56b132000ca05b6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T08:27:56.250849Z",
     "start_time": "2025-07-22T08:27:40.771626Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 2. å¤æ‚åµŒå¥—ç»“æ„ç¤ºä¾‹\n",
    "from datetime import datetime\n",
    "from typing import Dict, Any\n",
    "\n",
    "class Address(BaseModel):\n",
    "    \"\"\"åœ°å€ä¿¡æ¯\"\"\"\n",
    "    city: str = Field(description=\"åŸå¸‚\")\n",
    "    country: str = Field(description=\"å›½å®¶\")\n",
    "    postal_code: Optional[str] = Field(description=\"é‚®æ”¿ç¼–ç \", default=None)\n",
    "\n",
    "class Employee(BaseModel):\n",
    "    \"\"\"å‘˜å·¥ä¿¡æ¯\"\"\"\n",
    "    name: str = Field(description=\"å‘˜å·¥å§“å\")\n",
    "    position: str = Field(description=\"èŒä½\")\n",
    "    department: str = Field(description=\"éƒ¨é—¨\")\n",
    "    salary: Optional[int] = Field(description=\"è–ªèµ„\", default=None)\n",
    "\n",
    "class Revenue(BaseModel):\n",
    "    \"\"\"æ”¶å…¥ä¿¡æ¯\"\"\"\n",
    "    amount: float = Field(description=\"æ”¶å…¥é‡‘é¢\")\n",
    "    currency: str = Field(description=\"è´§å¸å•ä½\")\n",
    "    year: int = Field(description=\"å¹´ä»½\")\n",
    "\n",
    "class Company(BaseModel):\n",
    "    \"\"\"å…¬å¸ä¿¡æ¯ç»“æ„\"\"\"\n",
    "    name: str = Field(description=\"å…¬å¸åç§°\")\n",
    "    founded: int = Field(description=\"æˆç«‹å¹´ä»½\")\n",
    "    headquarters: Address = Field(description=\"æ€»éƒ¨ä¿¡æ¯\")\n",
    "    employees: List[Employee] = Field(description=\"å…³é”®å‘˜å·¥åˆ—è¡¨\")\n",
    "    revenue: Revenue = Field(description=\"æœ€æ–°æ”¶å…¥ä¿¡æ¯\")\n",
    "    products: List[str] = Field(description=\"ä¸»è¦äº§å“åˆ—è¡¨\")\n",
    "\n",
    "def nested_structured_output():\n",
    "    \"\"\"å¤æ‚åµŒå¥—ç»“æ„ç¤ºä¾‹\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"2. å¤æ‚åµŒå¥—ç»“æ„\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    model = ChatOllama(\n",
    "        base_url=\"http://localhost:11434\",\n",
    "        model=\"qwen2.5:3b\"\n",
    "    )\n",
    "\n",
    "    structured_model = model.with_structured_output(Company)\n",
    "\n",
    "    result = structured_model.invoke(\"\"\"\n",
    "    è¯·æä¾›é˜¿é‡Œå·´å·´é›†å›¢çš„è¯¦ç»†ä¿¡æ¯ï¼ŒåŒ…æ‹¬ï¼š\n",
    "    - å…¬å¸åŸºæœ¬ä¿¡æ¯å’Œæ€»éƒ¨åœ°å€\n",
    "    - 3-5ä¸ªå…³é”®å‘˜å·¥ï¼ˆåŒ…æ‹¬é©¬äº‘ã€å¼ å‹‡ç­‰ï¼‰\n",
    "    - æœ€æ–°å¹´åº¦æ”¶å…¥æ•°æ®\n",
    "    - ä¸»è¦äº§å“å’ŒæœåŠ¡\n",
    "    \"\"\")\n",
    "\n",
    "    print(f\"å…¬å¸åç§°: {result.name}\")\n",
    "    print(f\"æˆç«‹å¹´ä»½: {result.founded}\")\n",
    "    print(f\"æ€»éƒ¨: {result.headquarters.city}, {result.headquarters.country}\")\n",
    "    print(f\"å‘˜å·¥æ•°é‡: {len(result.employees)}\")\n",
    "    print(\"å…³é”®å‘˜å·¥:\")\n",
    "    for emp in result.employees:\n",
    "        print(f\"  - {emp.name}: {emp.position} ({emp.department})\")\n",
    "    print(f\"æ”¶å…¥: {result.revenue.amount} {result.revenue.currency} ({result.revenue.year})\")\n",
    "    print(f\"ä¸»è¦äº§å“: {', '.join(result.products)}\")\n",
    "\n",
    "    return result\n",
    "\n",
    "nested_structured_output()"
   ],
   "id": "53524a16541c7c80",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "2. å¤æ‚åµŒå¥—ç»“æ„\n",
      "==================================================\n",
      "å…¬å¸åç§°: é˜¿é‡Œå·´å·´é›†å›¢\n",
      "æˆç«‹å¹´ä»½: 1999\n",
      "æ€»éƒ¨: æ­å·, ä¸­å›½\n",
      "å‘˜å·¥æ•°é‡: 4\n",
      "å…³é”®å‘˜å·¥:\n",
      "  - é©¬äº‘: åˆ›å§‹äººï¼Œå‰è‘£äº‹å±€ä¸»å¸­ ()\n",
      "  - å¼ å‹‡: è‘£äº‹ä¼šæˆå‘˜,CEO (é˜¿é‡Œå·´å·´é›†å›¢)\n",
      "  - è”¡å´‡ä¿¡: è‘£äº‹æ€»ç»ç† (é˜¿é‡Œå·´å·´é›†å›¢)\n",
      "  - äº•è´¤æ ‹: å‰¯è‘£äº‹é•¿ (èš‚èšé‡‘æœ)\n",
      "æ”¶å…¥: 5304.6 Billion US Dollar (2021)\n",
      "ä¸»è¦äº§å“: å¤©çŒ«, Bç«™, ç›’é©¬, èœé¸Ÿç½‘ç»œ, é˜¿é‡Œäº‘, é«˜å¾·åœ°å›¾, ä¼˜é…·\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Company(name='é˜¿é‡Œå·´å·´é›†å›¢', founded=1999, headquarters=Address(city='æ­å·', country='ä¸­å›½', postal_code=None), employees=[Employee(name='é©¬äº‘', position='åˆ›å§‹äººï¼Œå‰è‘£äº‹å±€ä¸»å¸­', department='', salary=None), Employee(name='å¼ å‹‡', position='è‘£äº‹ä¼šæˆå‘˜,CEO', department='é˜¿é‡Œå·´å·´é›†å›¢', salary=None), Employee(name='è”¡å´‡ä¿¡', position='è‘£äº‹æ€»ç»ç†', department='é˜¿é‡Œå·´å·´é›†å›¢', salary=None), Employee(name='äº•è´¤æ ‹', position='å‰¯è‘£äº‹é•¿', department='èš‚èšé‡‘æœ', salary=None)], revenue=Revenue(amount=5304.6, currency='Billion US Dollar', year=2021), products=['å¤©çŒ«', 'Bç«™', 'ç›’é©¬', 'èœé¸Ÿç½‘ç»œ', 'é˜¿é‡Œäº‘', 'é«˜å¾·åœ°å›¾', 'ä¼˜é…·'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3. ä½¿ç”¨ StructuredOutputParser",
   "id": "d81218c78b377309"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T08:29:24.539011Z",
     "start_time": "2025-07-22T08:29:02.112619Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 3. StructuredOutputParser ç¤ºä¾‹\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "class BookReview(BaseModel):\n",
    "    \"\"\"ä¹¦ç±è¯„ä»·ç»“æ„\"\"\"\n",
    "    title: str = Field(description=\"ä¹¦ç±æ ‡é¢˜\")\n",
    "    author: str = Field(description=\"ä½œè€…\")\n",
    "    rating: int = Field(description=\"è¯„åˆ†(1-5)\", ge=1, le=5)\n",
    "    summary: str = Field(description=\"å†…å®¹æ‘˜è¦\")\n",
    "    pros: List[str] = Field(description=\"ä¼˜ç‚¹åˆ—è¡¨\")\n",
    "    cons: List[str] = Field(description=\"ç¼ºç‚¹åˆ—è¡¨\")\n",
    "    recommendation: bool = Field(description=\"æ˜¯å¦æ¨è\")\n",
    "\n",
    "def structured_output_parser():\n",
    "    \"\"\"StructuredOutputParser ç¤ºä¾‹\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"3. StructuredOutputParser\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    model = ChatOllama(\n",
    "        base_url=\"http://localhost:11434\",\n",
    "        model=\"qwen2.5:3b\"\n",
    "    )\n",
    "\n",
    "    # åˆ›å»ºè§£æå™¨\n",
    "    parser = PydanticOutputParser(pydantic_object=BookReview)\n",
    "\n",
    "    # åˆ›å»ºæç¤ºæ¨¡æ¿\n",
    "    prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "    è¯·å¯¹ä»¥ä¸‹ä¹¦ç±è¿›è¡Œè¯¦ç»†è¯„ä»·ï¼š{book}\n",
    "\n",
    "    {format_instructions}\n",
    "\n",
    "    è¯·ç¡®ä¿è¿”å›æœ‰æ•ˆçš„JSONæ ¼å¼ã€‚\n",
    "    \"\"\")\n",
    "\n",
    "    # åˆ›å»ºé“¾\n",
    "    chain = prompt | model | parser\n",
    "\n",
    "    # æ‰§è¡Œ\n",
    "    result = chain.invoke({\n",
    "        \"book\": \"ã€Šä¸‰ä½“ã€‹åˆ˜æ…ˆæ¬£\",\n",
    "        \"format_instructions\": parser.get_format_instructions()\n",
    "    })\n",
    "\n",
    "    print(f\"ä¹¦ç±: {result.title}\")\n",
    "    print(f\"ä½œè€…: {result.author}\")\n",
    "    print(f\"è¯„åˆ†: {result.rating}/5\")\n",
    "    print(f\"æ‘˜è¦: {result.summary}\")\n",
    "    print(f\"ä¼˜ç‚¹: {', '.join(result.pros)}\")\n",
    "    print(f\"ç¼ºç‚¹: {', '.join(result.cons)}\")\n",
    "    print(f\"æ¨è: {'æ˜¯' if result.recommendation else 'å¦'}\")\n",
    "\n",
    "    return result\n",
    "\n",
    "structured_output_parser()"
   ],
   "id": "53d98fe568c26c87",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "3. StructuredOutputParser\n",
      "==================================================\n",
      "ä¹¦ç±: ä¸‰ä½“\n",
      "ä½œè€…: åˆ˜æ…ˆæ¬£\n",
      "è¯„åˆ†: 5/5\n",
      "æ‘˜è¦: ã€Šä¸‰ä½“ã€‹æ˜¯åˆ˜æ…ˆæ¬£çš„ç§‘å¹»å·¨è‘—ï¼Œè®²è¿°äº†åœ°çƒæ–‡æ˜å’Œä¸‰ä½“æ–‡æ˜çš„å†²çªä¸èåˆã€‚é€šè¿‡å®å¤§çš„å™äº‹ç»“æ„å’Œæ·±å…¥çš„ç§‘å­¦æ¢è®¨ï¼Œã€Šä¸‰ä½“ã€‹ä¸ä»…æ˜¯ä¸€éƒ¨ç§‘å¹»å°è¯´ï¼Œæ›´æ˜¯ä¸€åœºå…³äºäººç±»å‘½è¿ã€å®‡å®™å¥¥ç§˜çš„å¤§è¾©è®ºã€‚\n",
      "ä¼˜ç‚¹: ç‹¬ç‰¹çš„ä¸–ç•Œè§‚æ„å»º, æ·±åˆ»çš„äººæ–‡å…³æ€€, åˆ›æ–°çš„ç§‘å­¦ç†è®º\n",
      "ç¼ºç‚¹: é•¿ç¯‡ç´¯ç‰ä¸æ˜“é˜…è¯»\n",
      "æ¨è: æ˜¯\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BookReview(title='ä¸‰ä½“', author='åˆ˜æ…ˆæ¬£', rating=5, summary='ã€Šä¸‰ä½“ã€‹æ˜¯åˆ˜æ…ˆæ¬£çš„ç§‘å¹»å·¨è‘—ï¼Œè®²è¿°äº†åœ°çƒæ–‡æ˜å’Œä¸‰ä½“æ–‡æ˜çš„å†²çªä¸èåˆã€‚é€šè¿‡å®å¤§çš„å™äº‹ç»“æ„å’Œæ·±å…¥çš„ç§‘å­¦æ¢è®¨ï¼Œã€Šä¸‰ä½“ã€‹ä¸ä»…æ˜¯ä¸€éƒ¨ç§‘å¹»å°è¯´ï¼Œæ›´æ˜¯ä¸€åœºå…³äºäººç±»å‘½è¿ã€å®‡å®™å¥¥ç§˜çš„å¤§è¾©è®ºã€‚', pros=['ç‹¬ç‰¹çš„ä¸–ç•Œè§‚æ„å»º', 'æ·±åˆ»çš„äººæ–‡å…³æ€€', 'åˆ›æ–°çš„ç§‘å­¦ç†è®º'], cons=['é•¿ç¯‡ç´¯ç‰ä¸æ˜“é˜…è¯»'], recommendation=True)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4. æ‰¹é‡ç»“æ„åŒ–è¾“å‡º",
   "id": "6d02a3541efde85f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T08:31:32.955775Z",
     "start_time": "2025-07-22T08:30:37.413970Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 4. æ‰¹é‡ç»“æ„åŒ–è¾“å‡º\n",
    "class Product(BaseModel):\n",
    "    \"\"\"äº§å“ä¿¡æ¯ç»“æ„\"\"\"\n",
    "    name: str = Field(description=\"äº§å“åç§°\")\n",
    "    category: str = Field(description=\"äº§å“ç±»åˆ«\")\n",
    "    price: float = Field(description=\"ä»·æ ¼(ç¾å…ƒ)\")\n",
    "    features: List[str] = Field(description=\"ä¸»è¦ç‰¹æ€§\")\n",
    "    target_audience: str = Field(description=\"ç›®æ ‡ç”¨æˆ·ç¾¤ä½“\")\n",
    "    pros: List[str] = Field(description=\"ä¼˜åŠ¿\")\n",
    "    cons: List[str] = Field(description=\"åŠ£åŠ¿\")\n",
    "\n",
    "def batch_structured_output():\n",
    "    \"\"\"æ‰¹é‡ç»“æ„åŒ–è¾“å‡ºç¤ºä¾‹\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"4. æ‰¹é‡ç»“æ„åŒ–è¾“å‡º\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    model = ChatOllama(\n",
    "        base_url=\"http://localhost:11434\",\n",
    "        model=\"qwen2.5:3b\"\n",
    "    )\n",
    "\n",
    "    structured_model = model.with_structured_output(Product)\n",
    "\n",
    "    products = [\n",
    "        \"iPhone 15 Pro\",\n",
    "        \"Tesla Model 3\",\n",
    "        \"ChatGPT Plusè®¢é˜…\",\n",
    "        \"Nintendo Switch\"\n",
    "    ]\n",
    "\n",
    "    # æ‰¹é‡å¤„ç†\n",
    "    prompts = [f\"è¯·è¯¦ç»†åˆ†æäº§å“: {product}ï¼ŒåŒ…æ‹¬ä»·æ ¼ã€ç‰¹æ€§ã€ç›®æ ‡ç”¨æˆ·ç­‰ä¿¡æ¯\" for product in products]\n",
    "    results = structured_model.batch(prompts)\n",
    "\n",
    "    for i, result in enumerate(results):\n",
    "        print(f\"\\n--- äº§å“ {i+1}: {products[i]} ---\")\n",
    "        print(f\"åç§°: {result.name}\")\n",
    "        print(f\"ç±»åˆ«: {result.category}\")\n",
    "        print(f\"ä»·æ ¼: ${result.price}\")\n",
    "        print(f\"ç‰¹æ€§: {', '.join(result.features[:3])}...\")  # åªæ˜¾ç¤ºå‰3ä¸ªç‰¹æ€§\n",
    "        print(f\"ç›®æ ‡ç”¨æˆ·: {result.target_audience}\")\n",
    "\n",
    "    return results\n",
    "\n",
    "batch_structured_output()"
   ],
   "id": "ce40d899eac1c230",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "4. æ‰¹é‡ç»“æ„åŒ–è¾“å‡º\n",
      "==================================================\n",
      "\n",
      "--- äº§å“ 1: iPhone 15 Pro ---\n",
      "åç§°: iPhone 15 Pro\n",
      "ç±»åˆ«: æ™ºèƒ½æ‰‹æœº\n",
      "ä»·æ ¼: $8999.0\n",
      "ç‰¹æ€§: A16èŠ¯ç‰‡, 4800ä¸‡åƒç´ ä¸»æ‘„é•œå¤´, ProMotionè‡ªé€‚åº”åˆ·æ–°ç‡æ˜¾ç¤ºæŠ€æœ¯...\n",
      "ç›®æ ‡ç”¨æˆ·: é«˜ç«¯ç”¨æˆ·,å°¤å…¶æ˜¯ä¸“ä¸šäººå£«ï¼Œå¦‚æ‘„å½±å¸ˆã€è§†é¢‘åˆ¶ä½œè€…å’Œç§‘æŠ€çˆ±å¥½è€…\n",
      "\n",
      "--- äº§å“ 2: Tesla Model 3 ---\n",
      "åç§°: Tesla Model 3\n",
      "ç±»åˆ«: Electric Vehicle\n",
      "ä»·æ ¼: $294.0\n",
      "ç‰¹æ€§: Fast charging capability, Autopilot advanced features, Long driving range on a single charge...\n",
      "ç›®æ ‡ç”¨æˆ·: Tesla Model 3 is aimed at tech enthusiasts, young professionals, and individuals looking for a high-performance electric vehicle within their budget. It also appeals to families who want a stylish, efficient, and reliable car. Additionally, Tesla is targeting business customers with its leasing options.\n",
      "\n",
      "--- äº§å“ 3: ChatGPT Plusè®¢é˜… ---\n",
      "åç§°: ChatGPT Plus\n",
      "ç±»åˆ«: äººå·¥æ™ºèƒ½æœåŠ¡\n",
      "ä»·æ ¼: $20.0\n",
      "ç‰¹æ€§: 1å°æ—¶è®¿é—®æ¬¡æ•°å¢åŠ åˆ°20æ¬¡, åŒ…å«24/7çš„å®¢æˆ·æ”¯æŒ, æ— é™åˆ¶çš„APIè°ƒç”¨æƒé™...\n",
      "ç›®æ ‡ç”¨æˆ·: é«˜çº§ç”¨æˆ·ï¼Œä¸“ä¸šå›¢é˜Ÿå’Œä¼ä¸šå®¢æˆ·\n",
      "\n",
      "--- äº§å“ 4: Nintendo Switch ---\n",
      "åç§°: Nintendo Switch\n",
      "ç±»åˆ«: ç”µå­æ¸¸æˆè®¾å¤‡\n",
      "ä»·æ ¼: $299.0\n",
      "ç‰¹æ€§: ä¾¿æºå¼è®¾è®¡ï¼šå¯ä»¥æŠ˜å åˆ°ä¸€ä¸ªå°èƒŒåŒ…ä¸­æºå¸¦ï¼Œéå¸¸é€‚åˆå»æˆ·å¤–æ¸¸ç©ã€‚, é«˜æ€§èƒ½å¤„ç†å™¨å’Œæµç•…çš„æ¸¸æˆä½“éªŒï¼šé…å¤‡æœ‰æ›´å¿«çš„Ampereæ¶æ„GPUä»¥åŠæœ€æ–°ç‰ˆæœ¬çš„Nintendo Switch OSã€‚, è·¨å¹³å°æ¸¸æˆæ”¯æŒï¼šç”¨æˆ·å¯ä»¥åœ¨Switchä¸Šç©åˆ°ä»»å¤©å ‚è‡ªå®¶å¼€å‘ã€å¾®è½¯Xboxæˆ–è°·æ­ŒStadiaå‘è¡Œçš„æ¸¸æˆï¼Œå¹¶ä¸”ä¹Ÿå…è®¸å…¶ä»–å…¬å¸ä½¿ç”¨è‡ªå·±çš„ç¡¬ä»¶æ¥è¿è¡Œè‡ªå·±çš„æ¸¸æˆã€‚...\n",
      "ç›®æ ‡ç”¨æˆ·: Nintendo Switchçš„ç›®æ ‡ç”¨æˆ·ä¸»è¦æ˜¯æ¸¸æˆçˆ±å¥½è€…ä»¥åŠæƒ³è¦åœ¨æ—…é€”ä¸­äº«å—ä¾¿æºå¼æ¸¸æˆä½“éªŒçš„äººä»¬ã€‚æ­¤å¤–ï¼Œè€ƒè™‘åˆ°æ¸¸æˆä¸»æœºå¸‚åœºçš„ç«äº‰æ¿€çƒˆç¨‹åº¦ï¼Œç‰¹åˆ«æ˜¯å¯¹äºé‚£äº›æƒ³åœ¨æ¸¸æˆä¸­ä¿æŒä¸å…¨çƒç©å®¶åŒæ­¥çš„æ¸¸æˆç©å®¶è€Œè¨€ï¼Œå®ƒä¹Ÿå¸å¼•äº†å¤§é‡çš„ç›®æ ‡å®¢æˆ·ç¾¤ã€‚\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Product(name='iPhone 15 Pro', category='æ™ºèƒ½æ‰‹æœº', price=8999.0, features=['A16èŠ¯ç‰‡', '4800ä¸‡åƒç´ ä¸»æ‘„é•œå¤´', 'ProMotionè‡ªé€‚åº”åˆ·æ–°ç‡æ˜¾ç¤ºæŠ€æœ¯', 'MagSafeç£å¸å……ç”µæ¥å£', 'IP6é˜²æ°´é˜²å°˜è®¾è®¡', 'æ–°ä¸€ä»£è¶…å¹¿è§’æ‘„åƒå¤´', 'æ™ºèƒ½HDR 5å½±åƒç³»ç»Ÿ', 'S Penæ‰‹å†™ç¬”å…¼å®¹æ€§', 'å¢å¼ºçš„Apple Vision Proé›†æˆæ”¯æŒ', 'å…ˆè¿›çš„éšç§ä¿æŠ¤åŠŸèƒ½', 'æ›´é•¿çš„ç”µæ± ç»­èˆªèƒ½åŠ›'], target_audience='é«˜ç«¯ç”¨æˆ·,å°¤å…¶æ˜¯ä¸“ä¸šäººå£«ï¼Œå¦‚æ‘„å½±å¸ˆã€è§†é¢‘åˆ¶ä½œè€…å’Œç§‘æŠ€çˆ±å¥½è€…', pros=['å¼ºå¤§çš„æ€§èƒ½å’Œé«˜æ•ˆçš„å›¾åƒå¤„ç†é€Ÿåº¦', 'å‡ºè‰²çš„æ‘„å½±èƒ½åŠ›', 'ç¨³å®šçš„è‡ªé€‚åº”åˆ·æ–°ç‡æ˜¾ç¤ºæŠ€æœ¯', 'ç‹¬ç‰¹çš„MagSafeå……ç”µè®¾è®¡', 'å…ˆè¿›çš„éšç§ä¿æŠ¤åŠŸèƒ½', 'æŒä¹…çš„ç”µæ± å¯¿å‘½'], cons=['è¾ƒé«˜ä»·æ ¼']),\n",
       " Product(name='Tesla Model 3', category='Electric Vehicle', price=294.0, features=['Fast charging capability', 'Autopilot advanced features', 'Long driving range on a single charge', 'Driverless technology (with Autopilot)', \"Seamless connectivity with Tesla's ecosystem\", \"Semi-autonomous driving capabilities through 'Full Self-Driving' Beta\"], target_audience='Tesla Model 3 is aimed at tech enthusiasts, young professionals, and individuals looking for a high-performance electric vehicle within their budget. It also appeals to families who want a stylish, efficient, and reliable car. Additionally, Tesla is targeting business customers with its leasing options.', pros=['Efficient fuel economy and low operating costs', 'Cleaner environment due to zero tailpipe emissions', 'Seamless integration into the Tesla ecosystem (charging infrastructure)', 'High levels of safety features through its Autopilot system'], cons=['Price: It is a relatively high-priced car in terms of both initial purchase and ongoing maintenance costs.', 'Limited charging stations outside major metropolitan areas, making it difficult for long-distance driving', \"Autonomous capabilities require extensive testing and regulatory approval. Tesla's Autopilot system does not have full self-driving capabilities yet.\"]),\n",
       " Product(name='ChatGPT Plus', category='äººå·¥æ™ºèƒ½æœåŠ¡', price=20.0, features=['1å°æ—¶è®¿é—®æ¬¡æ•°å¢åŠ åˆ°20æ¬¡', 'åŒ…å«24/7çš„å®¢æˆ·æ”¯æŒ', 'æ— é™åˆ¶çš„APIè°ƒç”¨æƒé™'], target_audience='é«˜çº§ç”¨æˆ·ï¼Œä¸“ä¸šå›¢é˜Ÿå’Œä¼ä¸šå®¢æˆ·', pros=['åŠŸèƒ½æ›´å¼ºå¤§', 'æ›´å¥½çš„å®¢æˆ·æœåŠ¡æ”¯æŒ', 'æ— éœ€æ‰¿æ‹…é£é™©'], cons=['éœ€è¦æ”¯ä»˜é¢å¤–è´¹ç”¨']),\n",
       " Product(name='Nintendo Switch', category='ç”µå­æ¸¸æˆè®¾å¤‡', price=299.0, features=['ä¾¿æºå¼è®¾è®¡ï¼šå¯ä»¥æŠ˜å åˆ°ä¸€ä¸ªå°èƒŒåŒ…ä¸­æºå¸¦ï¼Œéå¸¸é€‚åˆå»æˆ·å¤–æ¸¸ç©ã€‚', 'é«˜æ€§èƒ½å¤„ç†å™¨å’Œæµç•…çš„æ¸¸æˆä½“éªŒï¼šé…å¤‡æœ‰æ›´å¿«çš„Ampereæ¶æ„GPUä»¥åŠæœ€æ–°ç‰ˆæœ¬çš„Nintendo Switch OSã€‚', 'è·¨å¹³å°æ¸¸æˆæ”¯æŒï¼šç”¨æˆ·å¯ä»¥åœ¨Switchä¸Šç©åˆ°ä»»å¤©å ‚è‡ªå®¶å¼€å‘ã€å¾®è½¯Xboxæˆ–è°·æ­ŒStadiaå‘è¡Œçš„æ¸¸æˆï¼Œå¹¶ä¸”ä¹Ÿå…è®¸å…¶ä»–å…¬å¸ä½¿ç”¨è‡ªå·±çš„ç¡¬ä»¶æ¥è¿è¡Œè‡ªå·±çš„æ¸¸æˆã€‚', 'å†…ç½®æ§åˆ¶å™¨ï¼šé™„å¸¦äº†æ‰‹æŸ„ï¼Œè®©ç©å®¶å¯ä»¥è¿›è¡Œèˆ’é€‚çš„æ‰‹éƒ¨æ“ä½œã€‚', 'è§¦æ‘¸å±åŠŸèƒ½ï¼šå…·æœ‰12.3è‹±å¯¸çš„Retinaæ˜¾ç¤ºå±å’Œè§¦æ§æŠ€æœ¯ï¼Œä½¿ç”¨æˆ·å¯ä»¥åœ¨å±å¹•ä¸Šä¸‹æ–¹ç©æ¸¸æˆã€æŸ¥çœ‹ä¿¡æ¯æˆ–æµè§ˆå†…å®¹ã€‚'], target_audience='Nintendo Switchçš„ç›®æ ‡ç”¨æˆ·ä¸»è¦æ˜¯æ¸¸æˆçˆ±å¥½è€…ä»¥åŠæƒ³è¦åœ¨æ—…é€”ä¸­äº«å—ä¾¿æºå¼æ¸¸æˆä½“éªŒçš„äººä»¬ã€‚æ­¤å¤–ï¼Œè€ƒè™‘åˆ°æ¸¸æˆä¸»æœºå¸‚åœºçš„ç«äº‰æ¿€çƒˆç¨‹åº¦ï¼Œç‰¹åˆ«æ˜¯å¯¹äºé‚£äº›æƒ³åœ¨æ¸¸æˆä¸­ä¿æŒä¸å…¨çƒç©å®¶åŒæ­¥çš„æ¸¸æˆç©å®¶è€Œè¨€ï¼Œå®ƒä¹Ÿå¸å¼•äº†å¤§é‡çš„ç›®æ ‡å®¢æˆ·ç¾¤ã€‚', pros=['çµæ´»æ€§é«˜ã€åŠŸèƒ½å¤šæ ·ä¸”æ“ä½œç®€å•ã€é€‚åˆæ—…è¡Œç­‰'], cons=['ä»·æ ¼æ¯”ä¼ ç»Ÿæ¸¸æˆæœºæ›´é«˜'])]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 5. æ¡ä»¶ç»“æ„åŒ–è¾“å‡º",
   "id": "8b0ed2975b7a6bb6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T08:31:50.400964Z",
     "start_time": "2025-07-22T08:31:49.836251Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 5. æ¡ä»¶ç»“æ„åŒ–è¾“å‡º\n",
    "from typing import Union, Literal\n",
    "\n",
    "class PersonInfo(BaseModel):\n",
    "    \"\"\"äººç‰©ä¿¡æ¯\"\"\"\n",
    "    type: Literal[\"person\"] = \"person\"\n",
    "    name: str = Field(description=\"å§“å\")\n",
    "    age: int = Field(description=\"å¹´é¾„\")\n",
    "    occupation: str = Field(description=\"èŒä¸š\")\n",
    "\n",
    "class CompanyInfo(BaseModel):\n",
    "    \"\"\"å…¬å¸ä¿¡æ¯\"\"\"\n",
    "    type: Literal[\"company\"] = \"company\"\n",
    "    name: str = Field(description=\"å…¬å¸åç§°\")\n",
    "    founded: int = Field(description=\"æˆç«‹å¹´ä»½\")\n",
    "    industry: str = Field(description=\"è¡Œä¸š\")\n",
    "\n",
    "class EventInfo(BaseModel):\n",
    "    \"\"\"äº‹ä»¶ä¿¡æ¯\"\"\"\n",
    "    type: Literal[\"event\"] = \"event\"\n",
    "    name: str = Field(description=\"äº‹ä»¶åç§°\")\n",
    "    date: str = Field(description=\"æ—¥æœŸ\")\n",
    "    location: str = Field(description=\"åœ°ç‚¹\")\n",
    "\n",
    "# è”åˆç±»å‹\n",
    "EntityInfo = Union[PersonInfo, CompanyInfo, EventInfo]\n",
    "\n",
    "def conditional_structured_output():\n",
    "    \"\"\"æ¡ä»¶ç»“æ„åŒ–è¾“å‡ºç¤ºä¾‹\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"5. æ¡ä»¶ç»“æ„åŒ–è¾“å‡º\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    model = ChatOllama(\n",
    "        base_url=\"http://localhost:11434\",\n",
    "        model=\"qwen2.5:3b\"\n",
    "    )\n",
    "\n",
    "    # åˆ›å»ºè§£æå™¨å¤„ç†è”åˆç±»å‹\n",
    "    parser = PydanticOutputParser(pydantic_object=EntityInfo)\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "    è¯·åˆ†æä»¥ä¸‹å†…å®¹å¹¶æå–ç›¸å…³ä¿¡æ¯ï¼š{content}\n",
    "\n",
    "    æ ¹æ®å†…å®¹ç±»å‹è¿”å›å¯¹åº”çš„ç»“æ„ï¼š\n",
    "    - å¦‚æœæ˜¯äººç‰©ï¼Œè¿”å› person ç±»å‹\n",
    "    - å¦‚æœæ˜¯å…¬å¸ï¼Œè¿”å› company ç±»å‹\n",
    "    - å¦‚æœæ˜¯äº‹ä»¶ï¼Œè¿”å› event ç±»å‹\n",
    "\n",
    "    {format_instructions}\n",
    "    \"\"\")\n",
    "\n",
    "    chain = prompt | model | parser\n",
    "\n",
    "    test_cases = [\n",
    "        \"é©¬äº‘ï¼Œ1964å¹´å‡ºç”Ÿï¼Œé˜¿é‡Œå·´å·´åˆ›å§‹äºº\",\n",
    "        \"è‹¹æœå…¬å¸æˆç«‹äº1976å¹´ï¼Œæ˜¯ä¸€å®¶ç§‘æŠ€å…¬å¸\",\n",
    "        \"2024å¹´å·´é»å¥¥è¿ä¼šå°†åœ¨æ³•å›½å·´é»ä¸¾è¡Œ\"\n",
    "    ]\n",
    "\n",
    "    for content in test_cases:\n",
    "        print(f\"\\nè¾“å…¥: {content}\")\n",
    "        result = chain.invoke({\n",
    "            \"content\": content,\n",
    "            \"format_instructions\": parser.get_format_instructions()\n",
    "        })\n",
    "\n",
    "        print(f\"ç±»å‹: {result.type}\")\n",
    "        if result.type == \"person\":\n",
    "            print(f\"å§“å: {result.name}, å¹´é¾„: {result.age}, èŒä¸š: {result.occupation}\")\n",
    "        elif result.type == \"company\":\n",
    "            print(f\"å…¬å¸: {result.name}, æˆç«‹: {result.founded}, è¡Œä¸š: {result.industry}\")\n",
    "        elif result.type == \"event\":\n",
    "            print(f\"äº‹ä»¶: {result.name}, æ—¥æœŸ: {result.date}, åœ°ç‚¹: {result.location}\")\n",
    "\n",
    "conditional_structured_output()"
   ],
   "id": "1e7458efaf082da9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "5. æ¡ä»¶ç»“æ„åŒ–è¾“å‡º\n",
      "==================================================\n",
      "\n",
      "è¾“å…¥: é©¬äº‘ï¼Œ1964å¹´å‡ºç”Ÿï¼Œé˜¿é‡Œå·´å·´åˆ›å§‹äºº\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "model_json_schema",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mAttributeError\u001B[39m                            Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[5]\u001B[39m\u001B[32m, line 76\u001B[39m\n\u001B[32m     73\u001B[39m         \u001B[38;5;28;01melif\u001B[39;00m result.type == \u001B[33m\"\u001B[39m\u001B[33mevent\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m     74\u001B[39m             \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mäº‹ä»¶: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresult.name\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m, æ—¥æœŸ: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresult.date\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m, åœ°ç‚¹: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresult.location\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n\u001B[32m---> \u001B[39m\u001B[32m76\u001B[39m \u001B[43mconditional_structured_output\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[5]\u001B[39m\u001B[32m, line 65\u001B[39m, in \u001B[36mconditional_structured_output\u001B[39m\u001B[34m()\u001B[39m\n\u001B[32m     61\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m content \u001B[38;5;129;01min\u001B[39;00m test_cases:\n\u001B[32m     62\u001B[39m     \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33mè¾“å…¥: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mcontent\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n\u001B[32m     63\u001B[39m     result = chain.invoke({\n\u001B[32m     64\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mcontent\u001B[39m\u001B[33m\"\u001B[39m: content,\n\u001B[32m---> \u001B[39m\u001B[32m65\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mformat_instructions\u001B[39m\u001B[33m\"\u001B[39m: \u001B[43mparser\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget_format_instructions\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     66\u001B[39m     })\n\u001B[32m     68\u001B[39m     \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mç±»å‹: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresult.type\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n\u001B[32m     69\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m result.type == \u001B[33m\"\u001B[39m\u001B[33mperson\u001B[39m\u001B[33m\"\u001B[39m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/FastAPIProject/.venv/lib/python3.11/site-packages/langchain_core/output_parsers/pydantic.py:86\u001B[39m, in \u001B[36mPydanticOutputParser.get_format_instructions\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m     80\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"Return the format instructions for the JSON output.\u001B[39;00m\n\u001B[32m     81\u001B[39m \n\u001B[32m     82\u001B[39m \u001B[33;03mReturns:\u001B[39;00m\n\u001B[32m     83\u001B[39m \u001B[33;03m    The format instructions for the JSON output.\u001B[39;00m\n\u001B[32m     84\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m     85\u001B[39m \u001B[38;5;66;03m# Copy schema to avoid altering original Pydantic schema.\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m86\u001B[39m schema = \u001B[38;5;28mdict\u001B[39m(\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mpydantic_object\u001B[49m\u001B[43m.\u001B[49m\u001B[43mmodel_json_schema\u001B[49m().items())\n\u001B[32m     88\u001B[39m \u001B[38;5;66;03m# Remove extraneous fields.\u001B[39;00m\n\u001B[32m     89\u001B[39m reduced_schema = schema\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/usr/local/Cellar/python@3.11/3.11.12_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/typing.py:1317\u001B[39m, in \u001B[36m_BaseGenericAlias.__getattr__\u001B[39m\u001B[34m(self, attr)\u001B[39m\n\u001B[32m   1314\u001B[39m \u001B[38;5;66;03m# We are careful for copy and pickle.\u001B[39;00m\n\u001B[32m   1315\u001B[39m \u001B[38;5;66;03m# Also for simplicity we don't relay any dunder names\u001B[39;00m\n\u001B[32m   1316\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[33m'\u001B[39m\u001B[33m__origin__\u001B[39m\u001B[33m'\u001B[39m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m.\u001B[34m__dict__\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m _is_dunder(attr):\n\u001B[32m-> \u001B[39m\u001B[32m1317\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m.__origin__, attr)\n\u001B[32m   1318\u001B[39m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(attr)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/usr/local/Cellar/python@3.11/3.11.12_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/typing.py:474\u001B[39m, in \u001B[36m_SpecialForm.__getattr__\u001B[39m\u001B[34m(self, item)\u001B[39m\n\u001B[32m    471\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m item \u001B[38;5;129;01min\u001B[39;00m {\u001B[33m'\u001B[39m\u001B[33m__name__\u001B[39m\u001B[33m'\u001B[39m, \u001B[33m'\u001B[39m\u001B[33m__qualname__\u001B[39m\u001B[33m'\u001B[39m}:\n\u001B[32m    472\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._name\n\u001B[32m--> \u001B[39m\u001B[32m474\u001B[39m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(item)\n",
      "\u001B[31mAttributeError\u001B[39m: model_json_schema"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 6. æµå¼ç»“æ„åŒ–è¾“å‡º",
   "id": "2d98e7591ca5c23e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T08:32:36.382221Z",
     "start_time": "2025-07-22T08:32:24.763163Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 6. æµå¼ç»“æ„åŒ–è¾“å‡º\n",
    "import asyncio\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "class NewsAnalysis(BaseModel):\n",
    "    \"\"\"æ–°é—»åˆ†æç»“æ„\"\"\"\n",
    "    headline: str = Field(description=\"æ–°é—»æ ‡é¢˜\")\n",
    "    summary: str = Field(description=\"æ–°é—»æ‘˜è¦\")\n",
    "    category: str = Field(description=\"æ–°é—»ç±»åˆ«\")\n",
    "    keywords: List[str] = Field(description=\"å…³é”®è¯\")\n",
    "    sentiment: Literal[\"positive\", \"negative\", \"neutral\"] = Field(description=\"æƒ…æ„Ÿå€¾å‘\")\n",
    "    importance: int = Field(description=\"é‡è¦æ€§è¯„åˆ†(1-10)\", ge=1, le=10)\n",
    "\n",
    "async def streaming_structured_output():\n",
    "    \"\"\"æµå¼ç»“æ„åŒ–è¾“å‡ºç¤ºä¾‹\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"6. æµå¼ç»“æ„åŒ–è¾“å‡º\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    model = ChatOllama(\n",
    "        base_url=\"http://localhost:11434\",\n",
    "        model=\"qwen2.5:3b\"\n",
    "    )\n",
    "\n",
    "    structured_model = model.with_structured_output(NewsAnalysis)\n",
    "\n",
    "    news_content = \"\"\"\n",
    "    ä¸­å›½æˆåŠŸå‘å°„ç¥èˆŸåå…«å·è½½äººé£èˆ¹ï¼Œä¸‰åèˆªå¤©å‘˜é¡ºåˆ©è¿›å…¥å¤ªç©ºç«™ã€‚\n",
    "    è¿™æ ‡å¿—ç€ä¸­å›½è½½äººèˆªå¤©äº‹ä¸šåˆè¿ˆå‡ºé‡è¦ä¸€æ­¥ï¼Œå±•ç°äº†ä¸­å›½åœ¨èˆªå¤©é¢†åŸŸçš„æŠ€æœ¯å®åŠ›ã€‚\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"å¼€å§‹æµå¼ç”Ÿæˆæ–°é—»åˆ†æ...\")\n",
    "    print(\"è¾“å…¥æ–°é—»:\", news_content.strip())\n",
    "\n",
    "    try:\n",
    "        # æ³¨æ„ï¼šæŸäº›æ¨¡å‹å¯èƒ½ä¸æ”¯æŒç»“æ„åŒ–è¾“å‡ºçš„æµå¼å¤„ç†\n",
    "        # è¿™é‡Œæˆ‘ä»¬ä½¿ç”¨æ™®é€šè°ƒç”¨ä½œä¸ºç¤ºä¾‹\n",
    "        result = await structured_model.ainvoke(f\"è¯·åˆ†æè¿™æ¡æ–°é—»ï¼š{news_content}\")\n",
    "\n",
    "        print(f\"\\næ ‡é¢˜: {result.headline}\")\n",
    "        print(f\"æ‘˜è¦: {result.summary}\")\n",
    "        print(f\"ç±»åˆ«: {result.category}\")\n",
    "        print(f\"å…³é”®è¯: {', '.join(result.keywords)}\")\n",
    "        print(f\"æƒ…æ„Ÿ: {result.sentiment}\")\n",
    "        print(f\"é‡è¦æ€§: {result.importance}/10\")\n",
    "\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\"æµå¼å¤„ç†å‡ºé”™: {e}\")\n",
    "        # é™çº§åˆ°æ™®é€šè°ƒç”¨\n",
    "        result = structured_model.invoke(f\"è¯·åˆ†æè¿™æ¡æ–°é—»ï¼š{news_content}\")\n",
    "        print(\"ä½¿ç”¨æ™®é€šè°ƒç”¨å®Œæˆåˆ†æ\")\n",
    "        return result\n",
    "\n",
    "# è¿è¡Œå¼‚æ­¥å‡½æ•°\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "asyncio.run(streaming_structured_output())"
   ],
   "id": "d22a4a97646ed9e8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "6. æµå¼ç»“æ„åŒ–è¾“å‡º\n",
      "==================================================\n",
      "å¼€å§‹æµå¼ç”Ÿæˆæ–°é—»åˆ†æ...\n",
      "è¾“å…¥æ–°é—»: ä¸­å›½æˆåŠŸå‘å°„ç¥èˆŸåå…«å·è½½äººé£èˆ¹ï¼Œä¸‰åèˆªå¤©å‘˜é¡ºåˆ©è¿›å…¥å¤ªç©ºç«™ã€‚\n",
      "    è¿™æ ‡å¿—ç€ä¸­å›½è½½äººèˆªå¤©äº‹ä¸šåˆè¿ˆå‡ºé‡è¦ä¸€æ­¥ï¼Œå±•ç°äº†ä¸­å›½åœ¨èˆªå¤©é¢†åŸŸçš„æŠ€æœ¯å®åŠ›ã€‚\n",
      "\n",
      "æ ‡é¢˜: ä¸­å›½æˆåŠŸå‘å°„ç¥èˆŸåå…«å·è½½äººé£èˆ¹\n",
      "æ‘˜è¦: è¯¥æ–°é—»æŠ¥é“äº†ä¸­å›½æˆåŠŸå‘å°„äº†åä¸ºâ€˜ç¥èˆŸåå…«å·â€™çš„è½½äººé£èˆ¹ï¼Œå¹¶ä¸”ä¸‰åèˆªå¤©å‘˜å·²é¡ºåˆ©è¿›å…¥å¤ªç©ºç«™ã€‚è¿™æ ‡å¿—ç€ä¸­å›½åœ¨è½½äººèˆªå¤©é¢†åŸŸå–å¾—äº†é‡è¦è¿›å±•ï¼Œè¿›ä¸€æ­¥è¯æ˜äº†ä¸­å›½åœ¨ç›¸å…³é¢†åŸŸçš„æŠ€æœ¯å®åŠ›ã€‚\n",
      "ç±»åˆ«: ç§‘æŠ€/èˆªå¤©\n",
      "å…³é”®è¯: ç¥èˆŸåå…«å·, è½½äººé£èˆ¹, ä¸‰åèˆªå¤©å‘˜, å¤ªç©ºç«™, ä¸­å›½è½½äººèˆªå¤©äº‹ä¸š, æŠ€æœ¯æ°´å¹³\n",
      "æƒ…æ„Ÿ: positive\n",
      "é‡è¦æ€§: 1/10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NewsAnalysis(headline='ä¸­å›½æˆåŠŸå‘å°„ç¥èˆŸåå…«å·è½½äººé£èˆ¹', summary='è¯¥æ–°é—»æŠ¥é“äº†ä¸­å›½æˆåŠŸå‘å°„äº†åä¸ºâ€˜ç¥èˆŸåå…«å·â€™çš„è½½äººé£èˆ¹ï¼Œå¹¶ä¸”ä¸‰åèˆªå¤©å‘˜å·²é¡ºåˆ©è¿›å…¥å¤ªç©ºç«™ã€‚è¿™æ ‡å¿—ç€ä¸­å›½åœ¨è½½äººèˆªå¤©é¢†åŸŸå–å¾—äº†é‡è¦è¿›å±•ï¼Œè¿›ä¸€æ­¥è¯æ˜äº†ä¸­å›½åœ¨ç›¸å…³é¢†åŸŸçš„æŠ€æœ¯å®åŠ›ã€‚', category='ç§‘æŠ€/èˆªå¤©', keywords=['ç¥èˆŸåå…«å·', 'è½½äººé£èˆ¹', 'ä¸‰åèˆªå¤©å‘˜', 'å¤ªç©ºç«™', 'ä¸­å›½è½½äººèˆªå¤©äº‹ä¸š', 'æŠ€æœ¯æ°´å¹³'], sentiment='positive', importance=1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 7. é”™è¯¯å¤„ç†å’ŒéªŒè¯",
   "id": "c7c2dd6a4985c5b6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 7. é”™è¯¯å¤„ç†å’ŒéªŒè¯\n",
    "from pydantic import validator, ValidationError\n",
    "from langchain_core.output_parsers import OutputParserException\n",
    "\n",
    "class ValidatedProduct(BaseModel):\n",
    "    \"\"\"å¸¦éªŒè¯çš„äº§å“ä¿¡æ¯\"\"\"\n",
    "    name: str = Field(description=\"äº§å“åç§°\")\n",
    "    price: float = Field(description=\"ä»·æ ¼\", gt=0)  # å¿…é¡»å¤§äº0\n",
    "    category: str = Field(description=\"äº§å“ç±»åˆ«\")\n",
    "    rating: float = Field(description=\"è¯„åˆ†\", ge=0, le=5)  # 0-5ä¹‹é—´\n",
    "\n",
    "    @validator('name')\n",
    "    def name_must_not_be_empty(cls, v):\n",
    "        if not v.strip():\n",
    "            raise ValueError('äº§å“åç§°ä¸èƒ½ä¸ºç©º')\n",
    "        return v.strip()\n",
    "\n",
    "    @validator('category')\n",
    "    def category_must_be_valid(cls, v):\n",
    "        valid_categories = ['ç”µå­äº§å“', 'æœè£…', 'é£Ÿå“', 'ä¹¦ç±', 'å…¶ä»–']\n",
    "        if v not in valid_categories:\n",
    "            raise ValueError(f'ç±»åˆ«å¿…é¡»æ˜¯: {\", \".join(valid_categories)}')\n",
    "        return v\n",
    "\n",
    "def error_handling_example():\n",
    "    \"\"\"é”™è¯¯å¤„ç†ç¤ºä¾‹\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"7. é”™è¯¯å¤„ç†å’ŒéªŒè¯\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    model = ChatOllama(\n",
    "        base_url=\"http://localhost:11434\",\n",
    "        model=\"qwen2.5:3b\"\n",
    "    )\n",
    "\n",
    "    parser = PydanticOutputParser(pydantic_object=ValidatedProduct)\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "    è¯·åˆ†æä»¥ä¸‹äº§å“ä¿¡æ¯ï¼š{product}\n",
    "\n",
    "    {format_instructions}\n",
    "\n",
    "    æ³¨æ„ï¼š\n",
    "    - ä»·æ ¼å¿…é¡»å¤§äº0\n",
    "    - è¯„åˆ†å¿…é¡»åœ¨0-5ä¹‹é—´\n",
    "    - ç±»åˆ«å¿…é¡»æ˜¯ï¼šç”µå­äº§å“ã€æœè£…ã€é£Ÿå“ã€ä¹¦ç±ã€å…¶ä»– ä¹‹ä¸€\n",
    "    \"\"\")\n",
    "\n",
    "    chain = prompt | model | parser\n",
    "\n",
    "    test_products = [\n",
    "        \"iPhone 15 Pro - é«˜ç«¯æ™ºèƒ½æ‰‹æœº\",  # æ­£å¸¸æƒ…å†µ\n",
    "        \"å…è´¹è½¯ä»¶ - ä»·æ ¼ä¸º0çš„äº§å“\",      # ä»·æ ¼éªŒè¯å¤±è´¥\n",
    "        \"ç¥ç§˜äº§å“ - æœªçŸ¥ç±»åˆ«\"           # ç±»åˆ«éªŒè¯å¤±è´¥\n",
    "    ]\n",
    "\n",
    "    for product in test_products:\n",
    "        print(f\"\\næµ‹è¯•äº§å“: {product}\")\n",
    "        try:\n",
    "            result = chain.invoke({\n",
    "                \"product\": product,\n",
    "                \"format_instructions\": parser.get_format_instructions()\n",
    "            })\n",
    "            print(\"âœ… è§£ææˆåŠŸ:\")\n",
    "            print(f\"  åç§°: {result.name}\")\n",
    "            print(f\"  ä»·æ ¼: ${result.price}\")\n",
    "            print(f\"  ç±»åˆ«: {result.category}\")\n",
    "            print(f\"  è¯„åˆ†: {result.rating}/5\")\n",
    "\n",
    "        except ValidationError as e:\n",
    "            print(\"âŒ éªŒè¯å¤±è´¥:\")\n",
    "            for error in e.errors():\n",
    "                print(f\"  {error['loc'][0]}: {error['msg']}\")\n",
    "\n",
    "        except OutputParserException as e:\n",
    "            print(f\"âŒ è§£æå¤±è´¥: {e}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ å…¶ä»–é”™è¯¯: {e}\")\n",
    "\n",
    "error_handling_example()"
   ],
   "id": "78a6dffab88810e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 8. ä¸ LCEL é“¾å¼ç»„åˆ",
   "id": "a3eb3a03d20d4e3c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 8. ä¸ LCEL é“¾å¼ç»„åˆ\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "\n",
    "class TextAnalysis(BaseModel):\n",
    "    \"\"\"æ–‡æœ¬åˆ†æç»“æ„\"\"\"\n",
    "    language: str = Field(description=\"è¯­è¨€\")\n",
    "    word_count: int = Field(description=\"è¯æ•°\")\n",
    "    sentiment: Literal[\"positive\", \"negative\", \"neutral\"] = Field(description=\"æƒ…æ„Ÿ\")\n",
    "    topics: List[str] = Field(description=\"ä¸»é¢˜åˆ—è¡¨\")\n",
    "\n",
    "class Translation(BaseModel):\n",
    "    \"\"\"ç¿»è¯‘ç»“æ„\"\"\"\n",
    "    original_text: str = Field(description=\"åŸæ–‡\")\n",
    "    translated_text: str = Field(description=\"è¯‘æ–‡\")\n",
    "    source_language: str = Field(description=\"æºè¯­è¨€\")\n",
    "    target_language: str = Field(description=\"ç›®æ ‡è¯­è¨€\")\n",
    "\n",
    "def lcel_chain_example():\n",
    "    \"\"\"LCEL é“¾å¼ç»„åˆç¤ºä¾‹\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"8. LCEL é“¾å¼ç»„åˆ\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    model = ChatOllama(\n",
    "        base_url=\"http://localhost:11434\",\n",
    "        model=\"qwen2.5:3b\"\n",
    "    )\n",
    "\n",
    "    # åˆ›å»ºåˆ†æå’Œç¿»è¯‘æ¨¡å‹\n",
    "    analysis_model = model.with_structured_output(TextAnalysis)\n",
    "    translation_model = model.with_structured_output(Translation)\n",
    "\n",
    "    # åˆ›å»ºå¹¶è¡Œå¤„ç†é“¾\n",
    "    parallel_chain = RunnableParallel({\n",
    "        \"analysis\": analysis_model,\n",
    "        \"translation\": translation_model,\n",
    "        \"original\": RunnablePassthrough()\n",
    "    })\n",
    "\n",
    "    # åˆ›å»ºæç¤ºæ¨¡æ¿\n",
    "    analysis_prompt = ChatPromptTemplate.from_template(\"è¯·åˆ†æè¿™æ®µæ–‡æœ¬ï¼š{text}\")\n",
    "    translation_prompt = ChatPromptTemplate.from_template(\"è¯·å°†è¿™æ®µä¸­æ–‡ç¿»è¯‘æˆè‹±æ–‡ï¼š{text}\")\n",
    "\n",
    "    # ç»„åˆå®Œæ•´é“¾\n",
    "    full_chain = RunnableParallel({\n",
    "        \"analysis\": analysis_prompt | analysis_model,\n",
    "        \"translation\": translation_prompt | translation_model,\n",
    "        \"original\": RunnablePassthrough()\n",
    "    })\n",
    "\n",
    "    test_text = \"ä»Šå¤©å¤©æ°”çœŸå¥½ï¼Œæˆ‘å¾ˆå¼€å¿ƒèƒ½å¤Ÿå­¦ä¹ LangChainçš„ç»“æ„åŒ–è¾“å‡ºåŠŸèƒ½ã€‚è¿™ä¸ªåŠŸèƒ½éå¸¸å¼ºå¤§ï¼Œå¯ä»¥è®©AIè¿”å›æ ‡å‡†åŒ–çš„æ•°æ®ç»“æ„ã€‚\"\n",
    "\n",
    "    result = full_chain.invoke({\"text\": test_text})\n",
    "\n",
    "    print(\"åŸæ–‡:\", test_text)\n",
    "    print(\"\\n--- æ–‡æœ¬åˆ†æ ---\")\n",
    "    analysis = result[\"analysis\"]\n",
    "    print(f\"è¯­è¨€: {analysis.language}\")\n",
    "    print(f\"è¯æ•°: {analysis.word_count}\")\n",
    "    print(f\"æƒ…æ„Ÿ: {analysis.sentiment}\")\n",
    "    print(f\"ä¸»é¢˜: {', '.join(analysis.topics)}\")\n",
    "\n",
    "    print(\"\\n--- ç¿»è¯‘ç»“æœ ---\")\n",
    "    translation = result[\"translation\"]\n",
    "    print(f\"æºè¯­è¨€: {translation.source_language}\")\n",
    "    print(f\"ç›®æ ‡è¯­è¨€: {translation.target_language}\")\n",
    "    print(f\"è¯‘æ–‡: {translation.translated_text}\")\n",
    "\n",
    "lcel_chain_example()"
   ],
   "id": "cabe5f7c54d4b67a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 9. å®é™…åº”ç”¨åœºæ™¯",
   "id": "a854dfea2d3355dd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 9. å®é™…åº”ç”¨åœºæ™¯ - ç®€å†è§£æç³»ç»Ÿ\n",
    "class Education(BaseModel):\n",
    "    \"\"\"æ•™è‚²ç»å†\"\"\"\n",
    "    degree: str = Field(description=\"å­¦ä½\")\n",
    "    major: str = Field(description=\"ä¸“ä¸š\")\n",
    "    school: str = Field(description=\"å­¦æ ¡\")\n",
    "    graduation_year: int = Field(description=\"æ¯•ä¸šå¹´ä»½\")\n",
    "\n",
    "class WorkExperience(BaseModel):\n",
    "    \"\"\"å·¥ä½œç»å†\"\"\"\n",
    "    company: str = Field(description=\"å…¬å¸åç§°\")\n",
    "    position: str = Field(description=\"èŒä½\")\n",
    "    duration: str = Field(description=\"å·¥ä½œæ—¶é•¿\")\n",
    "    responsibilities: List[str] = Field(description=\"ä¸»è¦èŒè´£\")\n",
    "\n",
    "class Resume(BaseModel):\n",
    "    \"\"\"ç®€å†ç»“æ„\"\"\"\n",
    "    name: str = Field(description=\"å§“å\")\n",
    "    email: str = Field(description=\"é‚®ç®±\")\n",
    "    phone: str = Field(description=\"ç”µè¯\")\n",
    "    education: List[Education] = Field(description=\"æ•™è‚²ç»å†\")\n",
    "    work_experience: List[WorkExperience] = Field(description=\"å·¥ä½œç»å†\")\n",
    "    skills: List[str] = Field(description=\"æŠ€èƒ½åˆ—è¡¨\")\n",
    "    summary: str = Field(description=\"ä¸ªäººæ€»ç»“\")\n",
    "\n",
    "def resume_parsing_example():\n",
    "    \"\"\"ç®€å†è§£æåº”ç”¨ç¤ºä¾‹\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"9. å®é™…åº”ç”¨ - ç®€å†è§£æ\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    model = ChatOllama(\n",
    "        base_url=\"http://localhost:11434\",\n",
    "        model=\"qwen2.5:3b\"\n",
    "    )\n",
    "\n",
    "    structured_model = model.with_structured_output(Resume)\n",
    "\n",
    "    resume_text = \"\"\"\n",
    "    å¼ ä¸‰\n",
    "    é‚®ç®±: zhangsan@email.com\n",
    "    ç”µè¯: 138-0000-0000\n",
    "\n",
    "    æ•™è‚²èƒŒæ™¯ï¼š\n",
    "    2018-2022 åŒ—äº¬å¤§å­¦ è®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯ æœ¬ç§‘\n",
    "    2022-2024 æ¸…åå¤§å­¦ äººå·¥æ™ºèƒ½ ç¡•å£«\n",
    "\n",
    "    å·¥ä½œç»éªŒï¼š\n",
    "    2024.3-è‡³ä»Š é˜¿é‡Œå·´å·´ ç®—æ³•å·¥ç¨‹å¸ˆ\n",
    "    - è´Ÿè´£æ¨èç³»ç»Ÿç®—æ³•ä¼˜åŒ–\n",
    "    - å‚ä¸å¤§æ¨¡å‹è®­ç»ƒé¡¹ç›®\n",
    "    - æå‡ç”¨æˆ·ç‚¹å‡»ç‡15%\n",
    "\n",
    "    2023.6-2024.2 è…¾è®¯ å®ä¹ ç”Ÿ\n",
    "    - ååŠ©å¼€å‘èŠå¤©æœºå™¨äºº\n",
    "    - æ•°æ®æ¸…æ´—å’Œæ¨¡å‹è¯„ä¼°\n",
    "\n",
    "    æŠ€èƒ½ï¼š\n",
    "    Python, Java, TensorFlow, PyTorch, SQL, Git\n",
    "\n",
    "    ä¸ªäººæ€»ç»“ï¼š\n",
    "    çƒ­çˆ±AIæŠ€æœ¯ï¼Œæœ‰ä¸°å¯Œçš„æœºå™¨å­¦ä¹ é¡¹ç›®ç»éªŒï¼Œå–„äºå›¢é˜Ÿåˆä½œã€‚\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"è§£æç®€å†...\")\n",
    "    result = structured_model.invoke(f\"è¯·è§£æä»¥ä¸‹ç®€å†ä¿¡æ¯ï¼š\\n{resume_text}\")\n",
    "\n",
    "    print(f\"\\nå§“å: {result.name}\")\n",
    "    print(f\"é‚®ç®±: {result.email}\")\n",
    "    print(f\"ç”µè¯: {result.phone}\")\n",
    "\n",
    "    print(\"\\næ•™è‚²ç»å†:\")\n",
    "    for edu in result.education:\n",
    "        print(f\"  {edu.graduation_year} {edu.school} {edu.major} {edu.degree}\")\n",
    "\n",
    "    print(\"\\nå·¥ä½œç»å†:\")\n",
    "    for work in result.work_experience:\n",
    "        print(f\"  {work.company} - {work.position} ({work.duration})\")\n",
    "        for resp in work.responsibilities:\n",
    "            print(f\"    â€¢ {resp}\")\n",
    "\n",
    "    print(f\"\\næŠ€èƒ½: {', '.join(result.skills)}\")\n",
    "    print(f\"\\nä¸ªäººæ€»ç»“: {result.summary}\")\n",
    "\n",
    "    return result\n",
    "\n",
    "resume_parsing_example()"
   ],
   "id": "2507b42567b06612"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 10. æ€§èƒ½ä¼˜åŒ–å’Œæœ€ä½³å®è·µ",
   "id": "988f481da7dea327"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T08:36:03.705830Z",
     "start_time": "2025-07-22T08:35:46.210309Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 10. æ€§èƒ½ä¼˜åŒ–å’Œæœ€ä½³å®è·µ\n",
    "import time\n",
    "from functools import wraps\n",
    "\n",
    "def timing_decorator(func):\n",
    "    \"\"\"è®¡æ—¶è£…é¥°å™¨\"\"\"\n",
    "    @wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start = time.time()\n",
    "        result = func(*args, **kwargs)\n",
    "        end = time.time()\n",
    "        print(f\"â±ï¸ {func.__name__} è€—æ—¶: {end - start:.2f}ç§’\")\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "class OptimizedProduct(BaseModel):\n",
    "    \"\"\"ä¼˜åŒ–çš„äº§å“ç»“æ„ - ç®€åŒ–å­—æ®µ\"\"\"\n",
    "    name: str\n",
    "    price: float\n",
    "    category: str\n",
    "\n",
    "class DetailedProduct(BaseModel):\n",
    "    \"\"\"è¯¦ç»†çš„äº§å“ç»“æ„ - å¤æ‚å­—æ®µ\"\"\"\n",
    "    name: str = Field(description=\"äº§å“åç§°\")\n",
    "    price: float = Field(description=\"ä»·æ ¼\")\n",
    "    category: str = Field(description=\"ç±»åˆ«\")\n",
    "    description: str = Field(description=\"è¯¦ç»†æè¿°\")\n",
    "    features: List[str] = Field(description=\"ç‰¹æ€§åˆ—è¡¨\")\n",
    "    specifications: Dict[str, str] = Field(description=\"è§„æ ¼å‚æ•°\")\n",
    "    reviews: List[str] = Field(description=\"ç”¨æˆ·è¯„ä»·\")\n",
    "\n",
    "@timing_decorator\n",
    "def simple_structure_test():\n",
    "    \"\"\"ç®€å•ç»“æ„æ€§èƒ½æµ‹è¯•\"\"\"\n",
    "    model = ChatOllama(base_url=\"http://localhost:11434\", model=\"qwen2.5:3b\")\n",
    "    structured_model = model.with_structured_output(OptimizedProduct)\n",
    "\n",
    "    result = structured_model.invoke(\"iPhone 15 Proçš„åŸºæœ¬ä¿¡æ¯\")\n",
    "    return result\n",
    "\n",
    "@timing_decorator\n",
    "def complex_structure_test():\n",
    "    \"\"\"å¤æ‚ç»“æ„æ€§èƒ½æµ‹è¯•\"\"\"\n",
    "    model = ChatOllama(base_url=\"http://localhost:11434\", model=\"qwen2.5:3b\")\n",
    "    structured_model = model.with_structured_output(DetailedProduct)\n",
    "\n",
    "    result = structured_model.invoke(\"iPhone 15 Proçš„è¯¦ç»†ä¿¡æ¯ï¼ŒåŒ…æ‹¬ç‰¹æ€§ã€è§„æ ¼ã€ç”¨æˆ·è¯„ä»·ç­‰\")\n",
    "    return result\n",
    "\n",
    "def best_practices_demo():\n",
    "    \"\"\"æœ€ä½³å®è·µæ¼”ç¤º\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"10. æ€§èƒ½ä¼˜åŒ–å’Œæœ€ä½³å®è·µ\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    print(\"ğŸ” æ€§èƒ½å¯¹æ¯”æµ‹è¯•:\")\n",
    "\n",
    "    print(\"\\n1. ç®€å•ç»“æ„æµ‹è¯•:\")\n",
    "    simple_result = simple_structure_test()\n",
    "    print(f\"ç»“æœ: {simple_result.name} - ${simple_result.price}\")\n",
    "\n",
    "    print(\"\\n2. å¤æ‚ç»“æ„æµ‹è¯•:\")\n",
    "    complex_result = complex_structure_test()\n",
    "    print(f\"ç»“æœ: {complex_result.name} - ${complex_result.price}\")\n",
    "    print(f\"ç‰¹æ€§æ•°é‡: {len(complex_result.features)}\")\n",
    "\n",
    "    print(\"\\nğŸ“‹ æœ€ä½³å®è·µå»ºè®®:\")\n",
    "    print(\"âœ… 1. ä¼˜å…ˆä½¿ç”¨ .with_structured_output() æ–¹æ³•\")\n",
    "    print(\"âœ… 2. ä¿æŒç»“æ„ç®€å•ï¼Œé¿å…è¿‡åº¦åµŒå¥—\")\n",
    "    print(\"âœ… 3. ä½¿ç”¨æ¸…æ™°çš„å­—æ®µæè¿°\")\n",
    "    print(\"âœ… 4. åˆç†ä½¿ç”¨ Optional å­—æ®µ\")\n",
    "    print(\"âœ… 5. æ·»åŠ æ•°æ®éªŒè¯è§„åˆ™\")\n",
    "    print(\"âœ… 6. æ‰¹é‡å¤„ç†ç›¸ä¼¼ä»»åŠ¡\")\n",
    "    print(\"âœ… 7. é€‚å½“çš„é”™è¯¯å¤„ç†\")\n",
    "    print(\"âœ… 8. ç¼“å­˜å¸¸ç”¨çš„ç»“æ„åŒ–æ¨¡å‹\")\n",
    "\n",
    "best_practices_demo()"
   ],
   "id": "fa01da5c44dcbd38",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "10. æ€§èƒ½ä¼˜åŒ–å’Œæœ€ä½³å®è·µ\n",
      "==================================================\n",
      "ğŸ” æ€§èƒ½å¯¹æ¯”æµ‹è¯•:\n",
      "\n",
      "1. ç®€å•ç»“æ„æµ‹è¯•:\n",
      "â±ï¸ simple_structure_test è€—æ—¶: 4.06ç§’\n",
      "ç»“æœ: iPhone 15 Pro - $999.0\n",
      "\n",
      "2. å¤æ‚ç»“æ„æµ‹è¯•:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[7]\u001B[39m\u001B[32m, line 77\u001B[39m\n\u001B[32m     74\u001B[39m     \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mâœ… 7. é€‚å½“çš„é”™è¯¯å¤„ç†\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m     75\u001B[39m     \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mâœ… 8. ç¼“å­˜å¸¸ç”¨çš„ç»“æ„åŒ–æ¨¡å‹\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m---> \u001B[39m\u001B[32m77\u001B[39m \u001B[43mbest_practices_demo\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[7]\u001B[39m\u001B[32m, line 63\u001B[39m, in \u001B[36mbest_practices_demo\u001B[39m\u001B[34m()\u001B[39m\n\u001B[32m     60\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mç»“æœ: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00msimple_result.name\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m - $\u001B[39m\u001B[38;5;132;01m{\u001B[39;00msimple_result.price\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n\u001B[32m     62\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m2. å¤æ‚ç»“æ„æµ‹è¯•:\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m---> \u001B[39m\u001B[32m63\u001B[39m complex_result = \u001B[43mcomplex_structure_test\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     64\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mç»“æœ: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mcomplex_result.name\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m - $\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mcomplex_result.price\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n\u001B[32m     65\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mç‰¹æ€§æ•°é‡: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(complex_result.features)\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[7]\u001B[39m\u001B[32m, line 10\u001B[39m, in \u001B[36mtiming_decorator.<locals>.wrapper\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m      7\u001B[39m \u001B[38;5;129m@wraps\u001B[39m(func)\n\u001B[32m      8\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mwrapper\u001B[39m(*args, **kwargs):\n\u001B[32m      9\u001B[39m     start = time.time()\n\u001B[32m---> \u001B[39m\u001B[32m10\u001B[39m     result = \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     11\u001B[39m     end = time.time()\n\u001B[32m     12\u001B[39m     \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mâ±ï¸ \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc.\u001B[34m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m è€—æ—¶: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mend\u001B[38;5;250m \u001B[39m-\u001B[38;5;250m \u001B[39mstart\u001B[38;5;132;01m:\u001B[39;00m\u001B[33m.2f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33mç§’\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[7]\u001B[39m\u001B[32m, line 47\u001B[39m, in \u001B[36mcomplex_structure_test\u001B[39m\u001B[34m()\u001B[39m\n\u001B[32m     44\u001B[39m model = ChatOllama(base_url=\u001B[33m\"\u001B[39m\u001B[33mhttp://localhost:11434\u001B[39m\u001B[33m\"\u001B[39m, model=\u001B[33m\"\u001B[39m\u001B[33mqwen2.5:3b\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m     45\u001B[39m structured_model = model.with_structured_output(DetailedProduct)\n\u001B[32m---> \u001B[39m\u001B[32m47\u001B[39m result = \u001B[43mstructured_model\u001B[49m\u001B[43m.\u001B[49m\u001B[43minvoke\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43miPhone 15 Proçš„è¯¦ç»†ä¿¡æ¯ï¼ŒåŒ…æ‹¬ç‰¹æ€§ã€è§„æ ¼ã€ç”¨æˆ·è¯„ä»·ç­‰\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m     48\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/FastAPIProject/.venv/lib/python3.11/site-packages/langchain_core/runnables/base.py:3044\u001B[39m, in \u001B[36mRunnableSequence.invoke\u001B[39m\u001B[34m(self, input, config, **kwargs)\u001B[39m\n\u001B[32m   3042\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m set_config_context(config) \u001B[38;5;28;01mas\u001B[39;00m context:\n\u001B[32m   3043\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m i == \u001B[32m0\u001B[39m:\n\u001B[32m-> \u001B[39m\u001B[32m3044\u001B[39m         input_ = \u001B[43mcontext\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstep\u001B[49m\u001B[43m.\u001B[49m\u001B[43minvoke\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   3045\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   3046\u001B[39m         input_ = context.run(step.invoke, input_, config)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/FastAPIProject/.venv/lib/python3.11/site-packages/langchain_core/runnables/base.py:5434\u001B[39m, in \u001B[36mRunnableBindingBase.invoke\u001B[39m\u001B[34m(self, input, config, **kwargs)\u001B[39m\n\u001B[32m   5427\u001B[39m \u001B[38;5;129m@override\u001B[39m\n\u001B[32m   5428\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34minvoke\u001B[39m(\n\u001B[32m   5429\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m   5432\u001B[39m     **kwargs: Optional[Any],\n\u001B[32m   5433\u001B[39m ) -> Output:\n\u001B[32m-> \u001B[39m\u001B[32m5434\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mbound\u001B[49m\u001B[43m.\u001B[49m\u001B[43minvoke\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   5435\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m   5436\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_merge_configs\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   5437\u001B[39m \u001B[43m        \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43m{\u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   5438\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/FastAPIProject/.venv/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:378\u001B[39m, in \u001B[36mBaseChatModel.invoke\u001B[39m\u001B[34m(self, input, config, stop, **kwargs)\u001B[39m\n\u001B[32m    366\u001B[39m \u001B[38;5;129m@override\u001B[39m\n\u001B[32m    367\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34minvoke\u001B[39m(\n\u001B[32m    368\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m    373\u001B[39m     **kwargs: Any,\n\u001B[32m    374\u001B[39m ) -> BaseMessage:\n\u001B[32m    375\u001B[39m     config = ensure_config(config)\n\u001B[32m    376\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m cast(\n\u001B[32m    377\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mChatGeneration\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m--> \u001B[39m\u001B[32m378\u001B[39m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mgenerate_prompt\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    379\u001B[39m \u001B[43m            \u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_convert_input\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    380\u001B[39m \u001B[43m            \u001B[49m\u001B[43mstop\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    381\u001B[39m \u001B[43m            \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mcallbacks\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    382\u001B[39m \u001B[43m            \u001B[49m\u001B[43mtags\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mtags\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    383\u001B[39m \u001B[43m            \u001B[49m\u001B[43mmetadata\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mmetadata\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    384\u001B[39m \u001B[43m            \u001B[49m\u001B[43mrun_name\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mrun_name\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    385\u001B[39m \u001B[43m            \u001B[49m\u001B[43mrun_id\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m.\u001B[49m\u001B[43mpop\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mrun_id\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    386\u001B[39m \u001B[43m            \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    387\u001B[39m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m.generations[\u001B[32m0\u001B[39m][\u001B[32m0\u001B[39m],\n\u001B[32m    388\u001B[39m     ).message\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/FastAPIProject/.venv/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:963\u001B[39m, in \u001B[36mBaseChatModel.generate_prompt\u001B[39m\u001B[34m(self, prompts, stop, callbacks, **kwargs)\u001B[39m\n\u001B[32m    954\u001B[39m \u001B[38;5;129m@override\u001B[39m\n\u001B[32m    955\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mgenerate_prompt\u001B[39m(\n\u001B[32m    956\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m    960\u001B[39m     **kwargs: Any,\n\u001B[32m    961\u001B[39m ) -> LLMResult:\n\u001B[32m    962\u001B[39m     prompt_messages = [p.to_messages() \u001B[38;5;28;01mfor\u001B[39;00m p \u001B[38;5;129;01min\u001B[39;00m prompts]\n\u001B[32m--> \u001B[39m\u001B[32m963\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mgenerate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprompt_messages\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/FastAPIProject/.venv/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:782\u001B[39m, in \u001B[36mBaseChatModel.generate\u001B[39m\u001B[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001B[39m\n\u001B[32m    779\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m i, m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(input_messages):\n\u001B[32m    780\u001B[39m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m    781\u001B[39m         results.append(\n\u001B[32m--> \u001B[39m\u001B[32m782\u001B[39m             \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_generate_with_cache\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    783\u001B[39m \u001B[43m                \u001B[49m\u001B[43mm\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    784\u001B[39m \u001B[43m                \u001B[49m\u001B[43mstop\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    785\u001B[39m \u001B[43m                \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[43m=\u001B[49m\u001B[43mrun_managers\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mrun_managers\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    786\u001B[39m \u001B[43m                \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    787\u001B[39m \u001B[43m            \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    788\u001B[39m         )\n\u001B[32m    789\u001B[39m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m    790\u001B[39m         \u001B[38;5;28;01mif\u001B[39;00m run_managers:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/FastAPIProject/.venv/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:1028\u001B[39m, in \u001B[36mBaseChatModel._generate_with_cache\u001B[39m\u001B[34m(self, messages, stop, run_manager, **kwargs)\u001B[39m\n\u001B[32m   1026\u001B[39m     result = generate_from_stream(\u001B[38;5;28miter\u001B[39m(chunks))\n\u001B[32m   1027\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m inspect.signature(\u001B[38;5;28mself\u001B[39m._generate).parameters.get(\u001B[33m\"\u001B[39m\u001B[33mrun_manager\u001B[39m\u001B[33m\"\u001B[39m):\n\u001B[32m-> \u001B[39m\u001B[32m1028\u001B[39m     result = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_generate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1029\u001B[39m \u001B[43m        \u001B[49m\u001B[43mmessages\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[43m=\u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\n\u001B[32m   1030\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1031\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   1032\u001B[39m     result = \u001B[38;5;28mself\u001B[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/FastAPIProject/.venv/lib/python3.11/site-packages/langchain_ollama/chat_models.py:800\u001B[39m, in \u001B[36mChatOllama._generate\u001B[39m\u001B[34m(self, messages, stop, run_manager, **kwargs)\u001B[39m\n\u001B[32m    793\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_generate\u001B[39m(\n\u001B[32m    794\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m    795\u001B[39m     messages: \u001B[38;5;28mlist\u001B[39m[BaseMessage],\n\u001B[32m   (...)\u001B[39m\u001B[32m    798\u001B[39m     **kwargs: Any,\n\u001B[32m    799\u001B[39m ) -> ChatResult:\n\u001B[32m--> \u001B[39m\u001B[32m800\u001B[39m     final_chunk = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_chat_stream_with_aggregation\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    801\u001B[39m \u001B[43m        \u001B[49m\u001B[43mmessages\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\n\u001B[32m    802\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    803\u001B[39m     generation_info = final_chunk.generation_info\n\u001B[32m    804\u001B[39m     chat_generation = ChatGeneration(\n\u001B[32m    805\u001B[39m         message=AIMessage(\n\u001B[32m    806\u001B[39m             content=final_chunk.text,\n\u001B[32m   (...)\u001B[39m\u001B[32m    811\u001B[39m         generation_info=generation_info,\n\u001B[32m    812\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/FastAPIProject/.venv/lib/python3.11/site-packages/langchain_ollama/chat_models.py:735\u001B[39m, in \u001B[36mChatOllama._chat_stream_with_aggregation\u001B[39m\u001B[34m(self, messages, stop, run_manager, verbose, **kwargs)\u001B[39m\n\u001B[32m    726\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_chat_stream_with_aggregation\u001B[39m(\n\u001B[32m    727\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m    728\u001B[39m     messages: \u001B[38;5;28mlist\u001B[39m[BaseMessage],\n\u001B[32m   (...)\u001B[39m\u001B[32m    732\u001B[39m     **kwargs: Any,\n\u001B[32m    733\u001B[39m ) -> ChatGenerationChunk:\n\u001B[32m    734\u001B[39m     final_chunk = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m735\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mchunk\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_iterate_over_stream\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmessages\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m    736\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mfinal_chunk\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m:\u001B[49m\n\u001B[32m    737\u001B[39m \u001B[43m            \u001B[49m\u001B[43mfinal_chunk\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mchunk\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/FastAPIProject/.venv/lib/python3.11/site-packages/langchain_ollama/chat_models.py:822\u001B[39m, in \u001B[36mChatOllama._iterate_over_stream\u001B[39m\u001B[34m(self, messages, stop, **kwargs)\u001B[39m\n\u001B[32m    815\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_iterate_over_stream\u001B[39m(\n\u001B[32m    816\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m    817\u001B[39m     messages: \u001B[38;5;28mlist\u001B[39m[BaseMessage],\n\u001B[32m    818\u001B[39m     stop: Optional[\u001B[38;5;28mlist\u001B[39m[\u001B[38;5;28mstr\u001B[39m]] = \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[32m    819\u001B[39m     **kwargs: Any,\n\u001B[32m    820\u001B[39m ) -> Iterator[ChatGenerationChunk]:\n\u001B[32m    821\u001B[39m     reasoning = kwargs.get(\u001B[33m\"\u001B[39m\u001B[33mreasoning\u001B[39m\u001B[33m\"\u001B[39m, \u001B[38;5;28mself\u001B[39m.reasoning)\n\u001B[32m--> \u001B[39m\u001B[32m822\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mstream_resp\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_create_chat_stream\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmessages\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m    823\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43misinstance\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mstream_resp\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m    824\u001B[39m \u001B[43m            \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mstream_resp\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mdone\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m:\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/FastAPIProject/.venv/lib/python3.11/site-packages/langchain_ollama/chat_models.py:721\u001B[39m, in \u001B[36mChatOllama._create_chat_stream\u001B[39m\u001B[34m(self, messages, stop, **kwargs)\u001B[39m\n\u001B[32m    719\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m chat_params[\u001B[33m\"\u001B[39m\u001B[33mstream\u001B[39m\u001B[33m\"\u001B[39m]:\n\u001B[32m    720\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._client:\n\u001B[32m--> \u001B[39m\u001B[32m721\u001B[39m         \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28mself\u001B[39m._client.chat(**chat_params)\n\u001B[32m    722\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    723\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._client:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/FastAPIProject/.venv/lib/python3.11/site-packages/ollama/_client.py:172\u001B[39m, in \u001B[36mClient._request.<locals>.inner\u001B[39m\u001B[34m()\u001B[39m\n\u001B[32m    169\u001B[39m   e.response.read()\n\u001B[32m    170\u001B[39m   \u001B[38;5;28;01mraise\u001B[39;00m ResponseError(e.response.text, e.response.status_code) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m172\u001B[39m \u001B[43m\u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mline\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mr\u001B[49m\u001B[43m.\u001B[49m\u001B[43miter_lines\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m    173\u001B[39m \u001B[43m  \u001B[49m\u001B[43mpart\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mjson\u001B[49m\u001B[43m.\u001B[49m\u001B[43mloads\u001B[49m\u001B[43m(\u001B[49m\u001B[43mline\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    174\u001B[39m \u001B[43m  \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43merr\u001B[49m\u001B[43m \u001B[49m\u001B[43m:=\u001B[49m\u001B[43m \u001B[49m\u001B[43mpart\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43merror\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/FastAPIProject/.venv/lib/python3.11/site-packages/httpx/_models.py:929\u001B[39m, in \u001B[36mResponse.iter_lines\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    927\u001B[39m decoder = LineDecoder()\n\u001B[32m    928\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m request_context(request=\u001B[38;5;28mself\u001B[39m._request):\n\u001B[32m--> \u001B[39m\u001B[32m929\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mtext\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43miter_text\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m    930\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mline\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mdecoder\u001B[49m\u001B[43m.\u001B[49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtext\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m    931\u001B[39m \u001B[43m            \u001B[49m\u001B[38;5;28;43;01myield\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mline\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/FastAPIProject/.venv/lib/python3.11/site-packages/httpx/_models.py:916\u001B[39m, in \u001B[36mResponse.iter_text\u001B[39m\u001B[34m(self, chunk_size)\u001B[39m\n\u001B[32m    914\u001B[39m chunker = TextChunker(chunk_size=chunk_size)\n\u001B[32m    915\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m request_context(request=\u001B[38;5;28mself\u001B[39m._request):\n\u001B[32m--> \u001B[39m\u001B[32m916\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mbyte_content\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43miter_bytes\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m    917\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtext_content\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mdecoder\u001B[49m\u001B[43m.\u001B[49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbyte_content\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    918\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mchunk\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mchunker\u001B[49m\u001B[43m.\u001B[49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtext_content\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/FastAPIProject/.venv/lib/python3.11/site-packages/httpx/_models.py:897\u001B[39m, in \u001B[36mResponse.iter_bytes\u001B[39m\u001B[34m(self, chunk_size)\u001B[39m\n\u001B[32m    895\u001B[39m chunker = ByteChunker(chunk_size=chunk_size)\n\u001B[32m    896\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m request_context(request=\u001B[38;5;28mself\u001B[39m._request):\n\u001B[32m--> \u001B[39m\u001B[32m897\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mraw_bytes\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43miter_raw\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m    898\u001B[39m \u001B[43m        \u001B[49m\u001B[43mdecoded\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mdecoder\u001B[49m\u001B[43m.\u001B[49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[43mraw_bytes\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    899\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mchunk\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mchunker\u001B[49m\u001B[43m.\u001B[49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdecoded\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/FastAPIProject/.venv/lib/python3.11/site-packages/httpx/_models.py:951\u001B[39m, in \u001B[36mResponse.iter_raw\u001B[39m\u001B[34m(self, chunk_size)\u001B[39m\n\u001B[32m    948\u001B[39m chunker = ByteChunker(chunk_size=chunk_size)\n\u001B[32m    950\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m request_context(request=\u001B[38;5;28mself\u001B[39m._request):\n\u001B[32m--> \u001B[39m\u001B[32m951\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mraw_stream_bytes\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mstream\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m    952\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_num_bytes_downloaded\u001B[49m\u001B[43m \u001B[49m\u001B[43m+\u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mraw_stream_bytes\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    953\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mchunk\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mchunker\u001B[49m\u001B[43m.\u001B[49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[43mraw_stream_bytes\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/FastAPIProject/.venv/lib/python3.11/site-packages/httpx/_client.py:153\u001B[39m, in \u001B[36mBoundSyncStream.__iter__\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    152\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m__iter__\u001B[39m(\u001B[38;5;28mself\u001B[39m) -> typing.Iterator[\u001B[38;5;28mbytes\u001B[39m]:\n\u001B[32m--> \u001B[39m\u001B[32m153\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mchunk\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_stream\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m    154\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01myield\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mchunk\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/FastAPIProject/.venv/lib/python3.11/site-packages/httpx/_transports/default.py:127\u001B[39m, in \u001B[36mResponseStream.__iter__\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    125\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m__iter__\u001B[39m(\u001B[38;5;28mself\u001B[39m) -> typing.Iterator[\u001B[38;5;28mbytes\u001B[39m]:\n\u001B[32m    126\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m map_httpcore_exceptions():\n\u001B[32m--> \u001B[39m\u001B[32m127\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mpart\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_httpcore_stream\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m    128\u001B[39m \u001B[43m            \u001B[49m\u001B[38;5;28;43;01myield\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mpart\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/FastAPIProject/.venv/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py:407\u001B[39m, in \u001B[36mPoolByteStream.__iter__\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    405\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exc:\n\u001B[32m    406\u001B[39m     \u001B[38;5;28mself\u001B[39m.close()\n\u001B[32m--> \u001B[39m\u001B[32m407\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m exc \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/FastAPIProject/.venv/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py:403\u001B[39m, in \u001B[36mPoolByteStream.__iter__\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    401\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m__iter__\u001B[39m(\u001B[38;5;28mself\u001B[39m) -> typing.Iterator[\u001B[38;5;28mbytes\u001B[39m]:\n\u001B[32m    402\u001B[39m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m403\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mpart\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_stream\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m    404\u001B[39m \u001B[43m            \u001B[49m\u001B[38;5;28;43;01myield\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mpart\u001B[49m\n\u001B[32m    405\u001B[39m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exc:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/FastAPIProject/.venv/lib/python3.11/site-packages/httpcore/_sync/http11.py:342\u001B[39m, in \u001B[36mHTTP11ConnectionByteStream.__iter__\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    340\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m ShieldCancellation():\n\u001B[32m    341\u001B[39m     \u001B[38;5;28mself\u001B[39m.close()\n\u001B[32m--> \u001B[39m\u001B[32m342\u001B[39m \u001B[38;5;28;01mraise\u001B[39;00m exc\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/FastAPIProject/.venv/lib/python3.11/site-packages/httpcore/_sync/http11.py:334\u001B[39m, in \u001B[36mHTTP11ConnectionByteStream.__iter__\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    332\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m    333\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m Trace(\u001B[33m\"\u001B[39m\u001B[33mreceive_response_body\u001B[39m\u001B[33m\"\u001B[39m, logger, \u001B[38;5;28mself\u001B[39m._request, kwargs):\n\u001B[32m--> \u001B[39m\u001B[32m334\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mchunk\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_connection\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_receive_response_body\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m    335\u001B[39m \u001B[43m            \u001B[49m\u001B[38;5;28;43;01myield\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mchunk\u001B[49m\n\u001B[32m    336\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exc:\n\u001B[32m    337\u001B[39m     \u001B[38;5;66;03m# If we get an exception while streaming the response,\u001B[39;00m\n\u001B[32m    338\u001B[39m     \u001B[38;5;66;03m# we want to close the response (and possibly the connection)\u001B[39;00m\n\u001B[32m    339\u001B[39m     \u001B[38;5;66;03m# before raising that exception.\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/FastAPIProject/.venv/lib/python3.11/site-packages/httpcore/_sync/http11.py:203\u001B[39m, in \u001B[36mHTTP11Connection._receive_response_body\u001B[39m\u001B[34m(self, request)\u001B[39m\n\u001B[32m    200\u001B[39m timeout = timeouts.get(\u001B[33m\"\u001B[39m\u001B[33mread\u001B[39m\u001B[33m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[32m    202\u001B[39m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m203\u001B[39m     event = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_receive_event\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    204\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(event, h11.Data):\n\u001B[32m    205\u001B[39m         \u001B[38;5;28;01myield\u001B[39;00m \u001B[38;5;28mbytes\u001B[39m(event.data)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/FastAPIProject/.venv/lib/python3.11/site-packages/httpcore/_sync/http11.py:217\u001B[39m, in \u001B[36mHTTP11Connection._receive_event\u001B[39m\u001B[34m(self, timeout)\u001B[39m\n\u001B[32m    214\u001B[39m     event = \u001B[38;5;28mself\u001B[39m._h11_state.next_event()\n\u001B[32m    216\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m event \u001B[38;5;129;01mis\u001B[39;00m h11.NEED_DATA:\n\u001B[32m--> \u001B[39m\u001B[32m217\u001B[39m     data = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_network_stream\u001B[49m\u001B[43m.\u001B[49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    218\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mREAD_NUM_BYTES\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtimeout\u001B[49m\n\u001B[32m    219\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    221\u001B[39m     \u001B[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001B[39;00m\n\u001B[32m    222\u001B[39m     \u001B[38;5;66;03m#\u001B[39;00m\n\u001B[32m    223\u001B[39m     \u001B[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    227\u001B[39m     \u001B[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001B[39;00m\n\u001B[32m    228\u001B[39m     \u001B[38;5;66;03m# it as a ConnectError.\u001B[39;00m\n\u001B[32m    229\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m data == \u001B[33mb\u001B[39m\u001B[33m\"\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m._h11_state.their_state == h11.SEND_RESPONSE:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/FastAPIProject/.venv/lib/python3.11/site-packages/httpcore/_backends/sync.py:128\u001B[39m, in \u001B[36mSyncStream.read\u001B[39m\u001B[34m(self, max_bytes, timeout)\u001B[39m\n\u001B[32m    126\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m map_exceptions(exc_map):\n\u001B[32m    127\u001B[39m     \u001B[38;5;28mself\u001B[39m._sock.settimeout(timeout)\n\u001B[32m--> \u001B[39m\u001B[32m128\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_sock\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrecv\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmax_bytes\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# æ€»ç»“\n",
    "1. åŸºç¡€ç”¨æ³• - .with_structured_output() æ–¹æ³•\n",
    "2. å¤æ‚ç»“æ„ - åµŒå¥—å¯¹è±¡å’Œåˆ—è¡¨\n",
    "3. ä¼ ç»Ÿæ–¹æ³• - StructuredOutputParser\n",
    "4. æ‰¹é‡å¤„ç† - æé«˜æ•ˆç‡\n",
    "5. æ¡ä»¶è¾“å‡º - è”åˆç±»å‹å¤„ç†\n",
    "6. æµå¼è¾“å‡º - å®æ—¶å¤„ç†\n",
    "7. é”™è¯¯å¤„ç† - æ•°æ®éªŒè¯\n",
    "8. é“¾å¼ç»„åˆ - ä¸ LCEL ç»“åˆ\n",
    "9. å®é™…åº”ç”¨ - ç®€å†è§£æç³»ç»Ÿ\n",
    "10. æ€§èƒ½ä¼˜åŒ– - æœ€ä½³å®è·µ"
   ],
   "id": "67736b382d228451"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
