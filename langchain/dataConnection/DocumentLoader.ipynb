{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1. Document Loaders 示例",
   "id": "83f2a19cec7294c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1. 文本文件加载器",
   "id": "9dec91e179be942a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T03:18:31.722562Z",
     "start_time": "2025-07-23T03:18:31.715330Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文档数量: 1\n",
      "内容: 人工智能是计算机科学的一个分支。\n",
      "机器学习是AI的子集。\n",
      "元数据: {'source': 'sample.txt'}\n"
     ]
    }
   ],
   "execution_count": 14,
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_core.documents import Document\n",
    "import os\n",
    "\n",
    "def text_loader_examples():\n",
    "    \"\"\"文本文件加载器示例\"\"\"\n",
    "\n",
    "    # 1.1 基础文本加载\n",
    "    with open(\"sample.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"人工智能是计算机科学的一个分支。\\n机器学习是AI的子集。\")\n",
    "\n",
    "    loader = TextLoader(\"sample.txt\", encoding=\"utf-8\")\n",
    "    documents = loader.load()\n",
    "    print(f\"文档数量: {len(documents)}\")\n",
    "    print(f\"内容: {documents[0].page_content}\")\n",
    "    print(f\"元数据: {documents[0].metadata}\")\n",
    "\n",
    "    # # 1.2 处理大文件\n",
    "    # loader_large = TextLoader(\"large_file.txt\", encoding=\"utf-8\")\n",
    "    # try:\n",
    "    #     docs = loader_large.load()\n",
    "    #     print(f\"大文件加载成功，文档数: {len(docs)}\")\n",
    "    # except Exception as e:\n",
    "    #     print(f\"加载失败: {e}\")\n",
    "\n",
    "    # # 1.3 自动编码检测\n",
    "    # loader_auto = TextLoader(\"file.txt\", autodetect_encoding=True)\n",
    "    # docs = loader_auto.load()\n",
    "text_loader_examples()"
   ],
   "id": "208b154333b1e647"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2. PDF 文档加载器",
   "id": "54520ffd6591457b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T03:25:40.450347Z",
     "start_time": "2025-07-23T03:25:36.529217Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF页数: 10\n",
      "第1页内容: Multi-level Wavelet-CNN for Image Restoration\n",
      "Pengju Liu1, Hongzhi Zhang ∗1, Kai Zhang1, Liang Lin2,...\n",
      "页面元数据: {'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-23T00:19:39+00:00', 'author': '', 'keywords': '', 'moddate': '2018-05-23T00:19:39+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'docs/Multi-level Wavelet-CNN for Image Restoration.pdf', 'total_pages': 10, 'page': 0, 'page_label': '1'}\n",
      "第2页内容: is adopted to enlarge receptive ﬁeld without the sacriﬁce\n",
      "of computational cost. Dilated ﬁltering, h...\n",
      "页面元数据: {'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-05-23T00:19:39+00:00', 'author': '', 'keywords': '', 'moddate': '2018-05-23T00:19:39+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'docs/Multi-level Wavelet-CNN for Image Restoration.pdf', 'total_pages': 10, 'page': 1, 'page_label': '2'}\n"
     ]
    }
   ],
   "execution_count": 20,
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader, PDFMinerLoader, PDFPlumberLoader\n",
    "\n",
    "def pdf_loader_examples():\n",
    "    \"\"\"PDF加载器示例\"\"\"\n",
    "\n",
    "    # 2.1 PyPDFLoader - 最常用\n",
    "    pdf_loader = PyPDFLoader(\"docs/Multi-level Wavelet-CNN for Image Restoration.pdf\")\n",
    "    pages = pdf_loader.load()\n",
    "    print(f\"PDF页数: {len(pages)}\")\n",
    "\n",
    "    for i, page in enumerate(pages[:2]):\n",
    "        print(f\"第{i+1}页内容: {page.page_content[:100]}...\")\n",
    "        print(f\"页面元数据: {page.metadata}\")\n",
    "\n",
    "    # 2.2 PDFMinerLoader - 更好的文本提取\n",
    "    pdf_miner_loader = PDFMinerLoader(\"docs/Multi-level Wavelet-CNN for Image Restoration.pdf\")\n",
    "    docs = pdf_miner_loader.load()\n",
    "\n",
    "    # 2.3 PDFPlumberLoader - 表格处理更好\n",
    "    pdf_plumber_loader = PDFPlumberLoader(\"docs/Multi-level Wavelet-CNN for Image Restoration.pdf\")\n",
    "    docs = pdf_plumber_loader.load()\n",
    "\n",
    "    # 2.4 分页加载\n",
    "    pdf_loader = PyPDFLoader(\"docs/Multi-level Wavelet-CNN for Image Restoration.pdf\")\n",
    "    pages = pdf_loader.load_and_split()\n",
    "\n",
    "    # # 2.5 密码保护的PDF\n",
    "    # protected_loader = PyPDFLoader(\"docs/Multi-level Wavelet-CNN for Image Restoration.pdf\", password=\"password123\")\n",
    "    # docs = protected_loader.load()\n",
    "\n",
    "pdf_loader_examples()"
   ],
   "id": "664516871d1342fa"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 3. CSV 数据加载器",
   "id": "44d5e6a2e7dec69e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from langchain_community.document_loaders import CSVLoader\n",
    "import pandas as pd\n",
    "\n",
    "def csv_loader_examples():\n",
    "    \"\"\"CSV加载器示例\"\"\"\n",
    "\n",
    "    # 创建示例CSV\n",
    "    df = pd.DataFrame({\n",
    "        'name': ['张三', '李四', '王五'],\n",
    "        'age': [25, 30, 35],\n",
    "        'department': ['技术部', '销售部', '市场部'],\n",
    "        'description': ['Python开发工程师', '销售经理', '市场专员']\n",
    "    })\n",
    "    df.to_csv(\"employees.csv\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "    # 3.1 基础CSV加载\n",
    "    csv_loader = CSVLoader(\"employees.csv\", encoding=\"utf-8\")\n",
    "    docs = csv_loader.load()\n",
    "    print(f\"CSV文档数量: {len(docs)}\")\n",
    "    print(f\"第一条记录: {docs[0].page_content}\")\n",
    "\n",
    "    # 3.2 指定源列\n",
    "    csv_loader_with_source = CSVLoader(\n",
    "        \"employees.csv\",\n",
    "        source_column=\"name\",\n",
    "        encoding=\"utf-8\"\n",
    "    )\n",
    "    docs = csv_loader_with_source.load()\n",
    "\n",
    "    # 3.3 自定义CSV参数\n",
    "    csv_loader_custom = CSVLoader(\n",
    "        \"employees.csv\",\n",
    "        csv_args={\n",
    "            'delimiter': ',',\n",
    "            'quotechar': '\"',\n",
    "            'fieldnames': ['姓名', '年龄', '部门', '描述']\n",
    "        }\n",
    "    )\n",
    "    docs = csv_loader_custom.load()\n",
    "\n",
    "    # 3.4 过滤特定列\n",
    "    csv_loader_filtered = CSVLoader(\n",
    "        \"employees.csv\",\n",
    "        content_columns=['name', 'description'],\n",
    "        encoding=\"utf-8\"\n",
    "    )\n",
    "    docs = csv_loader_filtered.load()\n",
    "csv_loader_examples()"
   ],
   "id": "fe626b1b43fe80cb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 4. JSON 数据加载器",
   "id": "bbedfc377236d261"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from langchain_community.document_loaders import JSONLoader\n",
    "import json\n",
    "\n",
    "def json_loader_examples():\n",
    "    \"\"\"JSON加载器示例\"\"\"\n",
    "\n",
    "    # 创建示例JSON数据\n",
    "    data = [\n",
    "        {\n",
    "            \"id\": 1,\n",
    "            \"title\": \"Python编程指南\",\n",
    "            \"content\": \"Python是一种高级编程语言，语法简洁优雅。\",\n",
    "            \"author\": \"张三\",\n",
    "            \"tags\": [\"编程\", \"Python\", \"教程\"]\n",
    "        },\n",
    "        {\n",
    "            \"id\": 2,\n",
    "            \"title\": \"机器学习入门\",\n",
    "            \"content\": \"机器学习是人工智能的一个重要分支。\",\n",
    "            \"author\": \"李四\",\n",
    "            \"tags\": [\"AI\", \"机器学习\", \"数据科学\"]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    with open(\"articles.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    # 4.1 提取特定字段\n",
    "    json_loader = JSONLoader(\n",
    "        \"articles.json\",\n",
    "        jq_schema=\".[].content\",\n",
    "        text_content=False\n",
    "    )\n",
    "    docs = json_loader.load()\n",
    "    print(f\"JSON文档数量: {len(docs)}\")\n",
    "\n",
    "    # 4.2 提取多个字段\n",
    "    json_loader_multi = JSONLoader(\n",
    "        \"articles.json\",\n",
    "        jq_schema=\".[]\",\n",
    "        content_key=\"content\"\n",
    "    )\n",
    "    docs = json_loader_multi.load()\n",
    "\n",
    "    # 4.3 复杂JSON结构\n",
    "    complex_data = {\n",
    "        \"articles\": {\n",
    "            \"tech\": [\n",
    "                {\"title\": \"AI发展\", \"body\": \"人工智能快速发展\"},\n",
    "                {\"title\": \"云计算\", \"body\": \"云计算改变了IT架构\"}\n",
    "            ],\n",
    "            \"business\": [\n",
    "                {\"title\": \"数字化转型\", \"body\": \"企业数字化转型势在必行\"}\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "\n",
    "    with open(\"complex.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(complex_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    # 提取嵌套数据\n",
    "    json_loader_nested = JSONLoader(\n",
    "        \"complex.json\",\n",
    "        jq_schema=\".articles.tech[].body\"\n",
    "    )\n",
    "    docs = json_loader_nested.load()\n",
    "\n",
    "    # 4.4 JSONL格式\n",
    "    jsonl_data = [\n",
    "        {\"text\": \"第一行数据\", \"label\": \"A\"},\n",
    "        {\"text\": \"第二行数据\", \"label\": \"B\"}\n",
    "    ]\n",
    "\n",
    "    with open(\"data.jsonl\", \"w\", encoding=\"utf-8\") as f:\n",
    "        for item in jsonl_data:\n",
    "            f.write(json.dumps(item, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "    from langchain_community.document_loaders import JSONLinesLoader\n",
    "    jsonl_loader = JSONLinesLoader(\"data.jsonl\", jq_schema=\".text\")\n",
    "    docs = jsonl_loader.load()"
   ],
   "id": "109c70795f3818f2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 5. 网页内容加载器",
   "id": "6cf9d2a19d105ec2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader, AsyncHtmlLoader\n",
    "from langchain_community.document_transformers import Html2TextTransformer\n",
    "\n",
    "def web_loader_examples():\n",
    "    \"\"\"网页加载器示例\"\"\"\n",
    "\n",
    "    # 5.1 基础网页加载\n",
    "    web_loader = WebBaseLoader(\"https://example.com\")\n",
    "    docs = web_loader.load()\n",
    "    print(f\"网页文档: {docs[0].page_content[:200]}...\")\n",
    "\n",
    "    # 5.2 多个URL批量加载\n",
    "    urls = [\n",
    "        \"https://example.com/page1\",\n",
    "        \"https://example.com/page2\",\n",
    "        \"https://example.com/page3\"\n",
    "    ]\n",
    "    web_loader_multi = WebBaseLoader(urls)\n",
    "    docs = web_loader_multi.load()\n",
    "\n",
    "    # 5.3 自定义请求头\n",
    "    web_loader_headers = WebBaseLoader(\n",
    "        \"https://api.example.com/data\",\n",
    "        header_template={\n",
    "            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36\",\n",
    "            \"Authorization\": \"Bearer your-token\"\n",
    "        }\n",
    "    )\n",
    "    docs = web_loader_headers.load()\n",
    "\n",
    "    # 5.4 CSS选择器过滤\n",
    "    from bs4 import BeautifulSoup\n",
    "\n",
    "    web_loader_css = WebBaseLoader(\n",
    "        \"https://news.example.com\",\n",
    "        bs_kwargs={\n",
    "            \"parse_only\": BeautifulSoup.SoupStrainer(\"div\", {\"class\": \"article-content\"})\n",
    "        }\n",
    "    )\n",
    "    docs = web_loader_css.load()\n",
    "\n",
    "    # 5.5 异步网页加载\n",
    "    async def async_web_loading():\n",
    "        urls = [\"https://example.com/1\", \"https://example.com/2\"]\n",
    "        async_loader = AsyncHtmlLoader(urls)\n",
    "        html_docs = async_loader.load()\n",
    "\n",
    "        # HTML转文本\n",
    "        html2text = Html2TextTransformer()\n",
    "        text_docs = html2text.transform_documents(html_docs)\n",
    "        return text_docs\n",
    "\n",
    "    # 5.6 处理JavaScript渲染页面\n",
    "    from langchain_community.document_loaders import SeleniumURLLoader\n",
    "\n",
    "    selenium_loader = SeleniumURLLoader(\n",
    "        urls=[\"https://spa-example.com\"],\n",
    "        browser=\"chrome\",\n",
    "        headless=True\n",
    "    )\n",
    "    docs = selenium_loader.load()"
   ],
   "id": "59e94f75d42d0811"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 6. 目录批量加载器",
   "id": "d49b53e50f00e400"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "from langchain_community.document_loaders import TextLoader, PyPDFLoader, CSVLoader\n",
    "\n",
    "def directory_loader_examples():\n",
    "    \"\"\"目录加载器示例\"\"\"\n",
    "\n",
    "    # 创建测试目录结构\n",
    "    os.makedirs(\"documents/texts\", exist_ok=True)\n",
    "    os.makedirs(\"documents/pdfs\", exist_ok=True)\n",
    "    os.makedirs(\"documents/data\", exist_ok=True)\n",
    "\n",
    "    # 创建测试文件\n",
    "    for i in range(3):\n",
    "        with open(f\"documents/texts/doc_{i}.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(f\"这是文档{i}的内容，包含重要信息。\")\n",
    "\n",
    "    # 6.1 加载特定类型文件\n",
    "    txt_loader = DirectoryLoader(\n",
    "        \"documents/texts\",\n",
    "        glob=\"*.txt\",\n",
    "        loader_cls=TextLoader,\n",
    "        loader_kwargs={\"encoding\": \"utf-8\"}\n",
    "    )\n",
    "    txt_docs = txt_loader.load()\n",
    "    print(f\"文本文档数量: {len(txt_docs)}\")\n",
    "\n",
    "    # 6.2 多种文件类型混合加载\n",
    "    from langchain_community.document_loaders import UnstructuredFileLoader\n",
    "\n",
    "    mixed_loader = DirectoryLoader(\n",
    "        \"documents\",\n",
    "        glob=\"**/*\",  # 递归搜索\n",
    "        loader_cls=UnstructuredFileLoader,\n",
    "        recursive=True,\n",
    "        show_progress=True\n",
    "    )\n",
    "    mixed_docs = mixed_loader.load()\n",
    "\n",
    "    # 6.3 自定义文件类型映射\n",
    "    def get_loader_for_file(file_path: str):\n",
    "        if file_path.endswith('.txt'):\n",
    "            return TextLoader(file_path, encoding=\"utf-8\")\n",
    "        elif file_path.endswith('.pdf'):\n",
    "            return PyPDFLoader(file_path)\n",
    "        elif file_path.endswith('.csv'):\n",
    "            return CSVLoader(file_path, encoding=\"utf-8\")\n",
    "        else:\n",
    "            return UnstructuredFileLoader(file_path)\n",
    "\n",
    "    # 6.4 过滤和排除文件\n",
    "    filtered_loader = DirectoryLoader(\n",
    "        \"documents\",\n",
    "        glob=\"*.txt\",\n",
    "        exclude=[\"temp_*\", \"*.tmp\"],\n",
    "        loader_cls=TextLoader,\n",
    "        loader_kwargs={\"encoding\": \"utf-8\"}\n",
    "    )\n",
    "    filtered_docs = filtered_loader.load()\n",
    "\n",
    "    # 6.5 并行加载\n",
    "    parallel_loader = DirectoryLoader(\n",
    "        \"documents\",\n",
    "        glob=\"**/*\",\n",
    "        loader_cls=UnstructuredFileLoader,\n",
    "        use_multithreading=True,\n",
    "        max_concurrency=4\n",
    "    )\n",
    "    parallel_docs = parallel_loader.load()"
   ],
   "id": "8577899e5591bf76"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 7. 数据库加载器",
   "id": "5058e0a9d84a1083"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from langchain_community.document_loaders import SQLDatabaseLoader\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "def database_loader_examples():\n",
    "    \"\"\"数据库加载器示例\"\"\"\n",
    "\n",
    "    # 7.1 SQLite数据库加载\n",
    "    engine = create_engine(\"sqlite:///example.db\")\n",
    "\n",
    "    # 创建示例表和数据\n",
    "    with engine.connect() as conn:\n",
    "        conn.execute(text(\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS articles (\n",
    "                id INTEGER PRIMARY KEY,\n",
    "                title TEXT,\n",
    "                content TEXT,\n",
    "                author TEXT,\n",
    "                created_at TIMESTAMP\n",
    "            )\n",
    "        \"\"\"))\n",
    "\n",
    "        conn.execute(text(\"\"\"\n",
    "            INSERT OR REPLACE INTO articles VALUES\n",
    "            (1, 'Python教程', 'Python是一种编程语言', '张三', '2024-01-01'),\n",
    "            (2, 'AI发展', '人工智能快速发展', '李四', '2024-01-02')\n",
    "        \"\"\"))\n",
    "        conn.commit()\n",
    "\n",
    "    # 加载数据库内容\n",
    "    db_loader = SQLDatabaseLoader(\n",
    "        query=\"SELECT title, content, author FROM articles\",\n",
    "        db=engine,\n",
    "        page_content_columns=[\"title\", \"content\"],\n",
    "        metadata_columns=[\"author\"]\n",
    "    )\n",
    "    docs = db_loader.load()\n",
    "    print(f\"数据库文档数量: {len(docs)}\")\n",
    "\n",
    "    # 7.2 PostgreSQL示例\n",
    "    # pg_engine = create_engine(\"postgresql://user:password@localhost/dbname\")\n",
    "    # pg_loader = SQLDatabaseLoader(\n",
    "    #     query=\"SELECT * FROM documents WHERE category = 'tech'\",\n",
    "    #     db=pg_engine\n",
    "    # )\n",
    "    # pg_docs = pg_loader.load()\n",
    "\n",
    "    # 7.3 MongoDB加载器\n",
    "    from langchain_community.document_loaders import MongodbLoader\n",
    "\n",
    "    # mongodb_loader = MongodbLoader(\n",
    "    #     connection_string=\"mongodb://localhost:27017/\",\n",
    "    #     db_name=\"mydb\",\n",
    "    #     collection_name=\"documents\",\n",
    "    #     filter_criteria={\"status\": \"published\"}\n",
    "    # )\n",
    "    # mongo_docs = mongodb_loader.load()"
   ],
   "id": "c3c2f03c0f1169fc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 8. 云存储加载器",
   "id": "6a8319f1d2c492e0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def cloud_storage_examples():\n",
    "    \"\"\"云存储加载器示例\"\"\"\n",
    "\n",
    "    # 8.1 AWS S3加载器\n",
    "    from langchain_community.document_loaders import S3DirectoryLoader, S3FileLoader\n",
    "\n",
    "    # 单个S3文件\n",
    "    s3_file_loader = S3FileLoader(\n",
    "        bucket=\"my-bucket\",\n",
    "        key=\"documents/report.pdf\"\n",
    "    )\n",
    "    s3_docs = s3_file_loader.load()\n",
    "\n",
    "    # S3目录\n",
    "    s3_dir_loader = S3DirectoryLoader(\n",
    "        bucket=\"my-bucket\",\n",
    "        prefix=\"documents/\",\n",
    "        aws_access_key_id=\"your-access-key\",\n",
    "        aws_secret_access_key=\"your-secret-key\"\n",
    "    )\n",
    "    s3_dir_docs = s3_dir_loader.load()\n",
    "\n",
    "    # 8.2 Google Drive加载器\n",
    "    from langchain_community.document_loaders import GoogleDriveLoader\n",
    "\n",
    "    # gdrive_loader = GoogleDriveLoader(\n",
    "    #     folder_id=\"your-folder-id\",\n",
    "    #     credentials_path=\"path/to/credentials.json\",\n",
    "    #     token_path=\"path/to/token.json\"\n",
    "    # )\n",
    "    # gdrive_docs = gdrive_loader.load()\n",
    "\n",
    "    # 8.3 Azure Blob Storage\n",
    "    from langchain_community.document_loaders import AzureBlobStorageContainerLoader\n",
    "\n",
    "    # azure_loader = AzureBlobStorageContainerLoader(\n",
    "    #     conn_str=\"your-connection-string\",\n",
    "    #     container=\"documents\"\n",
    "    # )\n",
    "    # azure_docs = azure_loader.load()"
   ],
   "id": "1615b7c80aae4fa7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 9. 自定义文档加载器",
   "id": "850524eee9b0ec0f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from langchain_core.document_loaders import BaseLoader\n",
    "from langchain_core.documents import Document\n",
    "from typing import List, Iterator\n",
    "import requests\n",
    "\n",
    "class CustomAPILoader(BaseLoader):\n",
    "    \"\"\"自定义API加载器\"\"\"\n",
    "\n",
    "    def __init__(self, api_url: str, headers: dict = None):\n",
    "        self.api_url = api_url\n",
    "        self.headers = headers or {}\n",
    "\n",
    "    def load(self) -> List[Document]:\n",
    "        \"\"\"加载文档\"\"\"\n",
    "        response = requests.get(self.api_url, headers=self.headers)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        data = response.json()\n",
    "        documents = []\n",
    "\n",
    "        for item in data.get('items', []):\n",
    "            doc = Document(\n",
    "                page_content=item.get('content', ''),\n",
    "                metadata={\n",
    "                    'source': self.api_url,\n",
    "                    'id': item.get('id'),\n",
    "                    'title': item.get('title'),\n",
    "                    'timestamp': item.get('created_at')\n",
    "                }\n",
    "            )\n",
    "            documents.append(doc)\n",
    "\n",
    "        return documents\n",
    "\n",
    "    def lazy_load(self) -> Iterator[Document]:\n",
    "        \"\"\"懒加载文档\"\"\"\n",
    "        response = requests.get(self.api_url, headers=self.headers)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        data = response.json()\n",
    "        for item in data.get('items', []):\n",
    "            yield Document(\n",
    "                page_content=item.get('content', ''),\n",
    "                metadata={\n",
    "                    'source': self.api_url,\n",
    "                    'id': item.get('id'),\n",
    "                    'title': item.get('title')\n",
    "                }\n",
    "            )\n",
    "\n",
    "class DatabaseStreamLoader(BaseLoader):\n",
    "    \"\"\"流式数据库加载器\"\"\"\n",
    "\n",
    "    def __init__(self, connection_string: str, query: str, batch_size: int = 1000):\n",
    "        self.connection_string = connection_string\n",
    "        self.query = query\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def lazy_load(self) -> Iterator[Document]:\n",
    "        \"\"\"分批加载大量数据\"\"\"\n",
    "        from sqlalchemy import create_engine, text\n",
    "\n",
    "        engine = create_engine(self.connection_string)\n",
    "        offset = 0\n",
    "\n",
    "        while True:\n",
    "            paginated_query = f\"{self.query} LIMIT {self.batch_size} OFFSET {offset}\"\n",
    "\n",
    "            with engine.connect() as conn:\n",
    "                result = conn.execute(text(paginated_query))\n",
    "                rows = result.fetchall()\n",
    "\n",
    "                if not rows:\n",
    "                    break\n",
    "\n",
    "                for row in rows:\n",
    "                    yield Document(\n",
    "                        page_content=str(row[1]),  # 假设第二列是内容\n",
    "                        metadata={\n",
    "                            'id': row[0],  # 假设第一列是ID\n",
    "                            'source': 'database',\n",
    "                            'batch': offset // self.batch_size\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "                offset += self.batch_size\n",
    "\n",
    "def custom_loader_examples():\n",
    "    \"\"\"自定义加载器使用示例\"\"\"\n",
    "\n",
    "    # 使用自定义API加载器\n",
    "    api_loader = CustomAPILoader(\n",
    "        api_url=\"https://api.example.com/articles\",\n",
    "        headers={\"Authorization\": \"Bearer your-token\"}\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        api_docs = api_loader.load()\n",
    "        print(f\"API文档数量: {len(api_docs)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"API加载失败: {e}\")\n",
    "\n",
    "    # 使用流式数据库加载器\n",
    "    db_stream_loader = DatabaseStreamLoader(\n",
    "        connection_string=\"sqlite:///large_db.db\",\n",
    "        query=\"SELECT id, content FROM large_table\",\n",
    "        batch_size=500\n",
    "    )\n",
    "\n",
    "    # 懒加载处理大量数据\n",
    "    for i, doc in enumerate(db_stream_loader.lazy_load()):\n",
    "        if i >= 10:  # 只处理前10个文档作为示例\n",
    "            break\n",
    "        print(f\"文档 {i}: {doc.page_content[:50]}...\")"
   ],
   "id": "8f910eccf4132fb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 10. 完整使用示例",
   "id": "39e78bfcdabd7a36"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def complete_document_loader_example():\n",
    "    \"\"\"完整的文档加载器使用示例\"\"\"\n",
    "\n",
    "    print(\"🚀 LangChain 0.3 Document Loaders 完整示例\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    all_documents = []\n",
    "\n",
    "    # 1. 文本文件\n",
    "    print(\"\\n📄 加载文本文件...\")\n",
    "    text_docs = text_loader_examples()\n",
    "    all_documents.extend(text_docs)\n",
    "\n",
    "    # 2. CSV数据\n",
    "    print(\"\\n📊 加载CSV数据...\")\n",
    "    csv_docs = csv_loader_examples()\n",
    "    all_documents.extend(csv_docs)\n",
    "\n",
    "    # 3. JSON数据\n",
    "    print(\"\\n🔧 加载JSON数据...\")\n",
    "    json_docs = json_loader_examples()\n",
    "    all_documents.extend(json_docs)\n",
    "\n",
    "    # 4. 目录批量加载\n",
    "    print(\"\\n📁 批量加载目录...\")\n",
    "    dir_docs = directory_loader_examples()\n",
    "    all_documents.extend(dir_docs)\n",
    "\n",
    "    # 5. 数据库加载\n",
    "    print(\"\\n🗄️ 加载数据库...\")\n",
    "    db_docs = database_loader_examples()\n",
    "    all_documents.extend(db_docs)\n",
    "\n",
    "    # 6. 自定义加载器\n",
    "    print(\"\\n⚙️ 自定义加载器...\")\n",
    "    custom_docs = custom_loader_examples()\n",
    "\n",
    "    # 统计信息\n",
    "    print(f\"\\n📈 加载统计:\")\n",
    "    print(f\"总文档数量: {len(all_documents)}\")\n",
    "\n",
    "    # 按来源分组\n",
    "    sources = {}\n",
    "    for doc in all_documents:\n",
    "        source = doc.metadata.get('source', 'unknown')\n",
    "        sources[source] = sources.get(source, 0) + 1\n",
    "\n",
    "    print(\"按来源分布:\")\n",
    "    for source, count in sources.items():\n",
    "        print(f\"  {source}: {count} 个文档\")\n",
    "\n",
    "    # 内容长度统计\n",
    "    lengths = [len(doc.page_content) for doc in all_documents]\n",
    "    if lengths:\n",
    "        print(f\"内容长度统计:\")\n",
    "        print(f\"  平均长度: {sum(lengths) / len(lengths):.0f} 字符\")\n",
    "        print(f\"  最短: {min(lengths)} 字符\")\n",
    "        print(f\"  最长: {max(lengths)} 字符\")\n",
    "\n",
    "    return all_documents\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    documents = complete_document_loader_example()\n",
    "\n",
    "    # 清理临时文件\n",
    "    import shutil\n",
    "    for path in [\"sample.txt\", \"employees.csv\", \"articles.json\", \"documents\"]:\n",
    "        if os.path.exists(path):\n",
    "            if os.path.isdir(path):\n",
    "                shutil.rmtree(path)\n",
    "            else:\n",
    "                os.remove(path)\n",
    "\n",
    "    print(\"\\n🧹 临时文件已清理\")"
   ],
   "id": "93b85cf29d69650b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 总结\n",
    "1. LangChain 0.3 的 Document Loaders 提供了丰富的数据源支持：\n",
    "#### 主要特点：\n",
    "3. 统一的 Document 接口\n",
    "4. 丰富的文件格式支持\n",
    "5. 云存储集成\n",
    "6. 自定义加载器扩展\n",
    "7. 批量和流式处理\n",
    "8. 元数据保留\n",
    "\n",
    "#### 选择建议：\n",
    "10. 简单文本：使用 TextLoader\n",
    "11. PDF文档：推荐 PyPDFLoader\n",
    "12. 结构化数据：使用 CSVLoader 或 JSONLoader\n",
    "13. 网页内容：使用 WebBaseLoader\n",
    "14. 大量文件：使用 DirectoryLoader\n",
    "15. 云存储：使用对应的云存储加载器\n",
    "16. 特殊需求：实现自定义加载器"
   ],
   "id": "d6e603eca3abf24f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
