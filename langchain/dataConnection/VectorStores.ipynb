{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# FAISS向量存储",
   "id": "b16e8faf27e7cc99"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1. 基础创建和初始化",
   "id": "9237d01fd33d5a1c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T07:47:07.094649Z",
     "start_time": "2025-07-23T07:47:06.948963Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 基础FAISS向量存储创建\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# 初始化嵌入模型\n",
    "embeddings = OllamaEmbeddings(\n",
    "    base_url=\"http://localhost:11434\",\n",
    "    model=\"nomic-embed-text:latest\"\n",
    ")\n",
    "\n",
    "# 准备文档数据\n",
    "documents = [\n",
    "    Document(\n",
    "        page_content=\"人工智能是计算机科学的一个分支，致力于创建智能机器\",\n",
    "        metadata={\"source\": \"ai_intro.txt\", \"category\": \"technology\"}\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"机器学习是人工智能的子集，使计算机能够从数据中学习\",\n",
    "        metadata={\"source\": \"ml_basics.txt\", \"category\": \"technology\"}\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"深度学习使用神经网络来模拟人脑的工作方式\",\n",
    "        metadata={\"source\": \"dl_guide.txt\", \"category\": \"technology\"}\n",
    "    )\n",
    "]\n",
    "\n",
    "# 方法1：从文档创建\n",
    "faiss_vectorstore = FAISS.from_documents(documents, embeddings)\n",
    "\n",
    "# # 方法2：从文本创建\n",
    "# texts = [\"人工智能技术\", \"机器学习算法\", \"深度学习网络\"]\n",
    "# metadatas = [{\"id\": 1}, {\"id\": 2}, {\"id\": 3}]\n",
    "# faiss_vectorstore = FAISS.from_texts(texts, embeddings, metadatas)"
   ],
   "id": "848be98cf2aa3001",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2. 保存和加载索引",
   "id": "218eb4488cd1567c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T07:47:09.401291Z",
     "start_time": "2025-07-23T07:47:09.372632Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 保存FAISS索引到本地\n",
    "index_path = \"faiss_index\"\n",
    "faiss_vectorstore.save_local(index_path)\n",
    "print(f\"✅ FAISS索引已保存到 {index_path}\")\n",
    "\n",
    "# 加载已保存的索引\n",
    "loaded_vectorstore = FAISS.load_local(\n",
    "    index_path,\n",
    "    embeddings,\n",
    "    allow_dangerous_deserialization=True  # 允许反序列化\n",
    ")\n",
    "print(\"✅ FAISS索引加载成功\")\n",
    "\n",
    "# 验证加载结果\n",
    "# test_results = loaded_vectorstore.similarity_search(\"人工智能\", k=1)\n",
    "test_results = loaded_vectorstore.similarity_search(\"\") # 空则查询所有文档\n",
    "print(test_results)\n",
    "print(f\"加载验证：找到 {len(test_results)} 个文档\")"
   ],
   "id": "26e335ca0478e89e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ FAISS索引已保存到 faiss_index\n",
      "✅ FAISS索引加载成功\n",
      "[Document(id='b85e8ec4-f153-4d49-aca9-51fa3fcf0978', metadata={'source': 'ai_intro.txt', 'category': 'technology'}, page_content='人工智能是计算机科学的一个分支，致力于创建智能机器'), Document(id='cb7eebdd-e276-4e09-bf92-6e2b97e807eb', metadata={'source': 'dl_guide.txt', 'category': 'technology'}, page_content='深度学习使用神经网络来模拟人脑的工作方式'), Document(id='707f40c2-31a4-45fe-9b56-ab87ae9aecfc', metadata={'source': 'ml_basics.txt', 'category': 'technology'}, page_content='机器学习是人工智能的子集，使计算机能够从数据中学习')]\n",
      "加载验证：找到 3 个文档\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3. 相似性搜索操作",
   "id": "c358842161da0e52"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T07:48:10.418500Z",
     "start_time": "2025-07-23T07:48:10.348227Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 3.1 基础相似性搜索\n",
    "query = \"什么是人工智能技术？\"\n",
    "similar_docs = faiss_vectorstore.similarity_search(query, k=3)\n",
    "\n",
    "print(f\"查询: '{query}'\")\n",
    "for i, doc in enumerate(similar_docs):\n",
    "    print(f\"{i+1}. {doc.page_content}\")\n",
    "    print(f\"   元数据: {doc.metadata}\")\n",
    "\n",
    "# 3.2 带分数的相似性搜索\n",
    "similar_docs_with_scores = faiss_vectorstore.similarity_search_with_score(query, k=3)\n",
    "\n",
    "print(\"带分数的搜索结果:\")\n",
    "for i, (doc, score) in enumerate(similar_docs_with_scores):\n",
    "    print(f\"{i+1}. 分数: {score:.4f}\")\n",
    "    print(f\"   内容: {doc.page_content}\")\n",
    "    print(f\"   来源: {doc.metadata.get('source', 'unknown')}\")\n",
    "\n",
    "# # 3.3 基于阈值的搜索\n",
    "# threshold = 0.8\n",
    "# similar_docs_threshold = faiss_vectorstore.similarity_search_with_score_threshold(\n",
    "#     query,\n",
    "#     score_threshold=threshold\n",
    "# )\n",
    "#\n",
    "# print(f\"阈值 {threshold} 以上的文档:\")\n",
    "# for doc, score in similar_docs_threshold:\n",
    "#     print(f\"分数: {score:.4f} - {doc.page_content[:60]}...\")"
   ],
   "id": "8c7c4c4ed781eb92",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "查询: '什么是人工智能技术？'\n",
      "1. 人工智能是计算机科学的一个分支，致力于创建智能机器\n",
      "   元数据: {'source': 'ai_intro.txt', 'category': 'technology'}\n",
      "2. 机器学习是人工智能的子集，使计算机能够从数据中学习\n",
      "   元数据: {'source': 'ml_basics.txt', 'category': 'technology'}\n",
      "3. 深度学习使用神经网络来模拟人脑的工作方式\n",
      "   元数据: {'source': 'dl_guide.txt', 'category': 'technology'}\n",
      "带分数的搜索结果:\n",
      "1. 分数: 0.3241\n",
      "   内容: 人工智能是计算机科学的一个分支，致力于创建智能机器\n",
      "   来源: ai_intro.txt\n",
      "2. 分数: 0.3984\n",
      "   内容: 机器学习是人工智能的子集，使计算机能够从数据中学习\n",
      "   来源: ml_basics.txt\n",
      "3. 分数: 0.6661\n",
      "   内容: 深度学习使用神经网络来模拟人脑的工作方式\n",
      "   来源: dl_guide.txt\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4. 文档管理操作",
   "id": "80f50d55d010c6bb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T07:45:21.442789Z",
     "start_time": "2025-07-23T07:45:21.324611Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 4.1 添加新文档\n",
    "new_documents = [\n",
    "    Document(\n",
    "        page_content=\"量子计算是一种利用量子力学原理的计算方式\",\n",
    "        metadata={\"source\": \"quantum.txt\", \"category\": \"technology\"}\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"区块链技术提供了去中心化的数据存储方案\",\n",
    "        metadata={\"source\": \"blockchain.txt\", \"category\": \"technology\"}\n",
    "    )\n",
    "]\n",
    "\n",
    "# 添加文档并获取ID\n",
    "doc_ids = faiss_vectorstore.add_documents(new_documents)\n",
    "print(f\"✅ 已添加 {len(new_documents)} 个新文档，ID: {doc_ids}\")\n",
    "\n",
    "# 4.2 添加文本\n",
    "new_texts = [\"自然语言处理技术\", \"计算机视觉应用\"]\n",
    "new_metadatas = [{\"type\": \"nlp\"}, {\"type\": \"cv\"}]\n",
    "text_ids = faiss_vectorstore.add_texts(new_texts, new_metadatas)\n",
    "print(f\"✅ 已添加 {len(new_texts)} 个新文本，ID: {text_ids}\")\n",
    "\n",
    "# 4.3 删除文档（如果支持）\n",
    "try:\n",
    "    faiss_vectorstore.delete([doc_ids[0]])\n",
    "    print(\"✅ 文档删除成功\")\n",
    "except Exception as e:\n",
    "    print(f\"删除操作不支持: {e}\")"
   ],
   "id": "96c76cb68d908892",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 已添加 2 个新文档，ID: ['27806a87-e8f3-4c60-8be3-1a68759e517d', 'd05964ce-d18e-497e-86cc-0aadb3f625df']\n",
      "✅ 已添加 2 个新文本，ID: ['9d839ddf-6af9-4fe2-99ad-f35168b45eee', '8d1a8c2f-dd53-43bb-b2cd-bc515a2e6e78']\n",
      "✅ 文档删除成功\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 5. 高级索引类型",
   "id": "26a331a02ddbe92"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T07:48:23.471755Z",
     "start_time": "2025-07-23T07:48:23.267929Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 5.1 IVF索引（适合大规模数据）\n",
    "try:\n",
    "    faiss_ivf = FAISS.from_documents(\n",
    "        documents,\n",
    "        embeddings,\n",
    "        index_type=\"IVF\",\n",
    "        nlist=10  # 聚类中心数量\n",
    "    )\n",
    "\n",
    "    ivf_results = faiss_ivf.similarity_search(\"机器学习算法\", k=2)\n",
    "    print(\"IVF索引搜索结果:\")\n",
    "    for doc in ivf_results:\n",
    "        print(f\"- {doc.page_content}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"IVF索引创建失败: {e}\")\n",
    "\n",
    "# 5.2 HNSW索引（高精度搜索）\n",
    "try:\n",
    "    faiss_hnsw = FAISS.from_documents(\n",
    "        documents,\n",
    "        embeddings,\n",
    "        index_type=\"HNSW\",\n",
    "        M=16,  # 连接数\n",
    "        efConstruction=200  # 构建时的搜索参数\n",
    "    )\n",
    "\n",
    "    hnsw_results = faiss_hnsw.similarity_search(\"深度学习\", k=2)\n",
    "    print(\"HNSW索引搜索结果:\")\n",
    "    for doc in hnsw_results:\n",
    "        print(f\"- {doc.page_content}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"HNSW索引创建失败: {e}\")"
   ],
   "id": "cc00e4a67ddd83d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IVF索引创建失败: FAISS.__init__() got an unexpected keyword argument 'index_type'\n",
      "HNSW索引创建失败: FAISS.__init__() got an unexpected keyword argument 'index_type'\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 6. 向量存储合并",
   "id": "29204bcebbecfc5d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T07:48:45.340750Z",
     "start_time": "2025-07-23T07:48:45.203672Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 6.1 创建两个独立的向量存储\n",
    "docs1 = [\n",
    "    Document(page_content=\"第一个存储的文档1\", metadata={\"store\": \"store1\"}),\n",
    "    Document(page_content=\"第一个存储的文档2\", metadata={\"store\": \"store1\"})\n",
    "]\n",
    "\n",
    "docs2 = [\n",
    "    Document(page_content=\"第二个存储的文档1\", metadata={\"store\": \"store2\"}),\n",
    "    Document(page_content=\"第二个存储的文档2\", metadata={\"store\": \"store2\"})\n",
    "]\n",
    "\n",
    "store1 = FAISS.from_documents(docs1, embeddings)\n",
    "store2 = FAISS.from_documents(docs2, embeddings)\n",
    "\n",
    "# 6.2 合并向量存储\n",
    "store1.merge_from(store2)\n",
    "print(\"✅ 向量存储合并完成\")\n",
    "\n",
    "# 6.3 验证合并结果\n",
    "all_results = store1.similarity_search(\"文档\", k=4)\n",
    "print(f\"合并后总文档数: {len(all_results)}\")\n",
    "for doc in all_results:\n",
    "    print(f\"- {doc.page_content} (来源: {doc.metadata['store']})\")"
   ],
   "id": "888f00dd097a590c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 向量存储合并完成\n",
      "合并后总文档数: 4\n",
      "- 第一个存储的文档2 (来源: store1)\n",
      "- 第一个存储的文档1 (来源: store1)\n",
      "- 第二个存储的文档1 (来源: store2)\n",
      "- 第二个存储的文档2 (来源: store2)\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 7. 批量操作和性能优化",
   "id": "b6f38b0bf9ac5e41"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T07:48:58.914367Z",
     "start_time": "2025-07-23T07:48:57.527912Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 7.1 批量添加文档\n",
    "batch_docs = [\n",
    "    Document(\n",
    "        page_content=f\"批量文档{i}：这是第{i}个批量添加的文档\",\n",
    "        metadata={\"batch\": True, \"id\": i, \"category\": f\"batch_{i%3}\"}\n",
    "    )\n",
    "    for i in range(50)  # 创建50个文档\n",
    "]\n",
    "\n",
    "# 批量添加\n",
    "start_time = time.time()\n",
    "batch_ids = faiss_vectorstore.add_documents(batch_docs)\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"✅ 批量添加 {len(batch_docs)} 个文档\")\n",
    "print(f\"耗时: {end_time - start_time:.4f} 秒\")\n",
    "print(f\"平均每个文档: {(end_time - start_time) / len(batch_docs):.6f} 秒\")\n",
    "\n",
    "# 7.2 批量搜索测试\n",
    "queries = [\"批量文档\", \"人工智能\", \"机器学习\", \"深度学习\"]\n",
    "\n",
    "start_time = time.time()\n",
    "for query in queries:\n",
    "    results = faiss_vectorstore.similarity_search(query, k=3)\n",
    "    print(f\"查询 '{query}': {len(results)} 个结果\")\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"批量搜索耗时: {end_time - start_time:.4f} 秒\")"
   ],
   "id": "2abef4b933daab73",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 批量添加 50 个文档\n",
      "耗时: 1.2681 秒\n",
      "平均每个文档: 0.025361 秒\n",
      "查询 '批量文档': 3 个结果\n",
      "查询 '人工智能': 3 个结果\n",
      "查询 '机器学习': 3 个结果\n",
      "查询 '深度学习': 3 个结果\n",
      "批量搜索耗时: 0.1122 秒\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 8. 获取所有文档",
   "id": "4082367146476e66"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T07:49:13.449471Z",
     "start_time": "2025-07-23T07:49:13.414260Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_all_documents_from_faiss(vectorstore, max_docs=1000):\n",
    "    \"\"\"获取FAISS中的所有文档\"\"\"\n",
    "    try:\n",
    "        # 方法1：使用空查询\n",
    "        all_docs = vectorstore.similarity_search(\"\", k=max_docs)\n",
    "        return all_docs\n",
    "    except:\n",
    "        try:\n",
    "            # 方法2：使用通用词汇\n",
    "            all_docs = vectorstore.similarity_search(\"文档\", k=max_docs)\n",
    "            return all_docs\n",
    "        except:\n",
    "            # 方法3：使用docstore（如果可用）\n",
    "            if hasattr(vectorstore, 'docstore'):\n",
    "                return list(vectorstore.docstore._dict.values())\n",
    "            return []\n",
    "\n",
    "# 获取所有文档\n",
    "all_documents = get_all_documents_from_faiss(faiss_vectorstore)\n",
    "print(f\"总文档数量: {len(all_documents)}\")\n",
    "\n",
    "# 按类别统计\n",
    "category_count = {}\n",
    "for doc in all_documents:\n",
    "    category = doc.metadata.get('category', 'unknown')\n",
    "    category_count[category] = category_count.get(category, 0) + 1\n",
    "\n",
    "print(\"文档类别统计:\")\n",
    "for category, count in category_count.items():\n",
    "    print(f\"- {category}: {count} 个文档\")"
   ],
   "id": "700813cc7406253f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总文档数量: 53\n",
      "文档类别统计:\n",
      "- batch_0: 17 个文档\n",
      "- batch_1: 17 个文档\n",
      "- batch_2: 16 个文档\n",
      "- technology: 3 个文档\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 9. 转换为检索器",
   "id": "63eee78c66975e4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T07:49:18.151179Z",
     "start_time": "2025-07-23T07:49:18.033287Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 9.1 基础检索器\n",
    "retriever = faiss_vectorstore.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 3}\n",
    ")\n",
    "\n",
    "# 使用检索器\n",
    "query = \"人工智能的应用\"\n",
    "retrieved_docs = retriever.invoke(query)\n",
    "\n",
    "print(f\"检索器结果 (查询: '{query}'):\")\n",
    "for i, doc in enumerate(retrieved_docs):\n",
    "    print(f\"{i+1}. {doc.page_content[:80]}...\")\n",
    "\n",
    "# 9.2 带分数阈值的检索器\n",
    "threshold_retriever = faiss_vectorstore.as_retriever(\n",
    "    search_type=\"similarity_score_threshold\",\n",
    "    search_kwargs={\"score_threshold\": 0.5, \"k\": 5}\n",
    ")\n",
    "\n",
    "threshold_results = threshold_retriever.invoke(\"机器学习\")\n",
    "print(f\"阈值检索器结果: {len(threshold_results)} 个文档\")\n",
    "\n",
    "# 9.3 MMR检索器（最大边际相关性）\n",
    "mmr_retriever = faiss_vectorstore.as_retriever(\n",
    "    search_type=\"mmr\",\n",
    "    search_kwargs={\"k\": 3, \"fetch_k\": 10, \"lambda_mult\": 0.5}\n",
    ")\n",
    "\n",
    "mmr_results = mmr_retriever.invoke(\"深度学习技术\")\n",
    "print(f\"MMR检索器结果: {len(mmr_results)} 个文档\")"
   ],
   "id": "d3b96b498bae8510",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "检索器结果 (查询: '人工智能的应用'):\n",
      "1. 人工智能是计算机科学的一个分支，致力于创建智能机器...\n",
      "2. 机器学习是人工智能的子集，使计算机能够从数据中学习...\n",
      "3. 深度学习使用神经网络来模拟人脑的工作方式...\n",
      "阈值检索器结果: 3 个文档\n",
      "MMR检索器结果: 3 个文档\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 10. 性能监控和调试",
   "id": "c9ca62216b9f2ea2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T07:49:35.100237Z",
     "start_time": "2025-07-23T07:49:33.608337Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "\n",
    "def benchmark_faiss_operations(vectorstore, test_queries, num_runs=5):\n",
    "    \"\"\"FAISS操作性能基准测试\"\"\"\n",
    "    print(\"=\" * 50)\n",
    "    print(\"FAISS性能基准测试\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    # 搜索性能测试\n",
    "    search_times = []\n",
    "    for _ in range(num_runs):\n",
    "        start_time = time.time()\n",
    "        for query in test_queries:\n",
    "            results = vectorstore.similarity_search(query, k=5)\n",
    "        end_time = time.time()\n",
    "        search_times.append(end_time - start_time)\n",
    "\n",
    "    avg_search_time = sum(search_times) / len(search_times)\n",
    "    print(f\"平均搜索时间: {avg_search_time:.4f} 秒\")\n",
    "    print(f\"每个查询平均时间: {avg_search_time / len(test_queries):.6f} 秒\")\n",
    "\n",
    "    # 添加文档性能测试\n",
    "    test_docs = [\n",
    "        Document(page_content=f\"性能测试文档{i}\", metadata={\"test\": True})\n",
    "        for i in range(10)\n",
    "    ]\n",
    "\n",
    "    add_times = []\n",
    "    for _ in range(num_runs):\n",
    "        start_time = time.time()\n",
    "        vectorstore.add_documents(test_docs)\n",
    "        end_time = time.time()\n",
    "        add_times.append(end_time - start_time)\n",
    "\n",
    "    avg_add_time = sum(add_times) / len(add_times)\n",
    "    print(f\"平均添加时间: {avg_add_time:.4f} 秒\")\n",
    "    print(f\"每个文档平均添加时间: {avg_add_time / len(test_docs):.6f} 秒\")\n",
    "\n",
    "# 运行性能测试\n",
    "test_queries = [\"人工智能\", \"机器学习\", \"深度学习\", \"自然语言处理\"]\n",
    "benchmark_faiss_operations(faiss_vectorstore, test_queries)"
   ],
   "id": "40c18b514455d5e3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "FAISS性能基准测试\n",
      "==================================================\n",
      "平均搜索时间: 0.1369 秒\n",
      "每个查询平均时间: 0.034230 秒\n",
      "平均添加时间: 0.1604 秒\n",
      "每个文档平均添加时间: 0.016039 秒\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T07:03:56.273154Z",
     "start_time": "2025-07-23T07:03:53.944736Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "1. FAISS向量存储示例\n",
      "============================================================\n",
      "\n",
      "1.1 基础FAISS向量存储创建\n",
      "✅ FAISS向量存储创建成功，包含 7 个文档\n",
      "\n",
      "1.2 FAISS索引保存和加载\n",
      "✅ FAISS索引已保存到 faiss_index\n",
      "✅ FAISS索引加载成功\n",
      "\n",
      "1.3 基础相似性搜索\n",
      "查询: '什么是人工智能技术？'\n",
      "最相似的文档:\n",
      "1. 人工智能是计算机科学的一个分支，致力于创建智能机器\n",
      "   元数据: {'source': 'ai_intro.txt', 'category': 'technology', 'date': '2024-01-01'}\n",
      "\n",
      "2. 机器学习是人工智能的子集，使计算机能够从数据中学习\n",
      "   元数据: {'source': 'ml_basics.txt', 'category': 'technology', 'date': '2024-01-02'}\n",
      "\n",
      "3. 自然语言处理让计算机理解和生成人类语言\n",
      "   元数据: {'source': 'nlp_overview.txt', 'category': 'technology', 'date': '2024-01-04'}\n",
      "\n",
      "\n",
      "1.4 带分数的相似性搜索\n",
      "带分数的搜索结果:\n",
      "1. 分数: 0.3241\n",
      "   内容: 人工智能是计算机科学的一个分支，致力于创建智能机器...\n",
      "   来源: ai_intro.txt\n",
      "\n",
      "2. 分数: 0.3984\n",
      "   内容: 机器学习是人工智能的子集，使计算机能够从数据中学习...\n",
      "   来源: ml_basics.txt\n",
      "\n",
      "3. 分数: 0.6391\n",
      "   内容: 自然语言处理让计算机理解和生成人类语言...\n",
      "   来源: nlp_overview.txt\n",
      "\n",
      "\n",
      "1.5 基于阈值的相似性搜索\n",
      "FAISS示例失败: 'FAISS' object has no attribute 'similarity_search_with_score_threshold'\n"
     ]
    }
   ],
   "execution_count": 48,
   "source": [
    "\n",
    "def faiss_vectorstore_example():\n",
    "    \"\"\"FAISS向量存储详细示例\"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"1. FAISS向量存储示例\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    try:\n",
    "        # 初始化嵌入模型\n",
    "        # embeddings = HuggingFaceEmbeddings(\n",
    "        #     model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "        # )\n",
    "        embeddings = OllamaEmbeddings(\n",
    "        base_url=\"http://localhost:11434\",\n",
    "        model=\"nomic-embed-text:latest\",  # 推荐的嵌入模型\n",
    "        )\n",
    "\n",
    "        # 准备文档\n",
    "        documents = [\n",
    "            Document(\n",
    "                page_content=\"人工智能是计算机科学的一个分支，致力于创建智能机器\",\n",
    "                metadata={\"source\": \"ai_intro.txt\", \"category\": \"technology\", \"date\": \"2024-01-01\"}\n",
    "            ),\n",
    "            Document(\n",
    "                page_content=\"机器学习是人工智能的子集，使计算机能够从数据中学习\",\n",
    "                metadata={\"source\": \"ml_basics.txt\", \"category\": \"technology\", \"date\": \"2024-01-02\"}\n",
    "            ),\n",
    "            Document(\n",
    "                page_content=\"深度学习使用神经网络来模拟人脑的工作方式\",\n",
    "                metadata={\"source\": \"dl_guide.txt\", \"category\": \"technology\", \"date\": \"2024-01-03\"}\n",
    "            ),\n",
    "            Document(\n",
    "                page_content=\"自然语言处理让计算机理解和生成人类语言\",\n",
    "                metadata={\"source\": \"nlp_overview.txt\", \"category\": \"technology\", \"date\": \"2024-01-04\"}\n",
    "            ),\n",
    "            Document(\n",
    "                page_content=\"计算机视觉技术可以识别和分析图像中的内容\",\n",
    "                metadata={\"source\": \"cv_intro.txt\", \"category\": \"technology\", \"date\": \"2024-01-05\"}\n",
    "            ),\n",
    "            Document(\n",
    "                page_content=\"今天天气很好，适合出门散步和运动\",\n",
    "                metadata={\"source\": \"weather.txt\", \"category\": \"daily\", \"date\": \"2024-01-06\"}\n",
    "            ),\n",
    "            Document(\n",
    "                page_content=\"股票市场今天表现良好，科技股领涨\",\n",
    "                metadata={\"source\": \"market.txt\", \"category\": \"finance\", \"date\": \"2024-01-07\"}\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        # 1.1 基础FAISS创建\n",
    "        print(\"\\n1.1 基础FAISS向量存储创建\")\n",
    "        faiss_vectorstore = FAISS.from_documents(documents, embeddings)\n",
    "        print(f\"✅ FAISS向量存储创建成功，包含 {len(documents)} 个文档\")\n",
    "\n",
    "        # 1.2 保存和加载\n",
    "        print(\"\\n1.2 FAISS索引保存和加载\")\n",
    "        index_path = \"faiss_index\"\n",
    "        faiss_vectorstore.save_local(index_path)\n",
    "        print(f\"✅ FAISS索引已保存到 {index_path}\")\n",
    "\n",
    "        # 加载索引\n",
    "        loaded_vectorstore = FAISS.load_local(\n",
    "            index_path,\n",
    "            embeddings,\n",
    "            allow_dangerous_deserialization=True\n",
    "        )\n",
    "        print(\"✅ FAISS索引加载成功\")\n",
    "\n",
    "        # 1.3 基础相似性搜索\n",
    "        print(\"\\n1.3 基础相似性搜索\")\n",
    "        query = \"什么是人工智能技术？\"\n",
    "        similar_docs = faiss_vectorstore.similarity_search(query, k=3)\n",
    "\n",
    "        print(f\"查询: '{query}'\")\n",
    "        print(\"最相似的文档:\")\n",
    "        for i, doc in enumerate(similar_docs):\n",
    "            print(f\"{i+1}. {doc.page_content}\")\n",
    "            print(f\"   元数据: {doc.metadata}\")\n",
    "            print()\n",
    "\n",
    "        # 1.4 带分数的相似性搜索\n",
    "        print(\"\\n1.4 带分数的相似性搜索\")\n",
    "        similar_docs_with_scores = faiss_vectorstore.similarity_search_with_score(query, k=3)\n",
    "\n",
    "        print(\"带分数的搜索结果:\")\n",
    "        for i, (doc, score) in enumerate(similar_docs_with_scores):\n",
    "            print(f\"{i+1}. 分数: {score:.4f}\")\n",
    "            print(f\"   内容: {doc.page_content[:80]}...\")\n",
    "            print(f\"   来源: {doc.metadata.get('source', 'unknown')}\")\n",
    "            print()\n",
    "\n",
    "        # 1.5 基于阈值的搜索\n",
    "        print(\"\\n1.5 基于阈值的相似性搜索\")\n",
    "        threshold = 0.8\n",
    "        similar_docs_threshold = faiss_vectorstore.similarity_search_with_score_threshold(\n",
    "            query,\n",
    "            score_threshold=threshold\n",
    "        )\n",
    "\n",
    "        print(f\"阈值 {threshold} 以上的文档:\")\n",
    "        for doc, score in similar_docs_threshold:\n",
    "            print(f\"分数: {score:.4f} - {doc.page_content[:60]}...\")\n",
    "\n",
    "        # 1.6 添加新文档\n",
    "        print(\"\\n1.6 添加新文档\")\n",
    "        new_documents = [\n",
    "            Document(\n",
    "                page_content=\"量子计算是一种利用量子力学原理的计算方式\",\n",
    "                metadata={\"source\": \"quantum.txt\", \"category\": \"technology\", \"date\": \"2024-01-08\"}\n",
    "            ),\n",
    "            Document(\n",
    "                page_content=\"区块链技术提供了去中心化的数据存储方案\",\n",
    "                metadata={\"source\": \"blockchain.txt\", \"category\": \"technology\", \"date\": \"2024-01-09\"}\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        # 添加文档\n",
    "        faiss_vectorstore.add_documents(new_documents)\n",
    "        print(f\"✅ 已添加 {len(new_documents)} 个新文档\")\n",
    "\n",
    "        # 验证添加结果\n",
    "        new_query = \"量子计算的原理\"\n",
    "        new_results = faiss_vectorstore.similarity_search(new_query, k=2)\n",
    "        print(f\"新查询 '{new_query}' 的结果:\")\n",
    "        for doc in new_results:\n",
    "            print(f\"- {doc.page_content[:50]}...\")\n",
    "\n",
    "        # 1.7 不同搜索算法\n",
    "        print(\"\\n1.7 不同FAISS搜索算法\")\n",
    "\n",
    "        # 使用不同的索引类型\n",
    "        try:\n",
    "            # 创建IVF索引（适合大规模数据）\n",
    "            faiss_ivf = FAISS.from_documents(\n",
    "                documents,\n",
    "                embeddings,\n",
    "                index_type=\"IVF\",\n",
    "                nlist=10  # 聚类中心数量\n",
    "            )\n",
    "\n",
    "            ivf_results = faiss_ivf.similarity_search(\"机器学习算法\", k=2)\n",
    "            print(\"IVF索引搜索结果:\")\n",
    "            for doc in ivf_results:\n",
    "                print(f\"- {doc.page_content[:50]}...\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"IVF索引创建失败: {e}\")\n",
    "\n",
    "        return faiss_vectorstore\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"FAISS示例失败: {e}\")\n",
    "        return None\n",
    "faiss_vectorstore_example()"
   ],
   "id": "f8e20a3aa1c703fa"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Chroma向量存储详细示例",
   "id": "a546ffcd5b10b074"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "def chroma_vectorstore_example():\n",
    "    \"\"\"Chroma向量存储详细示例\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"2. Chroma向量存储示例\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    try:\n",
    "        # 初始化嵌入模型\n",
    "        embeddings = HuggingFaceEmbeddings(\n",
    "            model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "        )\n",
    "\n",
    "        # 准备文档\n",
    "        documents = [\n",
    "            Document(\n",
    "                page_content=\"Python是一种高级编程语言，语法简洁易读\",\n",
    "                metadata={\"language\": \"python\", \"difficulty\": \"beginner\", \"topic\": \"programming\"}\n",
    "            ),\n",
    "            Document(\n",
    "                page_content=\"JavaScript是Web开发的核心语言之一\",\n",
    "                metadata={\"language\": \"javascript\", \"difficulty\": \"intermediate\", \"topic\": \"web\"}\n",
    "            ),\n",
    "            Document(\n",
    "                page_content=\"Java是一种面向对象的编程语言，广泛用于企业开发\",\n",
    "                metadata={\"language\": \"java\", \"difficulty\": \"intermediate\", \"topic\": \"enterprise\"}\n",
    "            ),\n",
    "            Document(\n",
    "                page_content=\"C++是一种高性能的系统编程语言\",\n",
    "                metadata={\"language\": \"cpp\", \"difficulty\": \"advanced\", \"topic\": \"system\"}\n",
    "            ),\n",
    "            Document(\n",
    "                page_content=\"Go语言是Google开发的现代编程语言，适合并发编程\",\n",
    "                metadata={\"language\": \"go\", \"difficulty\": \"intermediate\", \"topic\": \"concurrent\"}\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        # 2.1 基础Chroma创建\n",
    "        print(\"\\n2.1 基础Chroma向量存储创建\")\n",
    "        persist_directory = \"./chroma_db\"\n",
    "\n",
    "        chroma_vectorstore = Chroma.from_documents(\n",
    "            documents=documents,\n",
    "            embedding=embeddings,\n",
    "            persist_directory=persist_directory,\n",
    "            collection_name=\"programming_languages\"\n",
    "        )\n",
    "\n",
    "        print(f\"✅ Chroma向量存储创建成功，持久化目录: {persist_directory}\")\n",
    "\n",
    "        # 2.2 持久化\n",
    "        print(\"\\n2.2 Chroma数据持久化\")\n",
    "        chroma_vectorstore.persist()\n",
    "        print(\"✅ Chroma数据已持久化\")\n",
    "\n",
    "        # 2.3 基础搜索\n",
    "        print(\"\\n2.3 基础相似性搜索\")\n",
    "        query = \"适合初学者的编程语言\"\n",
    "        results = chroma_vectorstore.similarity_search(query, k=3)\n",
    "\n",
    "        print(f\"查询: '{query}'\")\n",
    "        for i, doc in enumerate(results):\n",
    "            print(f\"{i+1}. {doc.page_content}\")\n",
    "            print(f\"   元数据: {doc.metadata}\")\n",
    "            print()\n",
    "\n",
    "        # 2.4 元数据过滤搜索\n",
    "        print(\"\\n2.4 基于元数据的过滤搜索\")\n",
    "\n",
    "        # 搜索初学者难度的语言\n",
    "        beginner_results = chroma_vectorstore.similarity_search(\n",
    "            query=\"编程语言\",\n",
    "            k=5,\n",
    "            filter={\"difficulty\": \"beginner\"}\n",
    "        )\n",
    "\n",
    "        print(\"初学者难度的编程语言:\")\n",
    "        for doc in beginner_results:\n",
    "            print(f\"- {doc.page_content}\")\n",
    "            print(f\"  难度: {doc.metadata['difficulty']}\")\n",
    "\n",
    "        # 搜索Web相关的语言\n",
    "        web_results = chroma_vectorstore.similarity_search(\n",
    "            query=\"开发语言\",\n",
    "            k=5,\n",
    "            filter={\"topic\": \"web\"}\n",
    "        )\n",
    "\n",
    "        print(\"\\nWeb开发相关的语言:\")\n",
    "        for doc in web_results:\n",
    "            print(f\"- {doc.page_content}\")\n",
    "            print(f\"  主题: {doc.metadata['topic']}\")\n",
    "\n",
    "        # 2.5 复杂过滤条件\n",
    "        print(\"\\n2.5 复杂过滤条件\")\n",
    "\n",
    "        # 使用$in操作符\n",
    "        intermediate_results = chroma_vectorstore.similarity_search(\n",
    "            query=\"编程\",\n",
    "            k=5,\n",
    "            filter={\"difficulty\": {\"$in\": [\"intermediate\", \"advanced\"]}}\n",
    "        )\n",
    "\n",
    "        print(\"中级和高级难度的语言:\")\n",
    "        for doc in intermediate_results:\n",
    "            print(f\"- {doc.page_content}\")\n",
    "            print(f\"  难度: {doc.metadata['difficulty']}\")\n",
    "\n",
    "        # 2.6 获取集合信息\n",
    "        print(\"\\n2.6 Chroma集合信息\")\n",
    "        collection = chroma_vectorstore._collection\n",
    "        print(f\"集合名称: {collection.name}\")\n",
    "        print(f\"文档数量: {collection.count()}\")\n",
    "\n",
    "        # 2.7 删除文档\n",
    "        print(\"\\n2.7 删除文档操作\")\n",
    "\n",
    "        # 添加一个临时文档用于删除演示\n",
    "        temp_doc = Document(\n",
    "            page_content=\"临时测试文档，将被删除\",\n",
    "            metadata={\"temp\": True, \"id\": \"temp_doc_1\"}\n",
    "        )\n",
    "\n",
    "        doc_ids = chroma_vectorstore.add_documents([temp_doc])\n",
    "        print(f\"添加临时文档，ID: {doc_ids}\")\n",
    "\n",
    "        # 删除文档\n",
    "        if doc_ids:\n",
    "            chroma_vectorstore.delete(doc_ids)\n",
    "            print(\"✅ 临时文档已删除\")\n",
    "\n",
    "        # 2.8 从现有集合加载\n",
    "        print(\"\\n2.8 从现有集合加载\")\n",
    "\n",
    "        # 创建新的Chroma实例连接到现有集合\n",
    "        existing_chroma = Chroma(\n",
    "            persist_directory=persist_directory,\n",
    "            embedding_function=embeddings,\n",
    "            collection_name=\"programming_languages\"\n",
    "        )\n",
    "\n",
    "        # 验证加载成功\n",
    "        test_results = existing_chroma.similarity_search(\"Python\", k=1)\n",
    "        print(f\"从现有集合加载成功，测试搜索结果: {len(test_results)} 个文档\")\n",
    "\n",
    "        return chroma_vectorstore\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Chroma示例失败: {e}\")\n",
    "        return None"
   ],
   "id": "a022ecedca83e637",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Qdrant向量存储示例",
   "id": "e17257a0ade69726"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "def qdrant_vectorstore_example():\n",
    "    \"\"\"Qdrant向量存储示例\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"3. Qdrant向量存储示例\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    try:\n",
    "        from qdrant_client import QdrantClient\n",
    "        from qdrant_client.models import Distance, VectorParams\n",
    "\n",
    "        # 初始化嵌入模型\n",
    "        embeddings = HuggingFaceEmbeddings(\n",
    "            model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "        )\n",
    "\n",
    "        # 3.1 本地Qdrant设置\n",
    "        print(\"\\n3.1 本地Qdrant向量存储\")\n",
    "\n",
    "        # 创建Qdrant客户端（内存模式）\n",
    "        client = QdrantClient(\":memory:\")\n",
    "\n",
    "        # 准备文档\n",
    "        documents = [\n",
    "            Document(\n",
    "                page_content=\"机器学习算法可以分为监督学习、无监督学习和强化学习\",\n",
    "                metadata={\"category\": \"ml\", \"type\": \"algorithm\", \"level\": \"intermediate\"}\n",
    "            ),\n",
    "            Document(\n",
    "                page_content=\"监督学习使用标记数据训练模型进行预测\",\n",
    "                metadata={\"category\": \"ml\", \"type\": \"supervised\", \"level\": \"beginner\"}\n",
    "            ),\n",
    "            Document(\n",
    "                page_content=\"无监督学习从未标记数据中发现隐藏模式\",\n",
    "                metadata={\"category\": \"ml\", \"type\": \"unsupervised\", \"level\": \"intermediate\"}\n",
    "            ),\n",
    "            Document(\n",
    "                page_content=\"强化学习通过与环境交互来学习最优策略\",\n",
    "                metadata={\"category\": \"ml\", \"type\": \"reinforcement\", \"level\": \"advanced\"}\n",
    "            ),\n",
    "            Document(\n",
    "                page_content=\"神经网络是深度学习的基础架构\",\n",
    "                metadata={\"category\": \"dl\", \"type\": \"architecture\", \"level\": \"intermediate\"}\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        # 创建Qdrant向量存储\n",
    "        collection_name = \"ml_knowledge\"\n",
    "        qdrant_vectorstore = Qdrant.from_documents(\n",
    "            documents,\n",
    "            embeddings,\n",
    "            client=client,\n",
    "            collection_name=collection_name,\n",
    "            force_recreate=True\n",
    "        )\n",
    "\n",
    "        print(f\"✅ Qdrant向量存储创建成功，集合: {collection_name}\")\n",
    "\n",
    "        # 3.2 基础搜索\n",
    "        print(\"\\n3.2 Qdrant相似性搜索\")\n",
    "        query = \"什么是监督学习？\"\n",
    "        results = qdrant_vectorstore.similarity_search(query, k=3)\n",
    "\n",
    "        print(f\"查询: '{query}'\")\n",
    "        for i, doc in enumerate(results):\n",
    "            print(f\"{i+1}. {doc.page_content}\")\n",
    "            print(f\"   类别: {doc.metadata.get('category')}\")\n",
    "            print(f\"   类型: {doc.metadata.get('type')}\")\n",
    "            print()\n",
    "\n",
    "        # 3.3 带分数搜索\n",
    "        print(\"\\n3.3 Qdrant带分数搜索\")\n",
    "        results_with_scores = qdrant_vectorstore.similarity_search_with_score(query, k=3)\n",
    "\n",
    "        for i, (doc, score) in enumerate(results_with_scores):\n",
    "            print(f\"{i+1}. 分数: {score:.4f}\")\n",
    "            print(f\"   内容: {doc.page_content[:60]}...\")\n",
    "            print()\n",
    "\n",
    "        # 3.4 过滤搜索\n",
    "        print(\"\\n3.4 Qdrant过滤搜索\")\n",
    "\n",
    "        # 搜索特定类别\n",
    "        ml_results = qdrant_vectorstore.similarity_search(\n",
    "            query=\"学习算法\",\n",
    "            k=5,\n",
    "            filter={\"category\": \"ml\"}\n",
    "        )\n",
    "\n",
    "        print(\"机器学习类别的文档:\")\n",
    "        for doc in ml_results:\n",
    "            print(f\"- {doc.page_content[:50]}...\")\n",
    "            print(f\"  类型: {doc.metadata.get('type')}\")\n",
    "\n",
    "        # 3.5 添加新文档\n",
    "        print(\"\\n3.5 添加新文档到Qdrant\")\n",
    "        new_docs = [\n",
    "            Document(\n",
    "                page_content=\"卷积神经网络特别适合图像处理任务\",\n",
    "                metadata={\"category\": \"dl\", \"type\": \"cnn\", \"level\": \"intermediate\"}\n",
    "            ),\n",
    "            Document(\n",
    "                page_content=\"循环神经网络擅长处理序列数据\",\n",
    "                metadata={\"category\": \"dl\", \"type\": \"rnn\", \"level\": \"intermediate\"}\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        qdrant_vectorstore.add_documents(new_docs)\n",
    "        print(f\"✅ 已添加 {len(new_docs)} 个新文档\")\n",
    "\n",
    "        # 验证添加\n",
    "        cnn_results = qdrant_vectorstore.similarity_search(\"卷积神经网络\", k=1)\n",
    "        print(f\"验证添加: {cnn_results[0].page_content[:40]}...\")\n",
    "\n",
    "        return qdrant_vectorstore\n",
    "\n",
    "    except ImportError:\n",
    "        print(\"需要安装qdrant-client: pip install qdrant-client\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Qdrant示例失败: {e}\")\n",
    "        return None"
   ],
   "id": "9d860dca190af24e",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Pinecone向量存储示例",
   "id": "b10cf2ac88691fdc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "def pinecone_vectorstore_example():\n",
    "    \"\"\"Pinecone向量存储示例\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"4. Pinecone向量存储示例\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    try:\n",
    "        import pinecone\n",
    "\n",
    "        # 4.1 Pinecone初始化\n",
    "        print(\"\\n4.1 Pinecone初始化\")\n",
    "\n",
    "        api_key = os.getenv(\"PINECONE_API_KEY\")\n",
    "        if not api_key:\n",
    "            print(\"请设置PINECONE_API_KEY环境变量\")\n",
    "            return None\n",
    "\n",
    "        # 初始化Pinecone\n",
    "        pinecone.init(\n",
    "            api_key=api_key,\n",
    "            environment=os.getenv(\"PINECONE_ENV\", \"us-west1-gcp\")\n",
    "        )\n",
    "\n",
    "        # 初始化嵌入模型\n",
    "        embeddings = OpenAIEmbeddings(\n",
    "            api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    "        )\n",
    "\n",
    "        # 准备文档\n",
    "        documents = [\n",
    "            Document(\n",
    "                page_content=\"云计算提供按需访问的计算资源\",\n",
    "                metadata={\"service\": \"cloud\", \"provider\": \"general\", \"type\": \"infrastructure\"}\n",
    "            ),\n",
    "            Document(\n",
    "                page_content=\"AWS是亚马逊提供的云计算平台\",\n",
    "                metadata={\"service\": \"cloud\", \"provider\": \"aws\", \"type\": \"platform\"}\n",
    "            ),\n",
    "            Document(\n",
    "                page_content=\"Azure是微软的云计算服务\",\n",
    "                metadata={\"service\": \"cloud\", \"provider\": \"microsoft\", \"type\": \"platform\"}\n",
    "            ),\n",
    "            Document(\n",
    "                page_content=\"Google Cloud Platform提供各种云服务\",\n",
    "                metadata={\"service\": \"cloud\", \"provider\": \"google\", \"type\": \"platform\"}\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        # 4.2 创建Pinecone索引\n",
    "        print(\"\\n4.2 创建Pinecone索引\")\n",
    "\n",
    "        index_name = \"langchain-demo\"\n",
    "        dimension = 1536  # OpenAI嵌入维度\n",
    "\n",
    "        # 检查索引是否存在\n",
    "        if index_name not in pinecone.list_indexes():\n",
    "            pinecone.create_index(\n",
    "                name=index_name,\n",
    "                dimension=dimension,\n",
    "                metric=\"cosine\"\n",
    "            )\n",
    "            print(f\"✅ 创建Pinecone索引: {index_name}\")\n",
    "        else:\n",
    "            print(f\"✅ 使用现有Pinecone索引: {index_name}\")\n",
    "\n",
    "        # 4.3 创建Pinecone向量存储\n",
    "        print(\"\\n4.3 创建Pinecone向量存储\")\n",
    "\n",
    "        pinecone_vectorstore = Pinecone.from_documents(\n",
    "            documents,\n",
    "            embeddings,\n",
    "            index_name=index_name\n",
    "        )\n",
    "\n",
    "        print(\"✅ Pinecone向量存储创建成功\")\n",
    "\n",
    "        # 4.4 搜索测试\n",
    "        print(\"\\n4.4 Pinecone搜索测试\")\n",
    "\n",
    "        query = \"什么是云计算平台？\"\n",
    "        results = pinecone_vectorstore.similarity_search(query, k=3)\n",
    "\n",
    "        print(f\"查询: '{query}'\")\n",
    "        for i, doc in enumerate(results):\n",
    "            print(f\"{i+1}. {doc.page_content}\")\n",
    "            print(f\"   提供商: {doc.metadata.get('provider')}\")\n",
    "            print()\n",
    "\n",
    "        # 4.5 命名空间使用\n",
    "        print(\"\\n4.5 Pinecone命名空间\")\n",
    "\n",
    "        # 使用命名空间分离不同类型的数据\n",
    "        namespace_vectorstore = Pinecone.from_existing_index(\n",
    "            index_name=index_name,\n",
    "            embedding=embeddings,\n",
    "            namespace=\"cloud_services\"\n",
    "        )\n",
    "\n",
    "        # 添加文档到特定命名空间\n",
    "        namespace_docs = [\n",
    "            Document(\n",
    "                page_content=\"Kubernetes是容器编排平台\",\n",
    "                metadata={\"type\": \"orchestration\", \"category\": \"devops\"}\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        namespace_vectorstore.add_documents(namespace_docs)\n",
    "        print(\"✅ 文档已添加到命名空间\")\n",
    "\n",
    "        return pinecone_vectorstore\n",
    "\n",
    "    except ImportError:\n",
    "        print(\"需要安装pinecone-client: pip install pinecone-client\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Pinecone示例失败: {e}\")\n",
    "        return None"
   ],
   "id": "5287d59228125dbf",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Elasticsearch向量存储示例",
   "id": "98ba478b7aaa80cd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "def elasticsearch_vectorstore_example():\n",
    "    \"\"\"Elasticsearch向量存储示例\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"5. Elasticsearch向量存储示例\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    try:\n",
    "        from elasticsearch import Elasticsearch\n",
    "\n",
    "        # 5.1 Elasticsearch连接\n",
    "        print(\"\\n5.1 Elasticsearch连接\")\n",
    "\n",
    "        # 连接到本地Elasticsearch\n",
    "        es_client = Elasticsearch(\n",
    "            [{\"host\": \"localhost\", \"port\": 9200}],\n",
    "            # 如果有认证，添加以下配置\n",
    "            # http_auth=(\"username\", \"password\"),\n",
    "            # use_ssl=True,\n",
    "            # verify_certs=True\n",
    "        )\n",
    "\n",
    "        # 检查连接\n",
    "        if not es_client.ping():\n",
    "            print(\"无法连接到Elasticsearch，请确保服务正在运行\")\n",
    "            return None\n",
    "\n",
    "        print(\"✅ Elasticsearch连接成功\")\n",
    "\n",
    "        # 初始化嵌入模型\n",
    "        embeddings = HuggingFaceEmbeddings(\n",
    "            model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "        )\n",
    "\n",
    "        # 准备文档\n",
    "        documents = [\n",
    "            Document(\n",
    "                page_content=\"搜索引擎技术是信息检索的核心\",\n",
    "                metadata={\"domain\": \"search\", \"complexity\": \"medium\", \"year\": 2024}\n",
    "            ),\n",
    "            Document(\n",
    "                page_content=\"全文搜索可以在大量文档中快速找到相关内容\",\n",
    "                metadata={\"domain\": \"search\", \"complexity\": \"low\", \"year\": 2024}\n",
    "            ),\n",
    "            Document(\n",
    "                page_content=\"倒排索引是搜索引擎的基础数据结构\",\n",
    "                metadata={\"domain\": \"search\", \"complexity\": \"high\", \"year\": 2024}\n",
    "            ),\n",
    "            Document(\n",
    "                page_content=\"分布式搜索可以处理大规模数据集\",\n",
    "                metadata={\"domain\": \"distributed\", \"complexity\": \"high\", \"year\": 2024}\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        # 5.2 创建Elasticsearch向量存储\n",
    "        print(\"\\n5.2 创建Elasticsearch向量存储\")\n",
    "\n",
    "        index_name = \"langchain_demo\"\n",
    "\n",
    "        es_vectorstore = ElasticsearchStore.from_documents(\n",
    "            documents,\n",
    "            embeddings,\n",
    "            es_connection=es_client,\n",
    "            index_name=index_name,\n",
    "            distance_strategy=\"COSINE\"\n",
    "        )\n",
    "\n",
    "        print(f\"✅ Elasticsearch向量存储创建成功，索引: {index_name}\")\n",
    "\n",
    "        # 5.3 基础搜索\n",
    "        print(\"\\n5.3 Elasticsearch搜索\")\n",
    "\n",
    "        query = \"如何实现快速搜索？\"\n",
    "        results = es_vectorstore.similarity_search(query, k=3)\n",
    "\n",
    "        print(f\"查询: '{query}'\")\n",
    "        for i, doc in enumerate(results):\n",
    "            print(f\"{i+1}. {doc.page_content}\")\n",
    "            print(f\"   领域: {doc.metadata.get('domain')}\")\n",
    "            print(f\"   复杂度: {doc.metadata.get('complexity')}\")\n",
    "            print()\n",
    "\n",
    "        # 5.4 混合搜索（向量+关键词）\n",
    "        print(\"\\n5.4 Elasticsearch混合搜索\")\n",
    "\n",
    "        # 结合向量搜索和关键词搜索\n",
    "        hybrid_results = es_vectorstore.similarity_search(\n",
    "            query=\"搜索引擎\",\n",
    "            k=3,\n",
    "            filter={\"term\": {\"metadata.domain.keyword\": \"search\"}}\n",
    "        )\n",
    "\n",
    "        print(\"混合搜索结果:\")\n",
    "        for doc in hybrid_results:\n",
    "            print(f\"- {doc.page_content}\")\n",
    "            print(f\"  复杂度: {doc.metadata.get('complexity')}\")\n",
    "\n",
    "        # 5.5 聚合查询\n",
    "        print(\"\\n5.5 Elasticsearch聚合查询\")\n",
    "\n",
    "        # 获取不同复杂度的文档数量\n",
    "        agg_query = {\n",
    "            \"aggs\": {\n",
    "                \"complexity_count\": {\n",
    "                    \"terms\": {\n",
    "                        \"field\": \"metadata.complexity.keyword\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "\n",
    "        # 执行聚合查询\n",
    "        agg_results = es_client.search(\n",
    "            index=index_name,\n",
    "            body=agg_query,\n",
    "            size=0\n",
    "        )\n",
    "\n",
    "        print(\"复杂度分布:\")\n",
    "        for bucket in agg_results[\"aggregations\"][\"complexity_count\"][\"buckets\"]:\n",
    "            print(f\"- {bucket['key']}: {bucket['doc_count']} 个文档\")\n",
    "\n",
    "        return es_vectorstore\n",
    "\n",
    "    except ImportError:\n",
    "        print(\"需要安装elasticsearch: pip install elasticsearch\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Elasticsearch示例失败: {e}\")\n",
    "        return None"
   ],
   "id": "f4215574e7c5df12",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Redis向量存储示例",
   "id": "41c5f31c93fef7b6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "def redis_vectorstore_example():\n",
    "    \"\"\"Redis向量存储示例\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"6. Redis向量存储示例\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    try:\n",
    "        import redis\n",
    "\n",
    "        # 6.1 Redis连接\n",
    "        print(\"\\n6.1 Redis连接\")\n",
    "\n",
    "        redis_client = redis.Redis(\n",
    "            host=\"localhost\",\n",
    "            port=6379,\n",
    "            db=0,\n",
    "            decode_responses=True\n",
    "        )\n",
    "\n",
    "        # 检查连接\n",
    "        redis_client.ping()\n",
    "        print(\"✅ Redis连接成功\")\n",
    "\n",
    "        # 初始化嵌入模型\n",
    "        embeddings = HuggingFaceEmbeddings(\n",
    "            model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "        )\n",
    "\n",
    "        # 准备文档\n",
    "        documents = [\n",
    "            Document(\n",
    "                page_content=\"Redis是一个高性能的键值存储数据库\",\n",
    "                metadata={\"type\": \"database\", \"performance\": \"high\", \"category\": \"nosql\"}\n",
    "            ),\n",
    "            Document(\n",
    "                page_content=\"Redis支持多种数据结构，如字符串、列表、集合等\",\n",
    "                metadata={\"type\": \"database\", \"feature\": \"data_structures\", \"category\": \"nosql\"}\n",
    "            ),\n",
    "            Document(\n",
    "                page_content=\"Redis可以用作缓存、消息队列和会话存储\",\n",
    "                metadata={\"type\": \"database\", \"use_case\": \"cache\", \"category\": \"nosql\"}\n",
    "            ),\n",
    "            Document(\n",
    "                page_content=\"Redis集群提供了高可用性和水平扩展能力\",\n",
    "                metadata={\"type\": \"database\", \"feature\": \"clustering\", \"category\": \"nosql\"}\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        # 6.2 创建Redis向量存储\n",
    "        print(\"\\n6.2 创建Redis向量存储\")\n",
    "\n",
    "        index_name = \"redis_langchain_demo\"\n",
    "\n",
    "        redis_vectorstore = Redis.from_documents(\n",
    "            documents,\n",
    "            embeddings,\n",
    "            redis_url=\"redis://localhost:6379\",\n",
    "            index_name=index_name\n",
    "        )\n",
    "\n",
    "        print(f\"✅ Redis向量存储创建成功，索引: {index_name}\")\n",
    "\n",
    "        # 6.3 搜索测试\n",
    "        print(\"\\n6.3 Redis搜索测试\")\n",
    "\n",
    "        query = \"什么是高性能数据库？\"\n",
    "        results = redis_vectorstore.similarity_search(query, k=3)\n",
    "\n",
    "        print(f\"查询: '{query}'\")\n",
    "        for i, doc in enumerate(results):\n",
    "            print(f\"{i+1}. {doc.page_content}\")\n",
    "            print(f\"   类型: {doc.metadata.get('type')}\")\n",
    "            print(f\"   特性: {doc.metadata.get('feature', doc.metadata.get('performance', 'N/A'))}\")\n",
    "            print()\n",
    "\n",
    "        # 6.4 过滤搜索\n",
    "        print(\"\\n6.4 Redis过滤搜索\")\n",
    "\n",
    "        # 搜索特定特性的文档\n",
    "        feature_results = redis_vectorstore.similarity_search(\n",
    "            query=\"Redis功能\",\n",
    "            k=5,\n",
    "            filter={\"feature\": \"data_structures\"}\n",
    "        )\n",
    "\n",
    "        print(\"数据结构相关的文档:\")\n",
    "        for doc in feature_results:\n",
    "            print(f\"- {doc.page_content}\")\n",
    "\n",
    "        return redis_vectorstore\n",
    "\n",
    "    except ImportError:\n",
    "        print(\"需要安装redis: pip install redis\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Redis示例失败: {e}\")\n",
    "        return None"
   ],
   "id": "cb65505a94b7857e",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 向量存储性能对比",
   "id": "b64b990b1e89bce8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "def vector_store_comparison():\n",
    "    \"\"\"向量存储性能对比\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"7. 向量存储性能对比\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # 准备测试数据\n",
    "    embeddings = HuggingFaceEmbeddings(\n",
    "        model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "    )\n",
    "\n",
    "    # 生成测试文档\n",
    "    test_documents = []\n",
    "    for i in range(100):\n",
    "        doc = Document(\n",
    "            page_content=f\"这是第{i}个测试文档，包含一些示例内容用于性能测试。文档编号：{i}\",\n",
    "            metadata={\"doc_id\": i, \"category\": f\"cat_{i % 5}\", \"priority\": i % 3}\n",
    "        )\n",
    "        test_documents.append(doc)\n",
    "\n",
    "    test_query = \"测试文档内容\"\n",
    "\n",
    "    # 测试不同向量存储的性能\n",
    "    stores_to_test = []\n",
    "\n",
    "    # FAISS测试\n",
    "    try:\n",
    "        print(\"\\n7.1 FAISS性能测试\")\n",
    "        start_time = time.time()\n",
    "        faiss_store = FAISS.from_documents(test_documents, embeddings)\n",
    "        creation_time = time.time() - start_time\n",
    "\n",
    "        start_time = time.time()\n",
    "        faiss_results = faiss_store.similarity_search(test_query, k=5)\n",
    "        search_time = time.time() - start_time\n",
    "\n",
    "        stores_to_test.append({\n",
    "            \"name\": \"FAISS\",\n",
    "            \"creation_time\": creation_time,\n",
    "            \"search_time\": search_time,\n",
    "            \"results_count\": len(faiss_results)\n",
    "        })\n",
    "\n",
    "        print(f\"FAISS - 创建时间: {creation_time:.4f}s, 搜索时间: {search_time:.4f}s\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"FAISS测试失败: {e}\")\n",
    "\n",
    "    # Chroma测试\n",
    "    try:\n",
    "        print(\"\\n7.2 Chroma性能测试\")\n",
    "        start_time = time.time()\n",
    "        chroma_store = Chroma.from_documents(\n",
    "            test_documents,\n",
    "            embeddings,\n",
    "            persist_directory=\"./test_chroma\",\n",
    "            collection_name=\"performance_test\"\n",
    "        )\n",
    "        creation_time = time.time() - start_time\n",
    "\n",
    "        start_time = time.time()\n",
    "        chroma_results = chroma_store.similarity_search(test_query, k=5)\n",
    "        search_time = time.time() - start_time\n",
    "\n",
    "        stores_to_test.append({\n",
    "            \"name\": \"Chroma\",\n",
    "            \"creation_time\": creation_time,\n",
    "            \"search_time\": search_time,\n",
    "            \"results_count\": len(chroma_results)\n",
    "        })\n",
    "\n",
    "        print(f\"Chroma - 创建时间: {creation_time:.4f}s, 搜索时间: {search_time:.4f}s\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Chroma测试失败: {e}\")\n",
    "\n",
    "    # 性能对比总结\n",
    "    print(\"\\n7.3 性能对比总结\")\n",
    "    print(f\"{'存储类型':<15} {'创建时间(s)':<12} {'搜索时间(s)':<12} {'结果数量':<10}\")\n",
    "    print(\"-\" * 55)\n",
    "\n",
    "    for store in stores_to_test:\n",
    "        print(f\"{store['name']:<15} {store['creation_time']:<12.4f} \"\n",
    "              f\"{store['search_time']:<12.4f} {store['results_count']:<10}\")\n",
    "\n",
    "    # 推荐建议\n",
    "    print(\"\\n7.4 选择建议\")\n",
    "    print(\"📋 向量存储选择指南:\")\n",
    "    print(\"1. 小规模本地应用: FAISS\")\n",
    "    print(\"2. 需要持久化: Chroma\")\n",
    "    print(\"3. 生产环境大规模: Pinecone/Qdrant\")\n",
    "    print(\"4. 已有Elasticsearch: ElasticsearchStore\")\n",
    "    print(\"5. 需要高性能缓存: Redis\")\n",
    "    print(\"6. 企业级应用: Weaviate/Milvus\")"
   ],
   "id": "4146a0e86f1703c3",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 高级向量操作示例",
   "id": "9ba020d120f26785"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "def advanced_vector_operations():\n",
    "    \"\"\"高级向量操作示例\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"8. 高级向量操作示例\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    try:\n",
    "        embeddings = HuggingFaceEmbeddings(\n",
    "            model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "        )\n",
    "\n",
    "        # 8.1 向量存储合并\n",
    "        print(\"\\n8.1 向量存储合并\")\n",
    "\n",
    "        # 创建两个不同的向量存储\n",
    "        docs1 = [\n",
    "            Document(page_content=\"第一个存储的文档1\", metadata={\"store\": \"store1\"}),\n",
    "            Document(page_content=\"第一个存储的文档2\", metadata={\"store\": \"store1\"})\n",
    "        ]\n",
    "\n",
    "        docs2 = [\n",
    "            Document(page_content=\"第二个存储的文档1\", metadata={\"store\": \"store2\"}),\n",
    "            Document(page_content=\"第二个存储的文档2\", metadata={\"store\": \"store2\"})\n",
    "        ]\n",
    "\n",
    "        store1 = FAISS.from_documents(docs1, embeddings)\n",
    "        store2 = FAISS.from_documents(docs2, embeddings)\n",
    "\n",
    "        # 合并向量存储\n",
    "        store1.merge_from(store2)\n",
    "        print(\"✅ 向量存储合并完成\")\n",
    "\n",
    "        # 验证合并结果\n",
    "        all_results = store1.similarity_search(\"文档\", k=4)\n",
    "        print(f\"合并后总文档数: {len(all_results)}\")\n",
    "        for doc in all_results:\n",
    "            print(f\"- {doc.page_content} (来源: {doc.metadata['store']})\")\n",
    "\n",
    "        # 8.2 批量操作\n",
    "        print(\"\\n8.2 批量向量操作\")\n",
    "\n",
    "        # 批量添加文档\n",
    "        batch_docs = [\n",
    "            Document(page_content=f\"批量文档{i}\", metadata={\"batch\": True, \"id\": i})\n",
    "            for i in range(10)\n",
    "        ]\n",
    "\n",
    "        start_time = time.time()\n",
    "        store1.add_documents(batch_docs)\n",
    "        batch_time = time.time() - start_time\n",
    "\n",
    "        print(f\"批量添加10个文档耗时: {batch_time:.4f}s\")\n",
    "\n",
    "        # 8.3 向量存储统计\n",
    "        print(\"\\n8.3 向量存储统计信息\")\n",
    "\n",
    "        # 获取所有文档进行统计\n",
    "        all_docs = store1.similarity_search(\"\", k=100)  # 获取更多文档\n",
    "\n",
    "        # 统计不同来源的文档数量\n",
    "        store_counts = {}\n",
    "        batch_count = 0\n",
    "\n",
    "        for doc in all_docs:\n",
    "            if doc.metadata.get(\"batch\"):\n",
    "                batch_count += 1\n",
    "            else:\n",
    "                store = doc.metadata.get(\"store\", \"unknown\")\n",
    "                store_counts[store] = store_counts.get(store, 0) + 1\n",
    "\n",
    "        print(\"文档统计:\")\n",
    "        for store, count in store_counts.items():\n",
    "            print(f\"- {store}: {count} 个文档\")\n",
    "        print(f\"- 批量文档: {batch_count} 个文档\")\n",
    "\n",
    "        # 8.4 相似度阈值过滤\n",
    "        print(\"\\n8.4 相似度阈值过滤\")\n",
    "\n",
    "        query = \"批量文档\"\n",
    "        threshold = 0.5\n",
    "\n",
    "        # 获取所有结果并手动过滤\n",
    "        all_results_with_scores = store1.similarity_search_with_score(query, k=20)\n",
    "\n",
    "        filtered_results = [\n",
    "            (doc, score) for doc, score in all_results_with_scores\n",
    "            if score <= threshold  # FAISS使用距离，越小越相似\n",
    "        ]\n",
    "\n",
    "        print(f\"阈值 {threshold} 以下的结果:\")\n",
    "        for doc, score in filtered_results[:5]:\n",
    "            print(f\"- 分数: {score:.4f} - {doc.page_content}\")\n",
    "\n",
    "        return store1\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"高级向量操作失败: {e}\")\n",
    "        return None"
   ],
   "id": "24e13d81dbc70c7e",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "def main():\n",
    "    \"\"\"运行所有向量存储示例\"\"\"\n",
    "    print(\"🚀 LangChain 0.3 Vector Stores 完整示例\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # 运行所有示例\n",
    "    faiss_store = faiss_vectorstore_example()\n",
    "    chroma_store = chroma_vectorstore_example()\n",
    "    qdrant_store = qdrant_vectorstore_example()\n",
    "    pinecone_store = pinecone_vectorstore_example()\n",
    "    es_store = elasticsearch_vectorstore_example()\n",
    "    redis_store = redis_vectorstore_example()\n",
    "\n",
    "    # 性能对比\n",
    "    vector_store_comparison()\n",
    "\n",
    "    # 高级操作\n",
    "    advanced_vector_operations()\n",
    "\n",
    "    print(\"\\n🎉 所有向量存储示例运行完成！\")\n",
    "\n",
    "    # 清理临时文件\n",
    "    import shutil\n",
    "    temp_dirs = [\"faiss_index\", \"chroma_db\", \"test_chroma\"]\n",
    "    for temp_dir in temp_dirs:\n",
    "        if os.path.exists(temp_dir):\n",
    "            try:\n",
    "                shutil.rmtree(temp_dir)\n",
    "                print(f\"🧹 已清理临时目录: {temp_dir}\")\n",
    "            except Exception as e:\n",
    "                print(f\"清理 {temp_dir} 失败: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "id": "5791ac8c34584e27"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
