{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3. Embedding Models 示例",
   "id": "8c936db5daa65279"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T04:52:14.218680Z",
     "start_time": "2025-07-23T04:52:13.636641Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 34,
   "source": [
    "\"\"\"\n",
    "LangChain 0.3 Embedding Models 完整示例\n",
    "包含所有主要嵌入模型和高级用法\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import asyncio\n",
    "from typing import List, Dict, Any, Optional\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import time\n",
    "\n",
    "# 核心嵌入模型导入\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.embeddings import (\n",
    "    HuggingFaceEmbeddings,\n",
    "    HuggingFaceInstructEmbeddings,\n",
    "    SentenceTransformerEmbeddings,\n",
    "    CohereEmbeddings,\n",
    "    BedrockEmbeddings\n",
    ")\n",
    "from langchain_core.documents import Document"
   ],
   "id": "d4fbb25d56977fe7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Ollama嵌入模型示例",
   "id": "1478a9e2b009c891"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T04:57:51.681456Z",
     "start_time": "2025-07-23T04:57:51.478789Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "1. Ollama嵌入模型示例\n",
      "============================================================\n",
      "\n",
      "1.1 基础Ollama嵌入模型\n",
      "生成文档嵌入...\n",
      "文档嵌入数量: 5\n",
      "嵌入向量维度: 768\n",
      "查询嵌入维度: 768\n",
      "\n",
      "1.2 语义相似度计算\n",
      "查询: '什么是人工智能技术？'\n",
      "与各文档的相似度:\n",
      "1. 0.8601 - 人工智能是计算机科学的分支\n",
      "2. 0.5262 - 机器学习是AI的重要组成部分\n",
      "3. 0.5862 - 深度学习使用神经网络进行学习\n",
      "4. 0.7732 - 自然语言处理让计算机理解人类语言\n",
      "5. 0.5400 - 今天天气很好，适合出门散步\n",
      "\n",
      "最相似文档: 人工智能是计算机科学的分支 (相似度: 0.8601)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OllamaEmbeddings(model='nomic-embed-text:latest', validate_model_on_init=False, base_url='http://localhost:11434', client_kwargs={}, async_client_kwargs={}, sync_client_kwargs={}, mirostat=None, mirostat_eta=None, mirostat_tau=None, num_ctx=None, num_gpu=None, keep_alive=None, num_thread=None, repeat_last_n=None, repeat_penalty=None, temperature=None, stop=None, tfs_z=None, top_k=None, top_p=None)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 41,
   "source": [
    "\n",
    "def ollama_embeddings_example():\n",
    "    \"\"\"Ollama嵌入模型示例 - 本地部署\"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"1. Ollama嵌入模型示例\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    try:\n",
    "        # 1.1 基础Ollama嵌入\n",
    "        print(\"\\n1.1 基础Ollama嵌入模型\")\n",
    "        embeddings = OllamaEmbeddings(\n",
    "            base_url=\"http://localhost:11434\",\n",
    "            model=\"nomic-embed-text:latest\",  # 推荐的嵌入模型\n",
    "        )\n",
    "\n",
    "        # 测试文本\n",
    "        texts = [\n",
    "            \"人工智能是计算机科学的分支\",\n",
    "            \"机器学习是AI的重要组成部分\",\n",
    "            \"深度学习使用神经网络进行学习\",\n",
    "            \"自然语言处理让计算机理解人类语言\",\n",
    "            \"今天天气很好，适合出门散步\"\n",
    "        ]\n",
    "\n",
    "        # 生成文档嵌入\n",
    "        print(\"生成文档嵌入...\")\n",
    "        doc_embeddings = embeddings.embed_documents(texts)\n",
    "        print(f\"文档嵌入数量: {len(doc_embeddings)}\")\n",
    "        print(f\"嵌入向量维度: {len(doc_embeddings[0])}\")\n",
    "\n",
    "        # 生成查询嵌入\n",
    "        query = \"什么是人工智能技术？\"\n",
    "        query_embedding = embeddings.embed_query(query)\n",
    "        print(f\"查询嵌入维度: {len(query_embedding)}\")\n",
    "\n",
    "        # 1.2 计算相似度\n",
    "        print(\"\\n1.2 语义相似度计算\")\n",
    "\n",
    "        def cosine_similarity(a: List[float], b: List[float]) -> float:\n",
    "            \"\"\"计算余弦相似度\"\"\"\n",
    "            a_np = np.array(a)\n",
    "            b_np = np.array(b)\n",
    "            return np.dot(a_np, b_np) / (np.linalg.norm(a_np) * np.linalg.norm(b_np))\n",
    "\n",
    "        print(f\"查询: '{query}'\")\n",
    "        print(\"与各文档的相似度:\")\n",
    "        similarities = []\n",
    "        for i, text in enumerate(texts):\n",
    "            similarity = cosine_similarity(query_embedding, doc_embeddings[i])\n",
    "            similarities.append((text, similarity))\n",
    "            print(f\"{i+1}. {similarity:.4f} - {text}\")\n",
    "\n",
    "        # 排序显示最相似的文档\n",
    "        similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "        print(f\"\\n最相似文档: {similarities[0][0]} (相似度: {similarities[0][1]:.4f})\")\n",
    "\n",
    "        # # 1.3 不同Ollama模型对比\n",
    "        # print(\"\\n1.3 不同Ollama嵌入模型对比\")\n",
    "        # ollama_models = [\n",
    "        #     \"nomic-embed-text\",\n",
    "        #     \"mxbai-embed-large\",\n",
    "        #     \"all-minilm\"\n",
    "        # ]\n",
    "        #\n",
    "        # for model_name in ollama_models:\n",
    "        #     try:\n",
    "        #         model_embeddings = OllamaEmbeddings(\n",
    "        #             base_url=\"http://localhost:11434\",\n",
    "        #             model=model_name\n",
    "        #         )\n",
    "        #         test_embedding = model_embeddings.embed_query(\"测试文本\")\n",
    "        #         print(f\"{model_name}: 维度 {len(test_embedding)}\")\n",
    "        #     except Exception as e:\n",
    "        #         print(f\"{model_name}: 不可用 ({str(e)[:50]}...)\")\n",
    "\n",
    "        return embeddings\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Ollama嵌入模型初始化失败: {e}\")\n",
    "        print(\"请确保Ollama服务正在运行并安装了嵌入模型\")\n",
    "        print(\"安装命令: ollama pull nomic-embed-text\")\n",
    "        return None\n",
    "ollama_embeddings_example()"
   ],
   "id": "769df0a1bb7091b0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### OpenAI嵌入模型示例",
   "id": "29bacfbeaad20aea"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "def openai_embeddings_example():\n",
    "    \"\"\"OpenAI嵌入模型示例\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"2. OpenAI嵌入模型示例\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    try:\n",
    "        # 2.1 基础OpenAI嵌入\n",
    "        print(\"\\n2.1 基础OpenAI嵌入\")\n",
    "        embeddings = OpenAIEmbeddings(\n",
    "            model=\"text-embedding-3-small\",  # 新版本模型\n",
    "            api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "            dimensions=1536  # 可选：指定维度\n",
    "        )\n",
    "\n",
    "        texts = [\n",
    "            \"Artificial intelligence is a branch of computer science\",\n",
    "            \"Machine learning is a subset of AI\",\n",
    "            \"Deep learning uses neural networks\",\n",
    "            \"Natural language processing enables computers to understand human language\"\n",
    "        ]\n",
    "\n",
    "        doc_embeddings = embeddings.embed_documents(texts)\n",
    "        query_embedding = embeddings.embed_query(\"What is artificial intelligence?\")\n",
    "\n",
    "        print(f\"OpenAI嵌入维度: {len(doc_embeddings[0])}\")\n",
    "\n",
    "        # 2.2 不同OpenAI模型对比\n",
    "        print(\"\\n2.2 OpenAI模型对比\")\n",
    "        openai_models = [\n",
    "            (\"text-embedding-3-small\", 1536),\n",
    "            (\"text-embedding-3-large\", 3072),\n",
    "            (\"text-embedding-ada-002\", 1536)\n",
    "        ]\n",
    "\n",
    "        for model_name, default_dim in openai_models:\n",
    "            try:\n",
    "                model_embeddings = OpenAIEmbeddings(\n",
    "                    model=model_name,\n",
    "                    api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    "                )\n",
    "                test_embedding = model_embeddings.embed_query(\"test\")\n",
    "                print(f\"{model_name}: 维度 {len(test_embedding)}\")\n",
    "            except Exception as e:\n",
    "                print(f\"{model_name}: 不可用 ({str(e)[:50]}...)\")\n",
    "\n",
    "        # 2.3 自定义维度（仅支持text-embedding-3系列）\n",
    "        print(\"\\n2.3 自定义嵌入维度\")\n",
    "        try:\n",
    "            custom_embeddings = OpenAIEmbeddings(\n",
    "                model=\"text-embedding-3-large\",\n",
    "                dimensions=1024,  # 自定义维度\n",
    "                api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    "            )\n",
    "            custom_embedding = custom_embeddings.embed_query(\"自定义维度测试\")\n",
    "            print(f\"自定义维度嵌入: {len(custom_embedding)}\")\n",
    "        except Exception as e:\n",
    "            print(f\"自定义维度失败: {e}\")\n",
    "\n",
    "        return embeddings\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"OpenAI嵌入模型失败: {e}\")\n",
    "        print(\"请设置OPENAI_API_KEY环境变量\")\n",
    "        return None"
   ],
   "id": "ff95b065bdae4c17"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### HuggingFace嵌入模型示例",
   "id": "334b02a06201fb7a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "def huggingface_embeddings_example():\n",
    "    \"\"\"HuggingFace嵌入模型示例\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"3. HuggingFace嵌入模型示例\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # 3.1 基础HuggingFace嵌入\n",
    "    print(\"\\n3.1 基础HuggingFace嵌入\")\n",
    "    try:\n",
    "        # 使用预训练的sentence-transformers模型\n",
    "        embeddings = HuggingFaceEmbeddings(\n",
    "            model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "            model_kwargs={'device': 'cpu'},  # 或 'cuda' 如果有GPU\n",
    "            encode_kwargs={'normalize_embeddings': True}  # 标准化嵌入\n",
    "        )\n",
    "\n",
    "        texts = [\n",
    "            \"这是一个测试文档\",\n",
    "            \"人工智能技术发展迅速\",\n",
    "            \"机器学习算法很重要\"\n",
    "        ]\n",
    "\n",
    "        doc_embeddings = embeddings.embed_documents(texts)\n",
    "        query_embedding = embeddings.embed_query(\"AI技术\")\n",
    "\n",
    "        print(f\"HuggingFace嵌入维度: {len(doc_embeddings[0])}\")\n",
    "\n",
    "        # 3.2 中文优化模型\n",
    "        print(\"\\n3.2 中文优化嵌入模型\")\n",
    "        chinese_models = [\n",
    "            \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\",\n",
    "            \"sentence-transformers/distiluse-base-multilingual-cased\",\n",
    "            \"BAAI/bge-small-zh-v1.5\"  # 中文优化模型\n",
    "        ]\n",
    "\n",
    "        for model_name in chinese_models:\n",
    "            try:\n",
    "                chinese_embeddings = HuggingFaceEmbeddings(\n",
    "                    model_name=model_name,\n",
    "                    model_kwargs={'device': 'cpu'}\n",
    "                )\n",
    "                test_embedding = chinese_embeddings.embed_query(\"中文测试\")\n",
    "                print(f\"{model_name}: 维度 {len(test_embedding)}\")\n",
    "            except Exception as e:\n",
    "                print(f\"{model_name}: 加载失败 ({str(e)[:50]}...)\")\n",
    "\n",
    "        # 3.3 指令优化嵌入\n",
    "        print(\"\\n3.3 指令优化嵌入模型\")\n",
    "        try:\n",
    "            instruct_embeddings = HuggingFaceInstructEmbeddings(\n",
    "                model_name=\"hkunlp/instructor-xl\",\n",
    "                model_kwargs={'device': 'cpu'}\n",
    "            )\n",
    "\n",
    "            # 使用指令前缀\n",
    "            query_instruction = \"为这个查询找到最相关的文档: \"\n",
    "            doc_instruction = \"这是一个关于技术的文档: \"\n",
    "\n",
    "            instruct_query = instruct_embeddings.embed_query(\n",
    "                query_instruction + \"人工智能应用\"\n",
    "            )\n",
    "            print(f\"指令嵌入维度: {len(instruct_query)}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"指令嵌入模型加载失败: {e}\")\n",
    "\n",
    "        return embeddings\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"HuggingFace嵌入模型失败: {e}\")\n",
    "        return None"
   ],
   "id": "395eab448816770b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### SentenceTransformers嵌入模型示例",
   "id": "b75cf90894756952"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "def sentence_transformers_example():\n",
    "    \"\"\"SentenceTransformers嵌入模型示例\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"4. SentenceTransformers嵌入模型示例\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    try:\n",
    "        # 4.1 多语言模型\n",
    "        print(\"\\n4.1 多语言SentenceTransformers\")\n",
    "        multilingual_embeddings = SentenceTransformerEmbeddings(\n",
    "            model_name=\"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\"\n",
    "        )\n",
    "\n",
    "        # 多语言测试\n",
    "        multilingual_texts = [\n",
    "            \"Hello, how are you?\",\n",
    "            \"你好，你好吗？\",\n",
    "            \"Hola, ¿cómo estás?\",\n",
    "            \"Bonjour, comment allez-vous?\"\n",
    "        ]\n",
    "\n",
    "        multi_embeddings = multilingual_embeddings.embed_documents(multilingual_texts)\n",
    "        print(f\"多语言嵌入维度: {len(multi_embeddings[0])}\")\n",
    "\n",
    "        # 计算跨语言相似度\n",
    "        english_query = multilingual_embeddings.embed_query(\"greeting\")\n",
    "        chinese_query = multilingual_embeddings.embed_query(\"问候\")\n",
    "\n",
    "        def cosine_similarity(a, b):\n",
    "            return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "        cross_lang_similarity = cosine_similarity(english_query, chinese_query)\n",
    "        print(f\"跨语言相似度 (greeting vs 问候): {cross_lang_similarity:.4f}\")\n",
    "\n",
    "        # 4.2 专业领域模型\n",
    "        print(\"\\n4.2 专业领域嵌入模型\")\n",
    "        domain_models = [\n",
    "            \"sentence-transformers/all-mpnet-base-v2\",  # 通用\n",
    "            \"sentence-transformers/msmarco-distilbert-base-v4\",  # 搜索优化\n",
    "            \"sentence-transformers/nli-mpnet-base-v2\"  # 自然语言推理\n",
    "        ]\n",
    "\n",
    "        for model_name in domain_models:\n",
    "            try:\n",
    "                domain_embeddings = SentenceTransformerEmbeddings(model_name=model_name)\n",
    "                test_embedding = domain_embeddings.embed_query(\"domain test\")\n",
    "                print(f\"{model_name.split('/')[-1]}: 维度 {len(test_embedding)}\")\n",
    "            except Exception as e:\n",
    "                print(f\"{model_name}: 不可用\")\n",
    "\n",
    "        return multilingual_embeddings\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"SentenceTransformers失败: {e}\")\n",
    "        return None"
   ],
   "id": "8abba28e47559ba8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 云端嵌入模型示例",
   "id": "6b986e96796163bb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "def cloud_embeddings_example():\n",
    "    \"\"\"云端嵌入模型示例\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"5. 云端嵌入模型示例\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # 5.1 Cohere嵌入\n",
    "    print(\"\\n5.1 Cohere嵌入模型\")\n",
    "    try:\n",
    "        cohere_embeddings = CohereEmbeddings(\n",
    "            cohere_api_key=os.getenv(\"COHERE_API_KEY\"),\n",
    "            model=\"embed-english-v3.0\"  # 或 embed-multilingual-v3.0\n",
    "        )\n",
    "\n",
    "        cohere_texts = [\"AI technology\", \"Machine learning algorithms\"]\n",
    "        cohere_embeds = cohere_embeddings.embed_documents(cohere_texts)\n",
    "        print(f\"Cohere嵌入维度: {len(cohere_embeds[0])}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Cohere嵌入失败: {e}\")\n",
    "\n",
    "    # 5.2 AWS Bedrock嵌入\n",
    "    print(\"\\n5.2 AWS Bedrock嵌入模型\")\n",
    "    try:\n",
    "        bedrock_embeddings = BedrockEmbeddings(\n",
    "            credentials_profile_name=\"default\",\n",
    "            region_name=\"us-east-1\",\n",
    "            model_id=\"amazon.titan-embed-text-v1\"\n",
    "        )\n",
    "\n",
    "        bedrock_texts = [\"Cloud computing\", \"Serverless architecture\"]\n",
    "        bedrock_embeds = bedrock_embeddings.embed_documents(bedrock_texts)\n",
    "        print(f\"Bedrock嵌入维度: {len(bedrock_embeds[0])}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Bedrock嵌入失败: {e}\")"
   ],
   "id": "f315da9b9cabc7d3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 嵌入模型性能对比",
   "id": "3ebebe9c3f803e5e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "def embedding_performance_comparison():\n",
    "    \"\"\"嵌入模型性能对比\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"6. 嵌入模型性能对比\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # 测试文本\n",
    "    test_texts = [\n",
    "        \"人工智能技术正在快速发展\",\n",
    "        \"机器学习算法在各个领域都有应用\",\n",
    "        \"深度学习模型需要大量的训练数据\",\n",
    "        \"自然语言处理让计算机理解人类语言\",\n",
    "        \"计算机视觉技术可以识别图像中的物体\"\n",
    "    ]\n",
    "\n",
    "    test_query = \"AI技术的应用领域\"\n",
    "\n",
    "    # 定义要测试的模型\n",
    "    models_to_test = []\n",
    "\n",
    "    # Ollama模型\n",
    "    try:\n",
    "        ollama_model = OllamaEmbeddings(\n",
    "            base_url=\"http://localhost:11434\",\n",
    "            model=\"nomic-embed-text\"\n",
    "        )\n",
    "        models_to_test.append((\"Ollama-nomic\", ollama_model))\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # HuggingFace模型\n",
    "    try:\n",
    "        hf_model = HuggingFaceEmbeddings(\n",
    "            model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "        )\n",
    "        models_to_test.append((\"HF-MiniLM\", hf_model))\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # 性能测试\n",
    "    results = {}\n",
    "\n",
    "    for model_name, model in models_to_test:\n",
    "        try:\n",
    "            print(f\"\\n测试 {model_name}...\")\n",
    "\n",
    "            # 测试文档嵌入时间\n",
    "            start_time = time.time()\n",
    "            doc_embeddings = model.embed_documents(test_texts)\n",
    "            doc_time = time.time() - start_time\n",
    "\n",
    "            # 测试查询嵌入时间\n",
    "            start_time = time.time()\n",
    "            query_embedding = model.embed_query(test_query)\n",
    "            query_time = time.time() - start_time\n",
    "\n",
    "            # 计算相似度\n",
    "            similarities = []\n",
    "            for doc_emb in doc_embeddings:\n",
    "                sim = np.dot(query_embedding, doc_emb) / (\n",
    "                    np.linalg.norm(query_embedding) * np.linalg.norm(doc_emb)\n",
    "                )\n",
    "                similarities.append(sim)\n",
    "\n",
    "            results[model_name] = {\n",
    "                \"dimension\": len(doc_embeddings[0]),\n",
    "                \"doc_time\": doc_time,\n",
    "                \"query_time\": query_time,\n",
    "                \"avg_similarity\": np.mean(similarities),\n",
    "                \"max_similarity\": np.max(similarities)\n",
    "            }\n",
    "\n",
    "        except Exception as e:\n",
    "            results[model_name] = {\"error\": str(e)}\n",
    "\n",
    "    # 显示结果\n",
    "    print(\"\\n性能对比结果:\")\n",
    "    print(f\"{'模型':<15} {'维度':<8} {'文档时间(s)':<12} {'查询时间(s)':<12} {'平均相似度':<12} {'最高相似度':<12}\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    for model_name, result in results.items():\n",
    "        if \"error\" not in result:\n",
    "            print(f\"{model_name:<15} {result['dimension']:<8} {result['doc_time']:<12.4f} \"\n",
    "                  f\"{result['query_time']:<12.4f} {result['avg_similarity']:<12.4f} \"\n",
    "                  f\"{result['max_similarity']:<12.4f}\")\n",
    "        else:\n",
    "            print(f\"{model_name:<15} 错误: {result['error'][:50]}...\")"
   ],
   "id": "1b314261935393b3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 高级嵌入技术",
   "id": "d7337cc0e609f98d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "def advanced_embedding_techniques():\n",
    "    \"\"\"高级嵌入技术\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"7. 高级嵌入技术\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # 7.1 嵌入缓存\n",
    "    print(\"\\n7.1 嵌入缓存机制\")\n",
    "\n",
    "    class CachedEmbeddings:\n",
    "        \"\"\"带缓存的嵌入模型\"\"\"\n",
    "\n",
    "        def __init__(self, base_embeddings):\n",
    "            self.base_embeddings = base_embeddings\n",
    "            self.cache = {}\n",
    "\n",
    "        def embed_query(self, text: str) -> List[float]:\n",
    "            if text in self.cache:\n",
    "                print(f\"缓存命中: {text[:30]}...\")\n",
    "                return self.cache[text]\n",
    "\n",
    "            embedding = self.base_embeddings.embed_query(text)\n",
    "            self.cache[text] = embedding\n",
    "            print(f\"新计算: {text[:30]}...\")\n",
    "            return embedding\n",
    "\n",
    "        def embed_documents(self, texts: List[str]) -> List[List[float]]:\n",
    "            embeddings = []\n",
    "            for text in texts:\n",
    "                embeddings.append(self.embed_query(text))\n",
    "            return embeddings\n",
    "\n",
    "    # 使用缓存嵌入\n",
    "    try:\n",
    "        base_model = HuggingFaceEmbeddings(\n",
    "            model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "        )\n",
    "        cached_model = CachedEmbeddings(base_model)\n",
    "\n",
    "        # 第一次计算\n",
    "        test_texts = [\"AI技术\", \"机器学习\", \"AI技术\"]  # 重复文本\n",
    "        embeddings1 = cached_model.embed_documents(test_texts)\n",
    "\n",
    "        # 第二次计算（应该使用缓存）\n",
    "        embeddings2 = cached_model.embed_documents(test_texts)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"缓存嵌入示例失败: {e}\")\n",
    "\n",
    "    # 7.2 批量处理优化\n",
    "    print(\"\\n7.2 批量处理优化\")\n",
    "\n",
    "    def batch_embed_documents(embeddings_model, texts: List[str], batch_size: int = 32):\n",
    "        \"\"\"批量处理嵌入\"\"\"\n",
    "        all_embeddings = []\n",
    "\n",
    "        for i in range(0, len(texts), batch_size):\n",
    "            batch = texts[i:i + batch_size]\n",
    "            print(f\"处理批次 {i//batch_size + 1}: {len(batch)} 个文档\")\n",
    "\n",
    "            batch_embeddings = embeddings_model.embed_documents(batch)\n",
    "            all_embeddings.extend(batch_embeddings)\n",
    "\n",
    "        return all_embeddings\n",
    "\n",
    "    # 7.3 异步嵌入处理\n",
    "    print(\"\\n7.3 异步嵌入处理\")\n",
    "\n",
    "    async def async_embed_documents(embeddings_model, texts: List[str]):\n",
    "        \"\"\"异步处理嵌入\"\"\"\n",
    "        loop = asyncio.get_event_loop()\n",
    "\n",
    "        # 将文本分组\n",
    "        chunk_size = len(texts) // 4 + 1\n",
    "        tasks = []\n",
    "\n",
    "        for i in range(0, len(texts), chunk_size):\n",
    "            chunk = texts[i:i + chunk_size]\n",
    "            task = loop.run_in_executor(\n",
    "                None,\n",
    "                embeddings_model.embed_documents,\n",
    "                chunk\n",
    "            )\n",
    "            tasks.append(task)\n",
    "\n",
    "        # 等待所有任务完成\n",
    "        results = await asyncio.gather(*tasks)\n",
    "\n",
    "        # 合并结果\n",
    "        all_embeddings = []\n",
    "        for result in results:\n",
    "            all_embeddings.extend(result)\n",
    "\n",
    "        return all_embeddings"
   ],
   "id": "13a8746b7d065d9f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 嵌入质量评估",
   "id": "c7f06da450b1cc92"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "def embedding_quality_evaluation():\n",
    "    \"\"\"嵌入质量评估\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"8. 嵌入质量评估\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # 8.1 语义相似度测试\n",
    "    print(\"\\n8.1 语义相似度测试\")\n",
    "\n",
    "    # 定义测试用例\n",
    "    similarity_tests = [\n",
    "        (\"人工智能\", \"AI技术\", \"高相似度\"),\n",
    "        (\"机器学习\", \"深度学习\", \"中等相似度\"),\n",
    "        (\"计算机\", \"苹果\", \"低相似度\"),\n",
    "        (\"狗\", \"猫\", \"中等相似度\"),\n",
    "        (\"汽车\", \"飞机\", \"低相似度\")\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        embeddings = HuggingFaceEmbeddings(\n",
    "            model_name=\"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\"\n",
    "        )\n",
    "\n",
    "        print(\"语义相似度测试结果:\")\n",
    "        for text1, text2, expected in similarity_tests:\n",
    "            emb1 = embeddings.embed_query(text1)\n",
    "            emb2 = embeddings.embed_query(text2)\n",
    "\n",
    "            similarity = np.dot(emb1, emb2) / (np.linalg.norm(emb1) * np.linalg.norm(emb2))\n",
    "            print(f\"{text1} vs {text2}: {similarity:.4f} ({expected})\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"语义相似度测试失败: {e}\")\n",
    "\n",
    "    # 8.2 聚类质量评估\n",
    "    print(\"\\n8.2 聚类质量评估\")\n",
    "\n",
    "    def evaluate_clustering_quality(embeddings_model, texts: List[str], labels: List[str]):\n",
    "        \"\"\"评估聚类质量\"\"\"\n",
    "        try:\n",
    "            from sklearn.cluster import KMeans\n",
    "            from sklearn.metrics import adjusted_rand_score\n",
    "\n",
    "            # 生成嵌入\n",
    "            embeddings = embeddings_model.embed_documents(texts)\n",
    "            embeddings_array = np.array(embeddings)\n",
    "\n",
    "            # 执行聚类\n",
    "            n_clusters = len(set(labels))\n",
    "            kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "            predicted_labels = kmeans.fit_predict(embeddings_array)\n",
    "\n",
    "            # 计算调整兰德指数\n",
    "            ari_score = adjusted_rand_score(labels, predicted_labels)\n",
    "            print(f\"聚类质量 (ARI): {ari_score:.4f}\")\n",
    "\n",
    "            return ari_score\n",
    "\n",
    "        except ImportError:\n",
    "            print(\"需要安装scikit-learn: pip install scikit-learn\")\n",
    "        except Exception as e:\n",
    "            print(f\"聚类评估失败: {e}\")"
   ],
   "id": "62de51fc2e10a4e0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 自定义嵌入包装器",
   "id": "66c3a63584771c0f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "def custom_embedding_wrapper():\n",
    "    \"\"\"自定义嵌入包装器\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"9. 自定义嵌入包装器\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    from langchain_core.embeddings import Embeddings\n",
    "\n",
    "    class MultiModelEmbeddings(Embeddings):\n",
    "        \"\"\"多模型集成嵌入\"\"\"\n",
    "\n",
    "        def __init__(self, models: List[Embeddings], weights: Optional[List[float]] = None):\n",
    "            self.models = models\n",
    "            self.weights = weights or [1.0] * len(models)\n",
    "\n",
    "            # 标准化权重\n",
    "            total_weight = sum(self.weights)\n",
    "            self.weights = [w / total_weight for w in self.weights]\n",
    "\n",
    "        def embed_documents(self, texts: List[str]) -> List[List[float]]:\n",
    "            \"\"\"集成多个模型的文档嵌入\"\"\"\n",
    "            all_embeddings = []\n",
    "\n",
    "            # 获取每个模型的嵌入\n",
    "            model_embeddings = []\n",
    "            for model in self.models:\n",
    "                embeddings = model.embed_documents(texts)\n",
    "                model_embeddings.append(embeddings)\n",
    "\n",
    "            # 加权平均\n",
    "            for i in range(len(texts)):\n",
    "                combined_embedding = np.zeros(len(model_embeddings[0][i]))\n",
    "\n",
    "                for j, (embeddings, weight) in enumerate(zip(model_embeddings, self.weights)):\n",
    "                    combined_embedding += np.array(embeddings[i]) * weight\n",
    "\n",
    "                all_embeddings.append(combined_embedding.tolist())\n",
    "\n",
    "            return all_embeddings\n",
    "\n",
    "        def embed_query(self, text: str) -> List[float]:\n",
    "            \"\"\"集成多个模型的查询嵌入\"\"\"\n",
    "            embeddings = self.embed_documents([text])\n",
    "            return embeddings[0]\n",
    "\n",
    "    # 使用示例\n",
    "    try:\n",
    "        # 创建多个基础模型\n",
    "        model1 = HuggingFaceEmbeddings(\n",
    "            model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "        )\n",
    "\n",
    "        # 如果有多个模型可用\n",
    "        models = [model1]  # 可以添加更多模型\n",
    "        weights = [1.0]    # 对应的权重\n",
    "\n",
    "        multi_embeddings = MultiModelEmbeddings(models, weights)\n",
    "\n",
    "        test_text = \"多模型嵌入测试\"\n",
    "        result = multi_embeddings.embed_query(test_text)\n",
    "        print(f\"多模型嵌入维度: {len(result)}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"多模型嵌入失败: {e}\")"
   ],
   "id": "3cbc9a21bdf18a08"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "def main():\n",
    "    \"\"\"运行所有嵌入模型示例\"\"\"\n",
    "    print(\"🚀 LangChain 0.3 Embedding Models 完整示例\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # 运行所有示例\n",
    "    ollama_embeddings = ollama_embeddings_example()\n",
    "    openai_embeddings = openai_embeddings_example()\n",
    "    hf_embeddings = huggingface_embeddings_example()\n",
    "    st_embeddings = sentence_transformers_example()\n",
    "    cloud_embeddings_example()\n",
    "    embedding_performance_comparison()\n",
    "    advanced_embedding_techniques()\n",
    "    embedding_quality_evaluation()\n",
    "    custom_embedding_wrapper()\n",
    "\n",
    "    print(\"\\n🎉 所有嵌入模型示例运行完成！\")\n",
    "\n",
    "    # 最佳实践建议\n",
    "    print(\"\\n📋 嵌入模型选择建议:\")\n",
    "    print(\"1. 本地部署：Ollama + nomic-embed-text\")\n",
    "    print(\"2. 云端服务：OpenAI text-embedding-3-small\")\n",
    "    print(\"3. 开源方案：HuggingFace sentence-transformers\")\n",
    "    print(\"4. 中文优化：BAAI/bge-small-zh-v1.5\")\n",
    "    print(\"5. 多语言：paraphrase-multilingual-mpnet-base-v2\")\n",
    "    print(\"6. 高性能：text-embedding-3-large\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "id": "31b1c1b39e98e6bc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T06:54:26.718459Z",
     "start_time": "2025-07-23T06:54:26.199599Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "3. Embedding Models 嵌入模型示例\n",
      "============================================================\n",
      "\n",
      "3.1 Ollama嵌入模型\n",
      "文档嵌入数量: 4\n",
      "嵌入向量维度: 768\n",
      "查询嵌入维度: 768\n",
      "\n",
      "相似度计算:\n",
      "'人工智能是计算机科学的分支' 相似度: 0.8551\n",
      "'机器学习是AI的子集' 相似度: 0.6135\n",
      "'深度学习使用神经网络' 相似度: 0.5818\n",
      "'今天天气很好' 相似度: 0.5851\n"
     ]
    }
   ],
   "execution_count": 42,
   "source": [
    "# 3. Embedding Models 示例\n",
    "def embedding_models_example():\n",
    "    \"\"\"嵌入模型示例\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"3. Embedding Models 嵌入模型示例\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # 3.1 Ollama嵌入模型\n",
    "    print(\"\\n3.1 Ollama嵌入模型\")\n",
    "    try:\n",
    "        embeddings = OllamaEmbeddings(\n",
    "            base_url=\"http://localhost:11434\",\n",
    "            model=\"nomic-embed-text\"  # 或使用其他嵌入模型\n",
    "        )\n",
    "\n",
    "        # 测试文本\n",
    "        texts = [\n",
    "            \"人工智能是计算机科学的分支\",\n",
    "            \"机器学习是AI的子集\",\n",
    "            \"深度学习使用神经网络\",\n",
    "            \"今天天气很好\"\n",
    "        ]\n",
    "\n",
    "        # 生成嵌入向量\n",
    "        text_embeddings = embeddings.embed_documents(texts)\n",
    "        query_embedding = embeddings.embed_query(\"什么是人工智能？\")\n",
    "\n",
    "        print(f\"文档嵌入数量: {len(text_embeddings)}\")\n",
    "        print(f\"嵌入向量维度: {len(text_embeddings[0])}\")\n",
    "        print(f\"查询嵌入维度: {len(query_embedding)}\")\n",
    "\n",
    "        # 计算相似度\n",
    "        import numpy as np\n",
    "\n",
    "        def cosine_similarity(a, b):\n",
    "            return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "        print(\"\\n相似度计算:\")\n",
    "        for i, text in enumerate(texts):\n",
    "            similarity = cosine_similarity(query_embedding, text_embeddings[i])\n",
    "            print(f\"'{text}' 相似度: {similarity:.4f}\")\n",
    "\n",
    "        return embeddings\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Ollama嵌入模型初始化失败: {e}\")\n",
    "        print(\"请确保Ollama服务正在运行并安装了嵌入模型\")\n",
    "        return None\n",
    "# 3. 嵌入模型\n",
    "embeddings = embedding_models_example()"
   ],
   "id": "70e94f0eb1a52a05"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
