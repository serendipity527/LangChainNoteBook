{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Retrievers",
   "id": "852d03aebfae20f6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## å¯¼å…¥ä¾èµ–",
   "id": "b27e2954d9d5934"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T08:08:31.495639Z",
     "start_time": "2025-07-23T08:08:31.436979Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# LangChain 0.3 Retrievers å®Œæ•´æ•™ç¨‹\n",
    "\n",
    "import os\n",
    "from typing import List, Dict, Any, Optional\n",
    "import asyncio\n",
    "\n",
    "# è®¾ç½®ç¯å¢ƒå˜é‡\n",
    "os.environ[\"USER_AGENT\"] = \"LangChain-Tutorial/1.0 (Educational Purpose)\"\n",
    "\n",
    "# æ ¸å¿ƒå¯¼å…¥\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_ollama import OllamaEmbeddings, ChatOllama\n",
    "from langchain_community.vectorstores import FAISS, Chroma\n",
    "from langchain_core.documents import Document\n",
    "from langchain.retrievers import (\n",
    "    BM25Retriever,\n",
    "    EnsembleRetriever,\n",
    "    MultiQueryRetriever,\n",
    "    ContextualCompressionRetriever,\n",
    "    SelfQueryRetriever\n",
    ")\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
    "from langchain_community.retrievers import (\n",
    "    TFIDFRetriever,\n",
    "    SVMRetriever\n",
    ")\n",
    "\n",
    "print(\"âœ… æ‰€æœ‰åº“å¯¼å…¥æˆåŠŸ\")"
   ],
   "id": "67aa08b699383331",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… æ‰€æœ‰åº“å¯¼å…¥æˆåŠŸ\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1. å‡†å¤‡æµ‹è¯•æ•°æ®",
   "id": "6ade4f558b0479cb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T08:08:47.230390Z",
     "start_time": "2025-07-23T08:08:46.490631Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "## 1. å‡†å¤‡æµ‹è¯•æ•°æ®\n",
    "\n",
    "def prepare_test_data():\n",
    "    \"\"\"å‡†å¤‡æµ‹è¯•æ•°æ®\"\"\"\n",
    "    # åˆ›å»ºæµ‹è¯•æ–‡æ¡£\n",
    "    documents = [\n",
    "        Document(\n",
    "            page_content=\"äººå·¥æ™ºèƒ½æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œè‡´åŠ›äºåˆ›å»ºèƒ½å¤Ÿæ‰§è¡Œé€šå¸¸éœ€è¦äººç±»æ™ºèƒ½çš„ä»»åŠ¡çš„ç³»ç»Ÿã€‚\",\n",
    "            metadata={\"source\": \"ai_intro.txt\", \"category\": \"technology\"}\n",
    "        ),\n",
    "        Document(\n",
    "            page_content=\"æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªå­é›†ï¼Œä½¿è®¡ç®—æœºèƒ½å¤Ÿåœ¨æ²¡æœ‰æ˜ç¡®ç¼–ç¨‹çš„æƒ…å†µä¸‹å­¦ä¹ å’Œæ”¹è¿›ã€‚\",\n",
    "            metadata={\"source\": \"ml_intro.txt\", \"category\": \"technology\"}\n",
    "        ),\n",
    "        Document(\n",
    "            page_content=\"æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œä½¿ç”¨å¤šå±‚ç¥ç»ç½‘ç»œæ¥æ¨¡æ‹Ÿäººè„‘çš„å·¥ä½œæ–¹å¼ã€‚\",\n",
    "            metadata={\"source\": \"dl_intro.txt\", \"category\": \"technology\"}\n",
    "        ),\n",
    "        Document(\n",
    "            page_content=\"è‡ªç„¶è¯­è¨€å¤„ç†æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªé¢†åŸŸï¼Œä¸“æ³¨äºè®¡ç®—æœºä¸äººç±»è¯­è¨€ä¹‹é—´çš„äº¤äº’ã€‚\",\n",
    "            metadata={\"source\": \"nlp_intro.txt\", \"category\": \"technology\"}\n",
    "        ),\n",
    "        Document(\n",
    "            page_content=\"è®¡ç®—æœºè§†è§‰æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œä½¿è®¡ç®—æœºèƒ½å¤Ÿç†è§£å’Œè§£é‡Šè§†è§‰ä¿¡æ¯ã€‚\",\n",
    "            metadata={\"source\": \"cv_intro.txt\", \"category\": \"technology\"}\n",
    "        ),\n",
    "        Document(\n",
    "            page_content=\"ä»Šå¤©å¤©æ°”å¾ˆå¥½ï¼Œé˜³å…‰æ˜åªšï¼Œé€‚åˆæˆ·å¤–æ´»åŠ¨å’Œæ•£æ­¥ã€‚\",\n",
    "            metadata={\"source\": \"weather.txt\", \"category\": \"daily\"}\n",
    "        ),\n",
    "        Document(\n",
    "            page_content=\"Pythonæ˜¯ä¸€ç§é«˜çº§ç¼–ç¨‹è¯­è¨€ï¼Œå¹¿æ³›ç”¨äºæ•°æ®ç§‘å­¦ã€æœºå™¨å­¦ä¹ å’ŒWebå¼€å‘ã€‚\",\n",
    "            metadata={\"source\": \"python_intro.txt\", \"category\": \"programming\"}\n",
    "        ),\n",
    "        Document(\n",
    "            page_content=\"æ•°æ®ç§‘å­¦ç»“åˆäº†ç»Ÿè®¡å­¦ã€è®¡ç®—æœºç§‘å­¦å’Œé¢†åŸŸä¸“ä¸šçŸ¥è¯†æ¥ä»æ•°æ®ä¸­æå–æ´å¯Ÿã€‚\",\n",
    "            metadata={\"source\": \"ds_intro.txt\", \"category\": \"technology\"}\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # åˆå§‹åŒ–åµŒå…¥æ¨¡å‹\n",
    "    embeddings = OllamaEmbeddings(\n",
    "        base_url=\"http://localhost:11434\",\n",
    "        model=\"nomic-embed-text:latest\"\n",
    "    )\n",
    "\n",
    "    # åˆ›å»ºå‘é‡å­˜å‚¨\n",
    "    vectorstore = FAISS.from_documents(documents, embeddings)\n",
    "\n",
    "    return documents, vectorstore, embeddings\n",
    "\n",
    "\n",
    "# å‡†å¤‡æ•°æ®\n",
    "documents, vectorstore, embeddings = prepare_test_data()\n",
    "print(f\"âœ… å‡†å¤‡äº† {len(documents)} ä¸ªæµ‹è¯•æ–‡æ¡£\")"
   ],
   "id": "2f48fb6dd0d714e7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… å‡†å¤‡äº† 8 ä¸ªæµ‹è¯•æ–‡æ¡£\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2. å‘é‡å­˜å‚¨æ£€ç´¢å™¨",
   "id": "fd3eca30ec90ba0a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T08:14:48.540546Z",
     "start_time": "2025-07-23T08:14:48.121260Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "## 2. å‘é‡å­˜å‚¨æ£€ç´¢å™¨\n",
    "\n",
    "def vector_store_retriever_example():\n",
    "    \"\"\"å‘é‡å­˜å‚¨æ£€ç´¢å™¨ç¤ºä¾‹\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"2. å‘é‡å­˜å‚¨æ£€ç´¢å™¨ç¤ºä¾‹\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # 2.1 åŸºç¡€ç›¸ä¼¼æ€§æ£€ç´¢\n",
    "    print(\"\\n2.1 åŸºç¡€ç›¸ä¼¼æ€§æ£€ç´¢\")\n",
    "    retriever = vectorstore.as_retriever(\n",
    "        search_type=\"similarity\",\n",
    "        search_kwargs={\"k\": 3}\n",
    "    )\n",
    "\n",
    "    query = \"ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ \"\n",
    "    results = retriever.invoke(query)\n",
    "    print(f\"æŸ¥è¯¢: {query}\")\n",
    "    print(f\"æ£€ç´¢åˆ° {len(results)} ä¸ªç»“æœ:\")\n",
    "    for i, doc in enumerate(results):\n",
    "        print(f\"{i + 1}. {doc.page_content}\")\n",
    "        print(f\"   æ¥æº: {doc.metadata.get('source', 'unknown')}\")\n",
    "\n",
    "    # 2.2 ç›¸ä¼¼æ€§é˜ˆå€¼æ£€ç´¢\n",
    "    print(\"\\n2.2 ç›¸ä¼¼æ€§é˜ˆå€¼æ£€ç´¢\")\n",
    "    threshold_retriever = vectorstore.as_retriever(\n",
    "        search_type=\"similarity_score_threshold\",\n",
    "        search_kwargs={\"score_threshold\": 0.5, \"k\": 5}\n",
    "    )\n",
    "\n",
    "    results = threshold_retriever.invoke(\"æ·±åº¦å­¦ä¹ ç¥ç»ç½‘ç»œ\")\n",
    "    print(f\"é˜ˆå€¼æ£€ç´¢ç»“æœæ•°é‡: {len(results)}\")\n",
    "\n",
    "    # 2.3 MMRæ£€ç´¢ï¼ˆæœ€å¤§è¾¹é™…ç›¸å…³æ€§ï¼‰\n",
    "    print(\"\\n2.3 MMRæ£€ç´¢\")\n",
    "    mmr_retriever = vectorstore.as_retriever(\n",
    "        search_type=\"mmr\",\n",
    "        search_kwargs={\"k\": 3, \"fetch_k\": 6, \"lambda_mult\": 0.5}\n",
    "    )\n",
    "\n",
    "    results = mmr_retriever.invoke(\"äººå·¥æ™ºèƒ½æŠ€æœ¯\")\n",
    "    print(f\"MMRæ£€ç´¢ç»“æœæ•°é‡: {len(results)}\")\n",
    "\n",
    "    return retriever\n",
    "\n",
    "\n",
    "vector_retriever = vector_store_retriever_example()"
   ],
   "id": "d4916271dcbf7e32",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "2. å‘é‡å­˜å‚¨æ£€ç´¢å™¨ç¤ºä¾‹\n",
      "============================================================\n",
      "\n",
      "2.1 åŸºç¡€ç›¸ä¼¼æ€§æ£€ç´¢\n",
      "æŸ¥è¯¢: ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ \n",
      "æ£€ç´¢åˆ° 3 ä¸ªç»“æœ:\n",
      "1. æ•°æ®ç§‘å­¦ç»“åˆäº†ç»Ÿè®¡å­¦ã€è®¡ç®—æœºç§‘å­¦å’Œé¢†åŸŸä¸“ä¸šçŸ¥è¯†æ¥ä»æ•°æ®ä¸­æå–æ´å¯Ÿã€‚\n",
      "   æ¥æº: ds_intro.txt\n",
      "2. æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œä½¿ç”¨å¤šå±‚ç¥ç»ç½‘ç»œæ¥æ¨¡æ‹Ÿäººè„‘çš„å·¥ä½œæ–¹å¼ã€‚\n",
      "   æ¥æº: dl_intro.txt\n",
      "3. æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªå­é›†ï¼Œä½¿è®¡ç®—æœºèƒ½å¤Ÿåœ¨æ²¡æœ‰æ˜ç¡®ç¼–ç¨‹çš„æƒ…å†µä¸‹å­¦ä¹ å’Œæ”¹è¿›ã€‚\n",
      "   æ¥æº: ml_intro.txt\n",
      "\n",
      "2.2 ç›¸ä¼¼æ€§é˜ˆå€¼æ£€ç´¢\n",
      "é˜ˆå€¼æ£€ç´¢ç»“æœæ•°é‡: 5\n",
      "\n",
      "2.3 MMRæ£€ç´¢\n",
      "MMRæ£€ç´¢ç»“æœæ•°é‡: 3\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3. BM25æ£€ç´¢å™¨",
   "id": "64c0fee40a516afd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T08:15:10.969043Z",
     "start_time": "2025-07-23T08:15:10.962373Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "## 3. BM25æ£€ç´¢å™¨\n",
    "\n",
    "def bm25_retriever_example():\n",
    "    \"\"\"BM25æ£€ç´¢å™¨ç¤ºä¾‹\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"3. BM25æ£€ç´¢å™¨ç¤ºä¾‹\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # 3.1 åŸºç¡€BM25æ£€ç´¢\n",
    "    print(\"\\n3.1 åŸºç¡€BM25æ£€ç´¢\")\n",
    "    bm25_retriever = BM25Retriever.from_documents(documents)\n",
    "    bm25_retriever.k = 3\n",
    "\n",
    "    query = \"æœºå™¨å­¦ä¹ ç®—æ³•\"\n",
    "    results = bm25_retriever.invoke(query)\n",
    "    print(f\"æŸ¥è¯¢: {query}\")\n",
    "    print(f\"BM25æ£€ç´¢åˆ° {len(results)} ä¸ªç»“æœ:\")\n",
    "    for i, doc in enumerate(results):\n",
    "        print(f\"{i + 1}. {doc.page_content[:80]}...\")\n",
    "\n",
    "    # 3.2 è‡ªå®šä¹‰BM25å‚æ•°\n",
    "    print(\"\\n3.2 è‡ªå®šä¹‰BM25å‚æ•°\")\n",
    "    custom_bm25 = BM25Retriever.from_documents(\n",
    "        documents,\n",
    "        k=2,\n",
    "        # BM25å‚æ•°å¯ä»¥é€šè¿‡åº•å±‚åº“è°ƒæ•´\n",
    "    )\n",
    "\n",
    "    results = custom_bm25.invoke(\"äººå·¥æ™ºèƒ½å‘å±•\")\n",
    "    print(f\"è‡ªå®šä¹‰BM25æ£€ç´¢ç»“æœæ•°é‡: {len(results)}\")\n",
    "\n",
    "    return bm25_retriever\n",
    "\n",
    "\n",
    "bm25_retriever = bm25_retriever_example()\n"
   ],
   "id": "2476a832ad18fdba",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "3. BM25æ£€ç´¢å™¨ç¤ºä¾‹\n",
      "============================================================\n",
      "\n",
      "3.1 åŸºç¡€BM25æ£€ç´¢\n",
      "æŸ¥è¯¢: æœºå™¨å­¦ä¹ ç®—æ³•\n",
      "BM25æ£€ç´¢åˆ° 3 ä¸ªç»“æœ:\n",
      "1. æ•°æ®ç§‘å­¦ç»“åˆäº†ç»Ÿè®¡å­¦ã€è®¡ç®—æœºç§‘å­¦å’Œé¢†åŸŸä¸“ä¸šçŸ¥è¯†æ¥ä»æ•°æ®ä¸­æå–æ´å¯Ÿã€‚...\n",
      "2. Pythonæ˜¯ä¸€ç§é«˜çº§ç¼–ç¨‹è¯­è¨€ï¼Œå¹¿æ³›ç”¨äºæ•°æ®ç§‘å­¦ã€æœºå™¨å­¦ä¹ å’ŒWebå¼€å‘ã€‚...\n",
      "3. ä»Šå¤©å¤©æ°”å¾ˆå¥½ï¼Œé˜³å…‰æ˜åªšï¼Œé€‚åˆæˆ·å¤–æ´»åŠ¨å’Œæ•£æ­¥ã€‚...\n",
      "\n",
      "3.2 è‡ªå®šä¹‰BM25å‚æ•°\n",
      "è‡ªå®šä¹‰BM25æ£€ç´¢ç»“æœæ•°é‡: 2\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4. é›†æˆæ£€ç´¢å™¨",
   "id": "ba1747643c9e9824"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T08:38:36.760497Z",
     "start_time": "2025-07-23T08:38:36.407150Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "## 4. é›†æˆæ£€ç´¢å™¨\n",
    "\n",
    "def ensemble_retriever_example():\n",
    "    \"\"\"é›†æˆæ£€ç´¢å™¨ç¤ºä¾‹\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"4. é›†æˆæ£€ç´¢å™¨ç¤ºä¾‹\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # 4.1 å‘é‡+BM25é›†æˆ\n",
    "    print(\"\\n4.1 å‘é‡+BM25é›†æˆæ£€ç´¢\")\n",
    "    ensemble_retriever = EnsembleRetriever(\n",
    "        retrievers=[vector_retriever, bm25_retriever],\n",
    "        weights=[0.7, 0.3]  # å‘é‡æœç´¢æƒé‡70%ï¼ŒBM25æƒé‡30%\n",
    "    )\n",
    "\n",
    "    query = \"æ·±åº¦å­¦ä¹ ç¥ç»ç½‘ç»œ\"\n",
    "    results = ensemble_retriever.invoke(query)\n",
    "    print(f\"æŸ¥è¯¢: {query}\")\n",
    "    print(f\"é›†æˆæ£€ç´¢åˆ° {len(results)} ä¸ªç»“æœ:\")\n",
    "    for i, doc in enumerate(results):\n",
    "        print(f\"{i + 1}. {doc.page_content[:80]}...\")\n",
    "\n",
    "    # 4.2 å¤šç§æ£€ç´¢å™¨é›†æˆ\n",
    "    print(\"\\n4.2 å¤šç§æ£€ç´¢å™¨é›†æˆ\")\n",
    "    try:\n",
    "        # æ·»åŠ TF-IDFæ£€ç´¢å™¨\n",
    "        tfidf_retriever = TFIDFRetriever.from_documents(documents)\n",
    "        tfidf_retriever.k = 3\n",
    "\n",
    "        multi_ensemble = EnsembleRetriever(\n",
    "            retrievers=[vector_retriever, bm25_retriever, tfidf_retriever],\n",
    "            weights=[0.5, 0.3, 0.2]\n",
    "        )\n",
    "\n",
    "        results = multi_ensemble.invoke(\"è®¡ç®—æœºè§†è§‰æŠ€æœ¯\")\n",
    "        print(f\"å¤šé‡é›†æˆæ£€ç´¢ç»“æœæ•°é‡: {len(results)}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"å¤šé‡é›†æˆæ£€ç´¢å™¨åˆ›å»ºå¤±è´¥: {e}\")\n",
    "\n",
    "    return ensemble_retriever\n",
    "\n",
    "\n",
    "ensemble_retriever = ensemble_retriever_example()\n"
   ],
   "id": "3de08feedbddba83",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "4. é›†æˆæ£€ç´¢å™¨ç¤ºä¾‹\n",
      "============================================================\n",
      "\n",
      "4.1 å‘é‡+BM25é›†æˆæ£€ç´¢\n",
      "æŸ¥è¯¢: æ·±åº¦å­¦ä¹ ç¥ç»ç½‘ç»œ\n",
      "é›†æˆæ£€ç´¢åˆ° 5 ä¸ªç»“æœ:\n",
      "1. æ•°æ®ç§‘å­¦ç»“åˆäº†ç»Ÿè®¡å­¦ã€è®¡ç®—æœºç§‘å­¦å’Œé¢†åŸŸä¸“ä¸šçŸ¥è¯†æ¥ä»æ•°æ®ä¸­æå–æ´å¯Ÿã€‚...\n",
      "2. æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œä½¿ç”¨å¤šå±‚ç¥ç»ç½‘ç»œæ¥æ¨¡æ‹Ÿäººè„‘çš„å·¥ä½œæ–¹å¼ã€‚...\n",
      "3. æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªå­é›†ï¼Œä½¿è®¡ç®—æœºèƒ½å¤Ÿåœ¨æ²¡æœ‰æ˜ç¡®ç¼–ç¨‹çš„æƒ…å†µä¸‹å­¦ä¹ å’Œæ”¹è¿›ã€‚...\n",
      "4. Pythonæ˜¯ä¸€ç§é«˜çº§ç¼–ç¨‹è¯­è¨€ï¼Œå¹¿æ³›ç”¨äºæ•°æ®ç§‘å­¦ã€æœºå™¨å­¦ä¹ å’ŒWebå¼€å‘ã€‚...\n",
      "5. ä»Šå¤©å¤©æ°”å¾ˆå¥½ï¼Œé˜³å…‰æ˜åªšï¼Œé€‚åˆæˆ·å¤–æ´»åŠ¨å’Œæ•£æ­¥ã€‚...\n",
      "\n",
      "4.2 å¤šç§æ£€ç´¢å™¨é›†æˆ\n",
      "å¤šé‡é›†æˆæ£€ç´¢å™¨åˆ›å»ºå¤±è´¥: Could not import scikit-learn, please install with `pip install scikit-learn`.\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 5. å¤šæŸ¥è¯¢æ£€ç´¢å™¨",
   "id": "31ecd50dadce7ef7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "## 5. å¤šæŸ¥è¯¢æ£€ç´¢å™¨\n",
    "\n",
    "def multi_query_retriever_example():\n",
    "    \"\"\"å¤šæŸ¥è¯¢æ£€ç´¢å™¨ç¤ºä¾‹\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"5. å¤šæŸ¥è¯¢æ£€ç´¢å™¨ç¤ºä¾‹\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    try:\n",
    "        # åˆå§‹åŒ–LLM\n",
    "        llm = ChatOllama(\n",
    "            base_url=\"http://localhost:11434\",\n",
    "            model=\"qwen2.5:3b\",\n",
    "            temperature=0.1\n",
    "        )\n",
    "\n",
    "        # 5.1 åŸºç¡€å¤šæŸ¥è¯¢æ£€ç´¢\n",
    "        print(\"\\n5.1 åŸºç¡€å¤šæŸ¥è¯¢æ£€ç´¢\")\n",
    "        multi_query_retriever = MultiQueryRetriever.from_llm(\n",
    "            retriever=vector_retriever,\n",
    "            llm=llm\n",
    "        )\n",
    "\n",
    "        query = \"AIçš„åº”ç”¨é¢†åŸŸ\"\n",
    "        results = multi_query_retriever.invoke(query)\n",
    "        print(f\"æŸ¥è¯¢: {query}\")\n",
    "        print(f\"å¤šæŸ¥è¯¢æ£€ç´¢åˆ° {len(results)} ä¸ªç»“æœ:\")\n",
    "        for i, doc in enumerate(results):\n",
    "            print(f\"{i + 1}. {doc.page_content[:80]}...\")\n",
    "\n",
    "        # 5.2 è‡ªå®šä¹‰æŸ¥è¯¢ç”Ÿæˆ\n",
    "        print(\"\\n5.2 è‡ªå®šä¹‰æŸ¥è¯¢ç”Ÿæˆ\")\n",
    "        from langchain.prompts import PromptTemplate\n",
    "\n",
    "        custom_prompt = PromptTemplate(\n",
    "            input_variables=[\"question\"],\n",
    "            template=\"\"\"ä½ æ˜¯ä¸€ä¸ªAIåŠ©æ‰‹ã€‚ç»™å®šä¸€ä¸ªç”¨æˆ·é—®é¢˜ï¼Œç”Ÿæˆ3ä¸ªä¸åŒçš„æœç´¢æŸ¥è¯¢æ¥æ£€ç´¢ç›¸å…³ä¿¡æ¯ã€‚\n",
    "\n",
    "åŸå§‹é—®é¢˜: {question}\n",
    "\n",
    "ç”Ÿæˆ3ä¸ªç›¸å…³çš„æœç´¢æŸ¥è¯¢:\n",
    "1.\"\"\"\n",
    "        )\n",
    "\n",
    "        custom_multi_retriever = MultiQueryRetriever.from_llm(\n",
    "            retriever=vector_retriever,\n",
    "            llm=llm,\n",
    "            prompt=custom_prompt\n",
    "        )\n",
    "\n",
    "        results = custom_multi_retriever.invoke(\"æœºå™¨å­¦ä¹ çš„å‘å±•å†å²\")\n",
    "        print(f\"è‡ªå®šä¹‰å¤šæŸ¥è¯¢æ£€ç´¢ç»“æœæ•°é‡: {len(results)}\")\n",
    "\n",
    "        return multi_query_retriever\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"å¤šæŸ¥è¯¢æ£€ç´¢å™¨åˆ›å»ºå¤±è´¥: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "multi_query_retriever = multi_query_retriever_example()"
   ],
   "id": "7b80708d5ceaa098",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 6. ä¸Šä¸‹æ–‡å‹ç¼©æ£€ç´¢å™¨",
   "id": "f0eb04dcc556f9e3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T08:39:01.331055Z",
     "start_time": "2025-07-23T08:39:01.245887Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "## 6. ä¸Šä¸‹æ–‡å‹ç¼©æ£€ç´¢å™¨\n",
    "\n",
    "def contextual_compression_retriever_example():\n",
    "    \"\"\"ä¸Šä¸‹æ–‡å‹ç¼©æ£€ç´¢å™¨ç¤ºä¾‹\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"6. ä¸Šä¸‹æ–‡å‹ç¼©æ£€ç´¢å™¨ç¤ºä¾‹\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    try:\n",
    "        llm = ChatOllama(\n",
    "            base_url=\"http://localhost:11434\",\n",
    "            model=\"qwen2.5:3b\",\n",
    "            temperature=0\n",
    "        )\n",
    "\n",
    "        # 6.1 LLMé“¾æå–å™¨\n",
    "        print(\"\\n6.1 LLMé“¾æå–å™¨\")\n",
    "        compressor = LLMChainExtractor.from_llm(llm)\n",
    "        compression_retriever = ContextualCompressionRetriever(\n",
    "            base_compressor=compressor,\n",
    "            base_retriever=vector_retriever\n",
    "        )\n",
    "\n",
    "        query = \"ä»€ä¹ˆæ˜¯æ·±åº¦å­¦ä¹ \"\n",
    "        compressed_docs = compression_retriever.invoke(query)\n",
    "        print(f\"æŸ¥è¯¢: {query}\")\n",
    "        print(f\"å‹ç¼©åæ–‡æ¡£æ•°é‡: {len(compressed_docs)}\")\n",
    "        for i, doc in enumerate(compressed_docs):\n",
    "            print(f\"{i + 1}. {doc.page_content}\")\n",
    "\n",
    "        return compression_retriever\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"ä¸Šä¸‹æ–‡å‹ç¼©æ£€ç´¢å™¨åˆ›å»ºå¤±è´¥: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "compression_retriever = contextual_compression_retriever_example()\n"
   ],
   "id": "9e1d90ce02d87850",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "6. ä¸Šä¸‹æ–‡å‹ç¼©æ£€ç´¢å™¨ç¤ºä¾‹\n",
      "============================================================\n",
      "\n",
      "6.1 LLMé“¾æå–å™¨\n",
      "ä¸Šä¸‹æ–‡å‹ç¼©æ£€ç´¢å™¨åˆ›å»ºå¤±è´¥: model \"qwen2.5:3b\" not found, try pulling it first (status code: 404)\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 7. è‡ªæŸ¥è¯¢æ£€ç´¢å™¨",
   "id": "e4e6af1e47e5a595"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T08:39:17.097050Z",
     "start_time": "2025-07-23T08:39:17.040684Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "## 7. è‡ªæŸ¥è¯¢æ£€ç´¢å™¨\n",
    "\n",
    "def self_query_retriever_example():\n",
    "    \"\"\"è‡ªæŸ¥è¯¢æ£€ç´¢å™¨ç¤ºä¾‹\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"7. è‡ªæŸ¥è¯¢æ£€ç´¢å™¨ç¤ºä¾‹\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    try:\n",
    "        from langchain.chains.query_constructor.base import AttributeInfo\n",
    "        from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "        from langchain.chains.query_constructor.base import (\n",
    "            StructuredQueryOutputParser,\n",
    "            get_query_constructor_prompt,\n",
    "        )\n",
    "\n",
    "        llm = ChatOllama(\n",
    "            base_url=\"http://localhost:11434\",\n",
    "            model=\"qwen2.5:3b\",\n",
    "            temperature=0\n",
    "        )\n",
    "\n",
    "        # å®šä¹‰å…ƒæ•°æ®å±æ€§\n",
    "        metadata_field_info = [\n",
    "            AttributeInfo(\n",
    "                name=\"source\",\n",
    "                description=\"æ–‡æ¡£çš„æ¥æºæ–‡ä»¶å\",\n",
    "                type=\"string\",\n",
    "            ),\n",
    "            AttributeInfo(\n",
    "                name=\"category\",\n",
    "                description=\"æ–‡æ¡£çš„åˆ†ç±»\",\n",
    "                type=\"string\",\n",
    "            ),\n",
    "        ]\n",
    "\n",
    "        document_content_description = \"å…³äºäººå·¥æ™ºèƒ½ã€æœºå™¨å­¦ä¹ ç­‰æŠ€æœ¯çš„æ–‡æ¡£\"\n",
    "\n",
    "        # åˆ›å»ºè‡ªæŸ¥è¯¢æ£€ç´¢å™¨\n",
    "        self_query_retriever = SelfQueryRetriever.from_llm(\n",
    "            llm,\n",
    "            vectorstore,\n",
    "            document_content_description,\n",
    "            metadata_field_info,\n",
    "            verbose=True\n",
    "        )\n",
    "\n",
    "        # æµ‹è¯•æŸ¥è¯¢\n",
    "        query = \"æ‰¾åˆ°æ‰€æœ‰å…³äºtechnologyåˆ†ç±»çš„æ–‡æ¡£\"\n",
    "        results = self_query_retriever.invoke(query)\n",
    "        print(f\"æŸ¥è¯¢: {query}\")\n",
    "        print(f\"è‡ªæŸ¥è¯¢æ£€ç´¢åˆ° {len(results)} ä¸ªç»“æœ:\")\n",
    "        for i, doc in enumerate(results):\n",
    "            print(f\"{i + 1}. {doc.page_content[:80]}...\")\n",
    "            print(f\"   åˆ†ç±»: {doc.metadata.get('category')}\")\n",
    "\n",
    "        return self_query_retriever\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"è‡ªæŸ¥è¯¢æ£€ç´¢å™¨åˆ›å»ºå¤±è´¥: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "self_query_retriever = self_query_retriever_example()"
   ],
   "id": "fece772b7d3f8380",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "7. è‡ªæŸ¥è¯¢æ£€ç´¢å™¨ç¤ºä¾‹\n",
      "============================================================\n",
      "è‡ªæŸ¥è¯¢æ£€ç´¢å™¨åˆ›å»ºå¤±è´¥: Self query retriever with Vector Store type <class 'langchain_community.vectorstores.faiss.FAISS'> not supported.\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 8. å¼‚æ­¥æ£€ç´¢ç¤ºä¾‹",
   "id": "8dc7bb98cdd5bc5f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "\n",
    "## 8. å¼‚æ­¥æ£€ç´¢ç¤ºä¾‹\n",
    "\n",
    "async def async_retrieval_example():\n",
    "    \"\"\"å¼‚æ­¥æ£€ç´¢ç¤ºä¾‹\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"8. å¼‚æ­¥æ£€ç´¢ç¤ºä¾‹\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # 8.1 å¼‚æ­¥å•ä¸ªæ£€ç´¢\n",
    "    print(\"\\n8.1 å¼‚æ­¥å•ä¸ªæ£€ç´¢\")\n",
    "    query = \"äººå·¥æ™ºèƒ½çš„å®šä¹‰\"\n",
    "    result = await vector_retriever.ainvoke(query)\n",
    "    print(f\"å¼‚æ­¥æ£€ç´¢ç»“æœæ•°é‡: {len(result)}\")\n",
    "\n",
    "    # 8.2 å¼‚æ­¥æ‰¹é‡æ£€ç´¢\n",
    "    print(\"\\n8.2 å¼‚æ­¥æ‰¹é‡æ£€ç´¢\")\n",
    "    queries = [\n",
    "        \"æœºå™¨å­¦ä¹ ç®—æ³•\",\n",
    "        \"æ·±åº¦å­¦ä¹ ç½‘ç»œ\",\n",
    "        \"è‡ªç„¶è¯­è¨€å¤„ç†\"\n",
    "    ]\n",
    "\n",
    "    batch_results = await vector_retriever.abatch(queries)\n",
    "    print(f\"æ‰¹é‡æ£€ç´¢äº† {len(queries)} ä¸ªæŸ¥è¯¢\")\n",
    "    for i, results in enumerate(batch_results):\n",
    "        print(f\"æŸ¥è¯¢ {i + 1}: {len(results)} ä¸ªç»“æœ\")\n",
    "\n",
    "\n",
    "# è¿è¡Œå¼‚æ­¥ç¤ºä¾‹\n",
    "await async_retrieval_example()"
   ],
   "id": "8abf696ed91a7d54",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "## 9. è‡ªå®šä¹‰æ£€ç´¢å™¨\n",
    "\n",
    "from langchain_core.retrievers import BaseRetriever\n",
    "from langchain_core.documents import Document\n",
    "from typing import List\n",
    "\n",
    "\n",
    "class CustomKeywordRetriever(BaseRetriever):\n",
    "    \"\"\"è‡ªå®šä¹‰å…³é”®è¯æ£€ç´¢å™¨\"\"\"\n",
    "\n",
    "    documents: List[Document]\n",
    "    k: int = 3\n",
    "\n",
    "    def _get_relevant_documents(self, query: str) -> List[Document]:\n",
    "        \"\"\"æ£€ç´¢ç›¸å…³æ–‡æ¡£\"\"\"\n",
    "        query_words = set(query.lower().split())\n",
    "        scored_docs = []\n",
    "\n",
    "        for doc in self.documents:\n",
    "            content_words = set(doc.page_content.lower().split())\n",
    "            score = len(query_words.intersection(content_words))\n",
    "            if score > 0:\n",
    "                scored_docs.append((doc, score))\n",
    "\n",
    "        # æŒ‰åˆ†æ•°æ’åºå¹¶è¿”å›å‰kä¸ª\n",
    "        scored_docs.sort(key=lambda x: x[1], reverse=True)\n",
    "        return [doc for doc, score in scored_docs[:self.k]]\n",
    "\n",
    "\n",
    "def custom_retriever_example():\n",
    "    \"\"\"è‡ªå®šä¹‰æ£€ç´¢å™¨ç¤ºä¾‹\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"9. è‡ªå®šä¹‰æ£€ç´¢å™¨ç¤ºä¾‹\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # åˆ›å»ºè‡ªå®šä¹‰æ£€ç´¢å™¨\n",
    "    custom_retriever = CustomKeywordRetriever(\n",
    "        documents=documents,\n",
    "        k=3\n",
    "    )\n",
    "\n",
    "    query = \"æœºå™¨å­¦ä¹ äººå·¥æ™ºèƒ½\"\n",
    "    results = custom_retriever.invoke(query)\n",
    "    print(f\"æŸ¥è¯¢: {query}\")\n",
    "    print(f\"è‡ªå®šä¹‰æ£€ç´¢åˆ° {len(results)} ä¸ªç»“æœ:\")\n",
    "    for i, doc in enumerate(results):\n",
    "        print(f\"{i + 1}. {doc.page_content[:80]}...\")\n",
    "\n",
    "\n",
    "custom_retriever_example()"
   ],
   "id": "7582e029861a1240",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "## 10. æ£€ç´¢å™¨æ€§èƒ½æ¯”è¾ƒ\n",
    "\n",
    "import time\n",
    "\n",
    "\n",
    "def performance_comparison():\n",
    "    \"\"\"æ£€ç´¢å™¨æ€§èƒ½æ¯”è¾ƒ\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"10. æ£€ç´¢å™¨æ€§èƒ½æ¯”è¾ƒ\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    query = \"æ·±åº¦å­¦ä¹ ç¥ç»ç½‘ç»œ\"\n",
    "    retrievers = {\n",
    "        \"å‘é‡æ£€ç´¢\": vector_retriever,\n",
    "        \"BM25æ£€ç´¢\": bm25_retriever,\n",
    "        \"é›†æˆæ£€ç´¢\": ensemble_retriever,\n",
    "    }\n",
    "\n",
    "    if multi_query_retriever:\n",
    "        retrievers[\"å¤šæŸ¥è¯¢æ£€ç´¢\"] = multi_query_retriever\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    for name, retriever in retrievers.items():\n",
    "        try:\n",
    "            start_time = time.time()\n",
    "            docs = retriever.invoke(query)\n",
    "            end_time = time.time()\n",
    "\n",
    "            results[name] = {\n",
    "                \"æ—¶é—´\": f\"{(end_time - start_time):.3f}ç§’\",\n",
    "                \"ç»“æœæ•°\": len(docs),\n",
    "                \"é¦–ä¸ªç»“æœ\": docs[0].page_content[:50] + \"...\" if docs else \"æ— ç»“æœ\"\n",
    "            }\n",
    "        except Exception as e:\n",
    "            results[name] = {\"é”™è¯¯\": str(e)}\n",
    "\n",
    "    print(f\"æŸ¥è¯¢: {query}\")\n",
    "    print(\"\\næ€§èƒ½æ¯”è¾ƒç»“æœ:\")\n",
    "    for name, result in results.items():\n",
    "        print(f\"\\n{name}:\")\n",
    "        for key, value in result.items():\n",
    "            print(f\"  {key}: {value}\")\n",
    "\n",
    "\n",
    "performance_comparison()\n"
   ],
   "id": "e1355cf19c7bc50a",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "3. BM25æ£€ç´¢å™¨ç¤ºä¾‹\n",
      "============================================================\n",
      "\n",
      "3.1 åŸºç¡€BM25æ£€ç´¢\n",
      "æŸ¥è¯¢: æœºå™¨å­¦ä¹ ç®—æ³•\n",
      "BM25æ£€ç´¢åˆ° 3 ä¸ªç»“æœ:\n",
      "1. æ•°æ®ç§‘å­¦ç»“åˆäº†ç»Ÿè®¡å­¦ã€è®¡ç®—æœºç§‘å­¦å’Œé¢†åŸŸä¸“ä¸šçŸ¥è¯†æ¥ä»æ•°æ®ä¸­æå–æ´å¯Ÿã€‚...\n",
      "2. Pythonæ˜¯ä¸€ç§é«˜çº§ç¼–ç¨‹è¯­è¨€ï¼Œå¹¿æ³›ç”¨äºæ•°æ®ç§‘å­¦ã€æœºå™¨å­¦ä¹ å’ŒWebå¼€å‘ã€‚...\n",
      "3. ä»Šå¤©å¤©æ°”å¾ˆå¥½ï¼Œé˜³å…‰æ˜åªšï¼Œé€‚åˆæˆ·å¤–æ´»åŠ¨å’Œæ•£æ­¥ã€‚...\n",
      "\n",
      "3.2 è‡ªå®šä¹‰BM25å‚æ•°\n",
      "è‡ªå®šä¹‰BM25æ£€ç´¢ç»“æœæ•°é‡: 2\n",
      "\n",
      "============================================================\n",
      "4. é›†æˆæ£€ç´¢å™¨ç¤ºä¾‹\n",
      "============================================================\n",
      "\n",
      "4.1 å‘é‡+BM25é›†æˆæ£€ç´¢\n",
      "æŸ¥è¯¢: æ·±åº¦å­¦ä¹ ç¥ç»ç½‘ç»œ\n",
      "é›†æˆæ£€ç´¢åˆ° 5 ä¸ªç»“æœ:\n",
      "1. æ•°æ®ç§‘å­¦ç»“åˆäº†ç»Ÿè®¡å­¦ã€è®¡ç®—æœºç§‘å­¦å’Œé¢†åŸŸä¸“ä¸šçŸ¥è¯†æ¥ä»æ•°æ®ä¸­æå–æ´å¯Ÿã€‚...\n",
      "2. æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œä½¿ç”¨å¤šå±‚ç¥ç»ç½‘ç»œæ¥æ¨¡æ‹Ÿäººè„‘çš„å·¥ä½œæ–¹å¼ã€‚...\n",
      "3. æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªå­é›†ï¼Œä½¿è®¡ç®—æœºèƒ½å¤Ÿåœ¨æ²¡æœ‰æ˜ç¡®ç¼–ç¨‹çš„æƒ…å†µä¸‹å­¦ä¹ å’Œæ”¹è¿›ã€‚...\n",
      "4. Pythonæ˜¯ä¸€ç§é«˜çº§ç¼–ç¨‹è¯­è¨€ï¼Œå¹¿æ³›ç”¨äºæ•°æ®ç§‘å­¦ã€æœºå™¨å­¦ä¹ å’ŒWebå¼€å‘ã€‚...\n",
      "5. ä»Šå¤©å¤©æ°”å¾ˆå¥½ï¼Œé˜³å…‰æ˜åªšï¼Œé€‚åˆæˆ·å¤–æ´»åŠ¨å’Œæ•£æ­¥ã€‚...\n",
      "\n",
      "4.2 å¤šç§æ£€ç´¢å™¨é›†æˆ\n",
      "å¤šé‡é›†æˆæ£€ç´¢å™¨åˆ›å»ºå¤±è´¥: Could not import scikit-learn, please install with `pip install scikit-learn`.\n",
      "\n",
      "============================================================\n",
      "5. å¤šæŸ¥è¯¢æ£€ç´¢å™¨ç¤ºä¾‹\n",
      "============================================================\n",
      "\n",
      "5.1 åŸºç¡€å¤šæŸ¥è¯¢æ£€ç´¢\n",
      "å¤šæŸ¥è¯¢æ£€ç´¢å™¨åˆ›å»ºå¤±è´¥: model \"qwen2.5:3b\" not found, try pulling it first (status code: 404)\n",
      "\n",
      "============================================================\n",
      "6. ä¸Šä¸‹æ–‡å‹ç¼©æ£€ç´¢å™¨ç¤ºä¾‹\n",
      "============================================================\n",
      "\n",
      "6.1 LLMé“¾æå–å™¨\n",
      "ä¸Šä¸‹æ–‡å‹ç¼©æ£€ç´¢å™¨åˆ›å»ºå¤±è´¥: model \"qwen2.5:3b\" not found, try pulling it first (status code: 404)\n",
      "\n",
      "============================================================\n",
      "7. è‡ªæŸ¥è¯¢æ£€ç´¢å™¨ç¤ºä¾‹\n",
      "============================================================\n",
      "è‡ªæŸ¥è¯¢æ£€ç´¢å™¨åˆ›å»ºå¤±è´¥: Self query retriever with Vector Store type <class 'langchain_community.vectorstores.faiss.FAISS'> not supported.\n",
      "\n",
      "============================================================\n",
      "8. å¼‚æ­¥æ£€ç´¢ç¤ºä¾‹\n",
      "============================================================\n",
      "\n",
      "8.1 å¼‚æ­¥å•ä¸ªæ£€ç´¢\n",
      "å¼‚æ­¥æ£€ç´¢ç»“æœæ•°é‡: 3\n",
      "\n",
      "8.2 å¼‚æ­¥æ‰¹é‡æ£€ç´¢\n",
      "æ‰¹é‡æ£€ç´¢äº† 3 ä¸ªæŸ¥è¯¢\n",
      "æŸ¥è¯¢ 1: 3 ä¸ªç»“æœ\n",
      "æŸ¥è¯¢ 2: 3 ä¸ªç»“æœ\n",
      "æŸ¥è¯¢ 3: 3 ä¸ªç»“æœ\n",
      "\n",
      "============================================================\n",
      "9. è‡ªå®šä¹‰æ£€ç´¢å™¨ç¤ºä¾‹\n",
      "============================================================\n",
      "æŸ¥è¯¢: æœºå™¨å­¦ä¹ äººå·¥æ™ºèƒ½\n",
      "è‡ªå®šä¹‰æ£€ç´¢åˆ° 0 ä¸ªç»“æœ:\n",
      "\n",
      "============================================================\n",
      "10. æ£€ç´¢å™¨æ€§èƒ½æ¯”è¾ƒ\n",
      "============================================================\n",
      "æŸ¥è¯¢: æ·±åº¦å­¦ä¹ ç¥ç»ç½‘ç»œ\n",
      "\n",
      "æ€§èƒ½æ¯”è¾ƒç»“æœ:\n",
      "\n",
      "å‘é‡æ£€ç´¢:\n",
      "  æ—¶é—´: 0.029ç§’\n",
      "  ç»“æœæ•°: 3\n",
      "  é¦–ä¸ªç»“æœ: æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œä½¿ç”¨å¤šå±‚ç¥ç»ç½‘ç»œæ¥æ¨¡æ‹Ÿäººè„‘çš„å·¥ä½œæ–¹å¼ã€‚...\n",
      "\n",
      "BM25æ£€ç´¢:\n",
      "  æ—¶é—´: 0.001ç§’\n",
      "  ç»“æœæ•°: 3\n",
      "  é¦–ä¸ªç»“æœ: æ•°æ®ç§‘å­¦ç»“åˆäº†ç»Ÿè®¡å­¦ã€è®¡ç®—æœºç§‘å­¦å’Œé¢†åŸŸä¸“ä¸šçŸ¥è¯†æ¥ä»æ•°æ®ä¸­æå–æ´å¯Ÿã€‚...\n",
      "\n",
      "é›†æˆæ£€ç´¢:\n",
      "  æ—¶é—´: 0.035ç§’\n",
      "  ç»“æœæ•°: 5\n",
      "  é¦–ä¸ªç»“æœ: æ•°æ®ç§‘å­¦ç»“åˆäº†ç»Ÿè®¡å­¦ã€è®¡ç®—æœºç§‘å­¦å’Œé¢†åŸŸä¸“ä¸šçŸ¥è¯†æ¥ä»æ•°æ®ä¸­æå–æ´å¯Ÿã€‚...\n",
      "\n",
      "============================================================\n",
      "11. å®é™…RAGåº”ç”¨ç¤ºä¾‹\n",
      "============================================================\n",
      "\n",
      "é—®é¢˜: ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ\n",
      "RAGç¤ºä¾‹åˆ›å»ºå¤±è´¥: model \"qwen2.5:3b\" not found, try pulling it first (status code: 404)\n",
      "\n",
      "ğŸ‰ æ‰€æœ‰æ£€ç´¢å™¨ç¤ºä¾‹è¿è¡Œå®Œæˆï¼\n"
     ]
    }
   ],
   "execution_count": 8,
   "source": [
    "\n",
    "## 11. å®é™…åº”ç”¨åœºæ™¯\n",
    "\n",
    "def practical_rag_example():\n",
    "    \"\"\"å®é™…RAGåº”ç”¨ç¤ºä¾‹\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"11. å®é™…RAGåº”ç”¨ç¤ºä¾‹\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    from langchain.chains import RetrievalQA\n",
    "    from langchain.prompts import PromptTemplate\n",
    "\n",
    "    try:\n",
    "        llm = ChatOllama(\n",
    "            base_url=\"http://localhost:11434\",\n",
    "            model=\"qwen2.5:3b\",\n",
    "            temperature=0.7\n",
    "        )\n",
    "\n",
    "        # è‡ªå®šä¹‰æç¤ºæ¨¡æ¿\n",
    "        prompt_template = \"\"\"åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ä¿¡æ¯å›ç­”é—®é¢˜ã€‚å¦‚æœä¸Šä¸‹æ–‡ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯·è¯´\"æ ¹æ®æä¾›çš„ä¿¡æ¯æ— æ³•å›ç­”\"ã€‚\n",
    "\n",
    "ä¸Šä¸‹æ–‡:\n",
    "{context}\n",
    "\n",
    "é—®é¢˜: {question}\n",
    "\n",
    "å›ç­”:\"\"\"\n",
    "\n",
    "        PROMPT = PromptTemplate(\n",
    "            template=prompt_template,\n",
    "            input_variables=[\"context\", \"question\"]\n",
    "        )\n",
    "\n",
    "        # åˆ›å»ºRAGé“¾\n",
    "        qa_chain = RetrievalQA.from_chain_type(\n",
    "            llm=llm,\n",
    "            chain_type=\"stuff\",\n",
    "            retriever=ensemble_retriever,\n",
    "            chain_type_kwargs={\"prompt\": PROMPT},\n",
    "            return_source_documents=True\n",
    "        )\n",
    "\n",
    "        # æµ‹è¯•é—®é¢˜\n",
    "        questions = [\n",
    "            \"ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ\",\n",
    "            \"æ·±åº¦å­¦ä¹ å’Œæœºå™¨å­¦ä¹ æœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ\",\n",
    "            \"äººå·¥æ™ºèƒ½æœ‰å“ªäº›åº”ç”¨é¢†åŸŸï¼Ÿ\"\n",
    "        ]\n",
    "\n",
    "        for question in questions:\n",
    "            print(f\"\\né—®é¢˜: {question}\")\n",
    "            result = qa_chain.invoke({\"query\": question})\n",
    "            print(f\"å›ç­”: {result['result']}\")\n",
    "            print(f\"å‚è€ƒæ–‡æ¡£æ•°é‡: {len(result['source_documents'])}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"RAGç¤ºä¾‹åˆ›å»ºå¤±è´¥: {e}\")\n",
    "\n",
    "\n",
    "practical_rag_example()\n",
    "\n",
    "print(\"\\nğŸ‰ æ‰€æœ‰æ£€ç´¢å™¨ç¤ºä¾‹è¿è¡Œå®Œæˆï¼\")"
   ],
   "id": "885ba966bb8484bb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T08:14:49.456134Z",
     "start_time": "2025-07-23T08:14:49.452623Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "# è®¾ç½®USER_AGENTç¯å¢ƒå˜é‡\n",
    "os.environ[\"USER_AGENT\"] = \"LangChain-Tutorial/1.0 (Educational Purpose)\"\n",
    "\n",
    "# æˆ–è€…è®¾ç½®æ›´è¯¦ç»†çš„USER_AGENT\n",
    "os.environ[\"USER_AGENT\"] = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "\n",
    "print(\"âœ… USER_AGENT ç¯å¢ƒå˜é‡å·²è®¾ç½®\")\n",
    "print(f\"å½“å‰ USER_AGENT: {os.environ.get('USER_AGENT')}\")"
   ],
   "id": "3b5e22e92c2f3ccd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… USER_AGENT ç¯å¢ƒå˜é‡å·²è®¾ç½®\n",
      "å½“å‰ USER_AGENT: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T08:14:49.488334Z",
     "start_time": "2025-07-23T08:14:49.483898Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "LangChain 0.3 Data Connection å®Œæ•´ç¤ºä¾‹\n",
    "åŒ…å«æ–‡æ¡£åŠ è½½ã€æ–‡æœ¬åˆ†å‰²ã€å‘é‡åŒ–ã€å­˜å‚¨å’Œæ£€ç´¢çš„å®Œæ•´æµç¨‹\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "from typing import List, Dict, Any\n",
    "import asyncio\n",
    "\n",
    "# æ ¸å¿ƒå¯¼å…¥\n",
    "from langchain_community.document_loaders import (\n",
    "    TextLoader,\n",
    "    PyPDFLoader,\n",
    "    CSVLoader,\n",
    "    JSONLoader,\n",
    "    WebBaseLoader,\n",
    "    DirectoryLoader\n",
    ")\n",
    "from langchain.text_splitter import (\n",
    "    RecursiveCharacterTextSplitter,\n",
    "    CharacterTextSplitter,\n",
    "    TokenTextSplitter,\n",
    "    MarkdownHeaderTextSplitter\n",
    ")\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_community.vectorstores import (\n",
    "    FAISS,\n",
    "    Chroma,\n",
    "    Qdrant\n",
    ")\n",
    "from langchain_core.documents import Document\n",
    "from langchain.retrievers import (\n",
    "    BM25Retriever,\n",
    "    EnsembleRetriever,\n",
    "    MultiQueryRetriever\n",
    ")\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "print(\"âœ… æ‰€æœ‰åº“å¯¼å…¥æˆåŠŸ\")"
   ],
   "id": "bb5b56271e5fc10f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… æ‰€æœ‰åº“å¯¼å…¥æˆåŠŸ\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T08:14:49.959145Z",
     "start_time": "2025-07-23T08:14:49.517272Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "# 5. Retrievers ç¤ºä¾‹\n",
    "def retrievers_example(vectorstore, chunks: List[Document]):\n",
    "    \"\"\"æ£€ç´¢å™¨ç¤ºä¾‹\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"5. Retrievers æ£€ç´¢å™¨ç¤ºä¾‹\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # 5.1 å‘é‡å­˜å‚¨æ£€ç´¢å™¨\n",
    "    print(\"\\n5.1 å‘é‡å­˜å‚¨æ£€ç´¢å™¨\")\n",
    "    if vectorstore:\n",
    "        vector_retriever = vectorstore.as_retriever(\n",
    "            search_type=\"similarity\",\n",
    "            search_kwargs={\"k\": 3}\n",
    "        )\n",
    "\n",
    "        results = vector_retriever.invoke(\"äººå·¥æ™ºèƒ½çš„åº”ç”¨\")\n",
    "        print(f\"å‘é‡æ£€ç´¢ç»“æœæ•°é‡: {len(results)}\")\n",
    "        for i, doc in enumerate(results):\n",
    "            print(f\"{i + 1}. {doc.page_content[:100]}...\")\n",
    "\n",
    "    # 5.2 BM25æ£€ç´¢å™¨\n",
    "    print(\"\\n5.2 BM25æ£€ç´¢å™¨\")\n",
    "    try:\n",
    "        bm25_retriever = BM25Retriever.from_documents(chunks)\n",
    "        bm25_retriever.k = 3\n",
    "\n",
    "        bm25_results = bm25_retriever.invoke(\"äººå·¥æ™ºèƒ½å‘å±•\")\n",
    "        print(f\"BM25æ£€ç´¢ç»“æœæ•°é‡: {len(bm25_results)}\")\n",
    "        for i, doc in enumerate(bm25_results):\n",
    "            print(f\"{i + 1}. {doc.page_content[:100]}...\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"BM25æ£€ç´¢å™¨åˆ›å»ºå¤±è´¥: {e}\")\n",
    "        bm25_retriever = None\n",
    "\n",
    "    # 5.3 é›†æˆæ£€ç´¢å™¨\n",
    "    print(\"\\n5.3 é›†æˆæ£€ç´¢å™¨\")\n",
    "    if vectorstore and bm25_retriever:\n",
    "        try:\n",
    "            ensemble_retriever = EnsembleRetriever(\n",
    "                retrievers=[vector_retriever, bm25_retriever],\n",
    "                weights=[0.7, 0.3]  # å‘é‡æœç´¢æƒé‡0.7ï¼ŒBM25æƒé‡0.3\n",
    "            )\n",
    "\n",
    "            ensemble_results = ensemble_retriever.invoke(\"æœºå™¨å­¦ä¹ æŠ€æœ¯\")\n",
    "            print(f\"é›†æˆæ£€ç´¢ç»“æœæ•°é‡: {len(ensemble_results)}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"é›†æˆæ£€ç´¢å™¨åˆ›å»ºå¤±è´¥: {e}\")\n",
    "\n",
    "    # 5.4 å¤šæŸ¥è¯¢æ£€ç´¢å™¨\n",
    "    print(\"\\n5.4 å¤šæŸ¥è¯¢æ£€ç´¢å™¨\")\n",
    "    if vectorstore:\n",
    "        try:\n",
    "            llm = ChatOllama(\n",
    "                base_url=\"http://localhost:11434\",\n",
    "                model=\"gemma3:4b\"\n",
    "            )\n",
    "\n",
    "            multi_query_retriever = MultiQueryRetriever.from_llm(\n",
    "                retriever=vector_retriever,\n",
    "                llm=llm\n",
    "            )\n",
    "\n",
    "            multi_results = multi_query_retriever.invoke(\"AIçš„æœªæ¥å‘å±•è¶‹åŠ¿\")\n",
    "            print(f\"å¤šæŸ¥è¯¢æ£€ç´¢ç»“æœæ•°é‡: {len(multi_results)}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"å¤šæŸ¥è¯¢æ£€ç´¢å™¨åˆ›å»ºå¤±è´¥: {e}\")\n",
    "# 5. æ£€ç´¢å™¨\n",
    "retrievers_example(faiss_store, chunks)"
   ],
   "id": "4ceed918758170b2",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'faiss_store' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[11]\u001B[39m\u001B[32m, line 71\u001B[39m\n\u001B[32m     69\u001B[39m             \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33må¤šæŸ¥è¯¢æ£€ç´¢å™¨åˆ›å»ºå¤±è´¥: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00me\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n\u001B[32m     70\u001B[39m \u001B[38;5;66;03m# 5. æ£€ç´¢å™¨\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m71\u001B[39m retrievers_example(\u001B[43mfaiss_store\u001B[49m, chunks)\n",
      "\u001B[31mNameError\u001B[39m: name 'faiss_store' is not defined"
     ]
    }
   ],
   "execution_count": 11
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
