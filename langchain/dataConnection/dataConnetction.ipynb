{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Data Connection æ ¸å¿ƒç»„ä»¶",
   "id": "d2588d34d8fa6662"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "* Data Connection æ˜¯ LangChain ä¸­å¤„ç†å¤–éƒ¨æ•°æ®çš„æ ¸å¿ƒæ¨¡å—ï¼ŒåŒ…å«ä»¥ä¸‹ä¸»è¦ç»„ä»¶ï¼š\n",
    "* Document Loaders - æ–‡æ¡£åŠ è½½å™¨\n",
    "* Text Splitters - æ–‡æœ¬åˆ†å‰²å™¨\n",
    "* Embedding Models - åµŒå…¥æ¨¡å‹\n",
    "* Vector Stores - å‘é‡å­˜å‚¨\n",
    "* Retrievers - æ£€ç´¢å™¨"
   ],
   "id": "1d00345d4349eba6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T16:04:43.826163Z",
     "start_time": "2025-07-22T16:04:41.880180Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "LangChain 0.3 Data Connection å®Œæ•´ç¤ºä¾‹\n",
    "åŒ…å«æ–‡æ¡£åŠ è½½ã€æ–‡æœ¬åˆ†å‰²ã€å‘é‡åŒ–ã€å­˜å‚¨å’Œæ£€ç´¢çš„å®Œæ•´æµç¨‹\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "from typing import List, Dict, Any\n",
    "import asyncio\n",
    "\n",
    "# æ ¸å¿ƒå¯¼å…¥\n",
    "from langchain_community.document_loaders import (\n",
    "    TextLoader,\n",
    "    PyPDFLoader,\n",
    "    CSVLoader,\n",
    "    JSONLoader,\n",
    "    WebBaseLoader,\n",
    "    DirectoryLoader\n",
    ")\n",
    "from langchain.text_splitter import (\n",
    "    RecursiveCharacterTextSplitter,\n",
    "    CharacterTextSplitter,\n",
    "    TokenTextSplitter,\n",
    "    MarkdownHeaderTextSplitter\n",
    ")\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_community.vectorstores import (\n",
    "    FAISS,\n",
    "    Chroma,\n",
    "    Qdrant\n",
    ")\n",
    "from langchain_core.documents import Document\n",
    "from langchain.retrievers import (\n",
    "    BM25Retriever,\n",
    "    EnsembleRetriever,\n",
    "    MultiQueryRetriever\n",
    ")\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "print(\"âœ… æ‰€æœ‰åº“å¯¼å…¥æˆåŠŸ\")"
   ],
   "id": "ed791ba631680edb",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… æ‰€æœ‰åº“å¯¼å…¥æˆåŠŸ\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1. Document Loaders ç¤ºä¾‹",
   "id": "e09a684636812a07"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T16:04:47.356957Z",
     "start_time": "2025-07-22T16:04:46.516827Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# 1. Document Loaders ç¤ºä¾‹\n",
    "def document_loaders_example():\n",
    "    \"\"\"æ–‡æ¡£åŠ è½½å™¨ç¤ºä¾‹\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"1. Document Loaders æ–‡æ¡£åŠ è½½å™¨ç¤ºä¾‹\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # 1.1 æ–‡æœ¬æ–‡ä»¶åŠ è½½\n",
    "    print(\"\\n1.1 æ–‡æœ¬æ–‡ä»¶åŠ è½½\")\n",
    "    # åˆ›å»ºç¤ºä¾‹æ–‡æœ¬æ–‡ä»¶\n",
    "    with open(\"sample.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"\"\"\n",
    "        äººå·¥æ™ºèƒ½ï¼ˆAIï¼‰æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œè‡´åŠ›äºåˆ›å»ºèƒ½å¤Ÿæ‰§è¡Œé€šå¸¸éœ€è¦äººç±»æ™ºèƒ½çš„ä»»åŠ¡çš„ç³»ç»Ÿã€‚\n",
    "        æœºå™¨å­¦ä¹ æ˜¯AIçš„ä¸€ä¸ªå­é›†ï¼Œå®ƒä½¿è®¡ç®—æœºèƒ½å¤Ÿä»æ•°æ®ä¸­å­¦ä¹ è€Œæ— éœ€æ˜ç¡®ç¼–ç¨‹ã€‚\n",
    "        æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªå­é›†ï¼Œä½¿ç”¨ç¥ç»ç½‘ç»œæ¥æ¨¡æ‹Ÿäººè„‘çš„å·¥ä½œæ–¹å¼ã€‚\n",
    "        \"\"\")\n",
    "\n",
    "    loader = TextLoader(\"sample.txt\", encoding=\"utf-8\")\n",
    "    documents = loader.load()\n",
    "    print(f\"åŠ è½½çš„æ–‡æ¡£æ•°é‡: {len(documents)}\")\n",
    "    print(f\"æ–‡æ¡£å†…å®¹é¢„è§ˆ: {documents[0].page_content[:100]}...\")\n",
    "\n",
    "    # 1.2 CSVæ–‡ä»¶åŠ è½½\n",
    "    print(\"\\n1.2 CSVæ–‡ä»¶åŠ è½½\")\n",
    "    import pandas as pd\n",
    "\n",
    "    # åˆ›å»ºç¤ºä¾‹CSV\n",
    "    df = pd.DataFrame({\n",
    "        'name': ['å¼ ä¸‰', 'æå››', 'ç‹äº”'],\n",
    "        'age': [25, 30, 35],\n",
    "        'city': ['åŒ—äº¬', 'ä¸Šæµ·', 'æ·±åœ³'],\n",
    "        'description': ['è½¯ä»¶å·¥ç¨‹å¸ˆ', 'æ•°æ®ç§‘å­¦å®¶', 'äº§å“ç»ç†']\n",
    "    })\n",
    "    df.to_csv(\"sample.csv\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "    csv_loader = CSVLoader(\"sample.csv\", encoding=\"utf-8\")\n",
    "    csv_docs = csv_loader.load()\n",
    "    print(f\"CSVæ–‡æ¡£æ•°é‡: {len(csv_docs)}\")\n",
    "    print(f\"CSVæ–‡æ¡£ç¤ºä¾‹: {csv_docs[0].page_content}\")\n",
    "\n",
    "    # 1.3 JSONæ–‡ä»¶åŠ è½½\n",
    "    print(\"\\n1.3 JSONæ–‡ä»¶åŠ è½½\")\n",
    "    import json\n",
    "\n",
    "    sample_data = [\n",
    "        {\"title\": \"Pythonç¼–ç¨‹\", \"content\": \"Pythonæ˜¯ä¸€ç§é«˜çº§ç¼–ç¨‹è¯­è¨€\", \"category\": \"æŠ€æœ¯\"},\n",
    "        {\"title\": \"æ•°æ®åˆ†æ\", \"content\": \"æ•°æ®åˆ†ææ˜¯ä»æ•°æ®ä¸­æå–æ´å¯Ÿçš„è¿‡ç¨‹\", \"category\": \"æ•°æ®ç§‘å­¦\"}\n",
    "    ]\n",
    "\n",
    "    with open(\"sample.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(sample_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    json_loader = JSONLoader(\"sample.json\", jq_schema=\".[].content\")\n",
    "    json_docs = json_loader.load()\n",
    "    print(f\"JSONæ–‡æ¡£æ•°é‡: {len(json_docs)}\")\n",
    "    print(f\"JSONæ–‡æ¡£ç¤ºä¾‹: {json_docs[0].page_content}\")\n",
    "\n",
    "    # 1.4 ç›®å½•æ‰¹é‡åŠ è½½\n",
    "    print(\"\\n1.4 ç›®å½•æ‰¹é‡åŠ è½½\")\n",
    "    os.makedirs(\"docs\", exist_ok=True)\n",
    "\n",
    "    # åˆ›å»ºå¤šä¸ªæ–‡æ¡£\n",
    "    for i in range(3):\n",
    "        with open(f\"docs/doc_{i}.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(f\"è¿™æ˜¯ç¬¬{i + 1}ä¸ªæ–‡æ¡£çš„å†…å®¹ã€‚åŒ…å«å…³äºæŠ€æœ¯{i + 1}çš„è¯¦ç»†ä¿¡æ¯ã€‚\")\n",
    "\n",
    "    dir_loader = DirectoryLoader(\"docs\", glob=\"*.txt\",\n",
    "                                 loader_cls=TextLoader,\n",
    "                                 loader_kwargs={\"encoding\": \"utf-8\"})\n",
    "    dir_docs = dir_loader.load()\n",
    "    print(f\"ç›®å½•æ–‡æ¡£æ•°é‡: {len(dir_docs)}\")\n",
    "\n",
    "    return documents + csv_docs + json_docs + dir_docs\n",
    "\n",
    "documents = document_loaders_example()"
   ],
   "id": "ba3eef49f7f1be9e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "1. Document Loaders æ–‡æ¡£åŠ è½½å™¨ç¤ºä¾‹\n",
      "============================================================\n",
      "\n",
      "1.1 æ–‡æœ¬æ–‡ä»¶åŠ è½½\n",
      "åŠ è½½çš„æ–‡æ¡£æ•°é‡: 1\n",
      "æ–‡æ¡£å†…å®¹é¢„è§ˆ: \n",
      "        äººå·¥æ™ºèƒ½ï¼ˆAIï¼‰æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œè‡´åŠ›äºåˆ›å»ºèƒ½å¤Ÿæ‰§è¡Œé€šå¸¸éœ€è¦äººç±»æ™ºèƒ½çš„ä»»åŠ¡çš„ç³»ç»Ÿã€‚\n",
      "        æœºå™¨å­¦ä¹ æ˜¯AIçš„ä¸€ä¸ªå­é›†ï¼Œå®ƒä½¿è®¡ç®—æœºèƒ½å¤Ÿä»æ•°æ®ä¸­å­¦ä¹ è€Œæ— éœ€æ˜ç¡®ç¼–ç¨‹ã€‚\n",
      "   ...\n",
      "\n",
      "1.2 CSVæ–‡ä»¶åŠ è½½\n",
      "CSVæ–‡æ¡£æ•°é‡: 3\n",
      "CSVæ–‡æ¡£ç¤ºä¾‹: name: å¼ ä¸‰\n",
      "age: 25\n",
      "city: åŒ—äº¬\n",
      "description: è½¯ä»¶å·¥ç¨‹å¸ˆ\n",
      "\n",
      "1.3 JSONæ–‡ä»¶åŠ è½½\n",
      "JSONæ–‡æ¡£æ•°é‡: 2\n",
      "JSONæ–‡æ¡£ç¤ºä¾‹: Pythonæ˜¯ä¸€ç§é«˜çº§ç¼–ç¨‹è¯­è¨€\n",
      "\n",
      "1.4 ç›®å½•æ‰¹é‡åŠ è½½\n",
      "ç›®å½•æ–‡æ¡£æ•°é‡: 3\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2. Text Splitters ç¤ºä¾‹",
   "id": "5fd3ca1111ba6401"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T16:04:50.352310Z",
     "start_time": "2025-07-22T16:04:50.110133Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# 2. Text Splitters ç¤ºä¾‹\n",
    "def text_splitters_example(documents: List[Document]):\n",
    "    \"\"\"æ–‡æœ¬åˆ†å‰²å™¨ç¤ºä¾‹\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"2. Text Splitters æ–‡æœ¬åˆ†å‰²å™¨ç¤ºä¾‹\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # åˆ›å»ºé•¿æ–‡æœ¬ç”¨äºåˆ†å‰²\n",
    "    long_text = \"\"\"\n",
    "    äººå·¥æ™ºèƒ½çš„å‘å±•å†ç¨‹å¯ä»¥è¿½æº¯åˆ°20ä¸–çºª50å¹´ä»£ã€‚å½“æ—¶ï¼Œè®¡ç®—æœºç§‘å­¦å®¶å¼€å§‹æ¢ç´¢è®©æœºå™¨æ¨¡æ‹Ÿäººç±»æ™ºèƒ½çš„å¯èƒ½æ€§ã€‚\n",
    "\n",
    "    åœ¨1956å¹´çš„è¾¾ç‰¹èŒ…æ–¯ä¼šè®®ä¸Šï¼Œäººå·¥æ™ºèƒ½è¿™ä¸ªæœ¯è¯­é¦–æ¬¡è¢«æ­£å¼æå‡ºã€‚è¿™æ ‡å¿—ç€AIä½œä¸ºä¸€ä¸ªç‹¬ç«‹å­¦ç§‘çš„è¯ç”Ÿã€‚\n",
    "\n",
    "    éšåçš„å‡ åå¹´é‡Œï¼ŒAIç»å†äº†å¤šæ¬¡èµ·ä¼ã€‚60-70å¹´ä»£æ˜¯ç¬¬ä¸€ä¸ªAIæ˜¥å¤©ï¼Œä¸“å®¶ç³»ç»Ÿå¾—åˆ°äº†å¹¿æ³›åº”ç”¨ã€‚\n",
    "\n",
    "    80å¹´ä»£æœ«åˆ°90å¹´ä»£åˆï¼Œç”±äºæŠ€æœ¯é™åˆ¶å’Œè¿‡é«˜æœŸæœ›ï¼ŒAIè¿›å…¥äº†æ‰€è°“çš„\"AIå†¬å¤©\"ã€‚\n",
    "\n",
    "    21ä¸–çºªä»¥æ¥ï¼Œéšç€å¤§æ•°æ®ã€äº‘è®¡ç®—å’Œæ·±åº¦å­¦ä¹ çš„å‘å±•ï¼ŒAIè¿æ¥äº†æ–°çš„æ˜¥å¤©ã€‚\n",
    "\n",
    "    ä»Šå¤©ï¼ŒAIå·²ç»åœ¨å›¾åƒè¯†åˆ«ã€è‡ªç„¶è¯­è¨€å¤„ç†ã€æ¨èç³»ç»Ÿç­‰é¢†åŸŸå–å¾—äº†çªç ´æ€§è¿›å±•ã€‚\n",
    "    \"\"\"\n",
    "\n",
    "    long_doc = Document(page_content=long_text, metadata={\"source\": \"ai_history\"})\n",
    "\n",
    "    # 2.1 é€’å½’å­—ç¬¦åˆ†å‰²å™¨ï¼ˆæ¨èï¼‰\n",
    "    print(\"\\n2.1 RecursiveCharacterTextSplitter\")\n",
    "    recursive_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=200,\n",
    "        chunk_overlap=50,\n",
    "        length_function=len,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \"ã€‚\", \"ï¼Œ\", \" \", \"\"]\n",
    "    )\n",
    "\n",
    "    recursive_chunks = recursive_splitter.split_documents([long_doc])\n",
    "    print(f\"é€’å½’åˆ†å‰²å—æ•°: {len(recursive_chunks)}\")\n",
    "    for i, chunk in enumerate(recursive_chunks[:2]):\n",
    "        print(f\"å— {i + 1}: {chunk.page_content[:100]}...\")\n",
    "\n",
    "    # 2.2 å­—ç¬¦åˆ†å‰²å™¨\n",
    "    print(\"\\n2.2 CharacterTextSplitter\")\n",
    "    char_splitter = CharacterTextSplitter(\n",
    "        chunk_size=300,\n",
    "        chunk_overlap=50,\n",
    "        separator=\"\\n\\n\"\n",
    "    )\n",
    "\n",
    "    char_chunks = char_splitter.split_documents([long_doc])\n",
    "    print(f\"å­—ç¬¦åˆ†å‰²å—æ•°: {len(char_chunks)}\")\n",
    "\n",
    "    # 2.3 Tokenåˆ†å‰²å™¨\n",
    "    print(\"\\n2.3 TokenTextSplitter\")\n",
    "    token_splitter = TokenTextSplitter(\n",
    "        chunk_size=100,\n",
    "        chunk_overlap=20\n",
    "    )\n",
    "\n",
    "    token_chunks = token_splitter.split_documents([long_doc])\n",
    "    print(f\"Tokenåˆ†å‰²å—æ•°: {len(token_chunks)}\")\n",
    "\n",
    "    # 2.4 Markdownåˆ†å‰²å™¨\n",
    "    print(\"\\n2.4 MarkdownHeaderTextSplitter\")\n",
    "    markdown_text = \"\"\"\n",
    "# äººå·¥æ™ºèƒ½æ¦‚è¿°\n",
    "\n",
    "## ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½\n",
    "äººå·¥æ™ºèƒ½æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªåˆ†æ”¯ã€‚\n",
    "\n",
    "## AIçš„åº”ç”¨é¢†åŸŸ\n",
    "\n",
    "### è‡ªç„¶è¯­è¨€å¤„ç†\n",
    "NLPæ˜¯AIçš„é‡è¦åˆ†æ”¯ã€‚\n",
    "\n",
    "### è®¡ç®—æœºè§†è§‰\n",
    "è®¡ç®—æœºè§†è§‰è®©æœºå™¨èƒ½å¤Ÿ\"çœ‹è§\"ã€‚\n",
    "\n",
    "## æœªæ¥å‘å±•\n",
    "AIå°†ç»§ç»­å¿«é€Ÿå‘å±•ã€‚\n",
    "\"\"\"\n",
    "\n",
    "    markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "        headers_to_split_on=[\n",
    "            (\"#\", \"Header 1\"),\n",
    "            (\"##\", \"Header 2\"),\n",
    "            (\"###\", \"Header 3\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    md_doc = Document(page_content=markdown_text)\n",
    "    md_chunks = markdown_splitter.split_text(markdown_text)\n",
    "    print(f\"Markdownåˆ†å‰²å—æ•°: {len(md_chunks)}\")\n",
    "\n",
    "    return recursive_chunks\n",
    "# 2. æ–‡æœ¬åˆ†å‰²\n",
    "chunks = text_splitters_example(documents)"
   ],
   "id": "1279205a511e600e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "2. Text Splitters æ–‡æœ¬åˆ†å‰²å™¨ç¤ºä¾‹\n",
      "============================================================\n",
      "\n",
      "2.1 RecursiveCharacterTextSplitter\n",
      "é€’å½’åˆ†å‰²å—æ•°: 2\n",
      "å— 1: äººå·¥æ™ºèƒ½çš„å‘å±•å†ç¨‹å¯ä»¥è¿½æº¯åˆ°20ä¸–çºª50å¹´ä»£ã€‚å½“æ—¶ï¼Œè®¡ç®—æœºç§‘å­¦å®¶å¼€å§‹æ¢ç´¢è®©æœºå™¨æ¨¡æ‹Ÿäººç±»æ™ºèƒ½çš„å¯èƒ½æ€§ã€‚\n",
      "\n",
      "    åœ¨1956å¹´çš„è¾¾ç‰¹èŒ…æ–¯ä¼šè®®ä¸Šï¼Œäººå·¥æ™ºèƒ½è¿™ä¸ªæœ¯è¯­é¦–æ¬¡è¢«æ­£å¼æå‡ºã€‚è¿™æ ‡å¿—ç€AIä½œä¸ºä¸€ä¸ªç‹¬ç«‹å­¦...\n",
      "å— 2: 80å¹´ä»£æœ«åˆ°90å¹´ä»£åˆï¼Œç”±äºæŠ€æœ¯é™åˆ¶å’Œè¿‡é«˜æœŸæœ›ï¼ŒAIè¿›å…¥äº†æ‰€è°“çš„\"AIå†¬å¤©\"ã€‚\n",
      "\n",
      "    21ä¸–çºªä»¥æ¥ï¼Œéšç€å¤§æ•°æ®ã€äº‘è®¡ç®—å’Œæ·±åº¦å­¦ä¹ çš„å‘å±•ï¼ŒAIè¿æ¥äº†æ–°çš„æ˜¥å¤©ã€‚\n",
      "\n",
      "    ä»Šå¤©ï¼ŒAIå·²ç»åœ¨å›¾åƒè¯†åˆ«ã€è‡ª...\n",
      "\n",
      "2.2 CharacterTextSplitter\n",
      "å­—ç¬¦åˆ†å‰²å—æ•°: 1\n",
      "\n",
      "2.3 TokenTextSplitter\n",
      "Tokenåˆ†å‰²å—æ•°: 7\n",
      "\n",
      "2.4 MarkdownHeaderTextSplitter\n",
      "Markdownåˆ†å‰²å—æ•°: 4\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3. Embedding Models ç¤ºä¾‹",
   "id": "88b30c524eb356d8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T16:04:55.634387Z",
     "start_time": "2025-07-22T16:04:55.103348Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "# 3. Embedding Models ç¤ºä¾‹\n",
    "def embedding_models_example():\n",
    "    \"\"\"åµŒå…¥æ¨¡å‹ç¤ºä¾‹\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"3. Embedding Models åµŒå…¥æ¨¡å‹ç¤ºä¾‹\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # 3.1 OllamaåµŒå…¥æ¨¡å‹\n",
    "    print(\"\\n3.1 OllamaåµŒå…¥æ¨¡å‹\")\n",
    "    try:\n",
    "        embeddings = OllamaEmbeddings(\n",
    "            base_url=\"http://localhost:11434\",\n",
    "            model=\"nomic-embed-text\"  # æˆ–ä½¿ç”¨å…¶ä»–åµŒå…¥æ¨¡å‹\n",
    "        )\n",
    "\n",
    "        # æµ‹è¯•æ–‡æœ¬\n",
    "        texts = [\n",
    "            \"äººå·¥æ™ºèƒ½æ˜¯è®¡ç®—æœºç§‘å­¦çš„åˆ†æ”¯\",\n",
    "            \"æœºå™¨å­¦ä¹ æ˜¯AIçš„å­é›†\",\n",
    "            \"æ·±åº¦å­¦ä¹ ä½¿ç”¨ç¥ç»ç½‘ç»œ\",\n",
    "            \"ä»Šå¤©å¤©æ°”å¾ˆå¥½\"\n",
    "        ]\n",
    "\n",
    "        # ç”ŸæˆåµŒå…¥å‘é‡\n",
    "        text_embeddings = embeddings.embed_documents(texts)\n",
    "        query_embedding = embeddings.embed_query(\"ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ\")\n",
    "\n",
    "        print(f\"æ–‡æ¡£åµŒå…¥æ•°é‡: {len(text_embeddings)}\")\n",
    "        print(f\"åµŒå…¥å‘é‡ç»´åº¦: {len(text_embeddings[0])}\")\n",
    "        print(f\"æŸ¥è¯¢åµŒå…¥ç»´åº¦: {len(query_embedding)}\")\n",
    "\n",
    "        # è®¡ç®—ç›¸ä¼¼åº¦\n",
    "        import numpy as np\n",
    "\n",
    "        def cosine_similarity(a, b):\n",
    "            return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "        print(\"\\nç›¸ä¼¼åº¦è®¡ç®—:\")\n",
    "        for i, text in enumerate(texts):\n",
    "            similarity = cosine_similarity(query_embedding, text_embeddings[i])\n",
    "            print(f\"'{text}' ç›¸ä¼¼åº¦: {similarity:.4f}\")\n",
    "\n",
    "        return embeddings\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"OllamaåµŒå…¥æ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}\")\n",
    "        print(\"è¯·ç¡®ä¿OllamaæœåŠ¡æ­£åœ¨è¿è¡Œå¹¶å®‰è£…äº†åµŒå…¥æ¨¡å‹\")\n",
    "        return None\n",
    "# 3. åµŒå…¥æ¨¡å‹\n",
    "embeddings = embedding_models_example()"
   ],
   "id": "95925b2d3a7b8cd2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "3. Embedding Models åµŒå…¥æ¨¡å‹ç¤ºä¾‹\n",
      "============================================================\n",
      "\n",
      "3.1 OllamaåµŒå…¥æ¨¡å‹\n",
      "æ–‡æ¡£åµŒå…¥æ•°é‡: 4\n",
      "åµŒå…¥å‘é‡ç»´åº¦: 768\n",
      "æŸ¥è¯¢åµŒå…¥ç»´åº¦: 768\n",
      "\n",
      "ç›¸ä¼¼åº¦è®¡ç®—:\n",
      "'äººå·¥æ™ºèƒ½æ˜¯è®¡ç®—æœºç§‘å­¦çš„åˆ†æ”¯' ç›¸ä¼¼åº¦: 0.8551\n",
      "'æœºå™¨å­¦ä¹ æ˜¯AIçš„å­é›†' ç›¸ä¼¼åº¦: 0.6135\n",
      "'æ·±åº¦å­¦ä¹ ä½¿ç”¨ç¥ç»ç½‘ç»œ' ç›¸ä¼¼åº¦: 0.5818\n",
      "'ä»Šå¤©å¤©æ°”å¾ˆå¥½' ç›¸ä¼¼åº¦: 0.5851\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4. Vector Stores ç¤ºä¾‹",
   "id": "8127affda365bc76"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T16:07:24.198103Z",
     "start_time": "2025-07-22T16:07:17.981530Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "# 4. Vector Stores ç¤ºä¾‹\n",
    "def vector_stores_example(chunks: List[Document], embeddings):\n",
    "    \"\"\"å‘é‡å­˜å‚¨ç¤ºä¾‹\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"4. Vector Stores å‘é‡å­˜å‚¨ç¤ºä¾‹\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    if embeddings is None:\n",
    "        print(\"è·³è¿‡å‘é‡å­˜å‚¨ç¤ºä¾‹ï¼ˆåµŒå…¥æ¨¡å‹ä¸å¯ç”¨ï¼‰\")\n",
    "        return None, None\n",
    "\n",
    "    # 4.1 FAISSå‘é‡å­˜å‚¨\n",
    "    print(\"\\n4.1 FAISSå‘é‡å­˜å‚¨\")\n",
    "    try:\n",
    "        # åˆ›å»ºFAISSå‘é‡å­˜å‚¨\n",
    "        faiss_vectorstore = FAISS.from_documents(chunks, embeddings)\n",
    "\n",
    "        # ä¿å­˜åˆ°æœ¬åœ°\n",
    "        faiss_vectorstore.save_local(\"faiss_index\")\n",
    "        print(\"âœ… FAISSç´¢å¼•å·²ä¿å­˜\")\n",
    "\n",
    "        # ç›¸ä¼¼æ€§æœç´¢\n",
    "        query = \"äººå·¥æ™ºèƒ½çš„å‘å±•\"\n",
    "        similar_docs = faiss_vectorstore.similarity_search(query, k=3)\n",
    "\n",
    "        print(f\"\\næŸ¥è¯¢: '{query}'\")\n",
    "        print(\"ç›¸ä¼¼æ–‡æ¡£:\")\n",
    "        for i, doc in enumerate(similar_docs):\n",
    "            print(f\"{i + 1}. {doc.page_content[:100]}...\")\n",
    "\n",
    "        # å¸¦åˆ†æ•°çš„ç›¸ä¼¼æ€§æœç´¢\n",
    "        similar_docs_with_scores = faiss_vectorstore.similarity_search_with_score(query, k=3)\n",
    "        print(\"\\nå¸¦åˆ†æ•°çš„æœç´¢ç»“æœ:\")\n",
    "        for i, (doc, score) in enumerate(similar_docs_with_scores):\n",
    "            print(f\"{i + 1}. åˆ†æ•°: {score:.4f} - {doc.page_content[:80]}...\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"FAISSåˆ›å»ºå¤±è´¥: {e}\")\n",
    "        faiss_vectorstore = None\n",
    "\n",
    "    # 4.2 Chromaå‘é‡å­˜å‚¨\n",
    "    print(\"\\n4.2 Chromaå‘é‡å­˜å‚¨\")\n",
    "    try:\n",
    "        chroma_vectorstore = Chroma.from_documents(\n",
    "            chunks,\n",
    "            embeddings,\n",
    "            persist_directory=\"./chroma_db\"\n",
    "        )\n",
    "\n",
    "        # æŒä¹…åŒ–\n",
    "        chroma_vectorstore.persist()\n",
    "        print(\"âœ… Chromaæ•°æ®åº“å·²æŒä¹…åŒ–\")\n",
    "\n",
    "        # æœç´¢æµ‹è¯•\n",
    "        chroma_results = chroma_vectorstore.similarity_search(\"æœºå™¨å­¦ä¹ \", k=2)\n",
    "        print(f\"Chromaæœç´¢ç»“æœæ•°é‡: {len(chroma_results)}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Chromaåˆ›å»ºå¤±è´¥: {e}\")\n",
    "        chroma_vectorstore = None\n",
    "\n",
    "    return faiss_vectorstore, chroma_vectorstore\n",
    "\n",
    "# 4. å‘é‡å­˜å‚¨\n",
    "faiss_store, chroma_store = vector_stores_example(chunks, embeddings)"
   ],
   "id": "6e01b3deffa2493e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "4. Vector Stores å‘é‡å­˜å‚¨ç¤ºä¾‹\n",
      "============================================================\n",
      "\n",
      "4.1 FAISSå‘é‡å­˜å‚¨\n",
      "âœ… FAISSç´¢å¼•å·²ä¿å­˜\n",
      "\n",
      "æŸ¥è¯¢: 'äººå·¥æ™ºèƒ½çš„å‘å±•'\n",
      "ç›¸ä¼¼æ–‡æ¡£:\n",
      "1. äººå·¥æ™ºèƒ½çš„å‘å±•å†ç¨‹å¯ä»¥è¿½æº¯åˆ°20ä¸–çºª50å¹´ä»£ã€‚å½“æ—¶ï¼Œè®¡ç®—æœºç§‘å­¦å®¶å¼€å§‹æ¢ç´¢è®©æœºå™¨æ¨¡æ‹Ÿäººç±»æ™ºèƒ½çš„å¯èƒ½æ€§ã€‚\n",
      "\n",
      "    åœ¨1956å¹´çš„è¾¾ç‰¹èŒ…æ–¯ä¼šè®®ä¸Šï¼Œäººå·¥æ™ºèƒ½è¿™ä¸ªæœ¯è¯­é¦–æ¬¡è¢«æ­£å¼æå‡ºã€‚è¿™æ ‡å¿—ç€AIä½œä¸ºä¸€ä¸ªç‹¬ç«‹å­¦...\n",
      "2. 80å¹´ä»£æœ«åˆ°90å¹´ä»£åˆï¼Œç”±äºæŠ€æœ¯é™åˆ¶å’Œè¿‡é«˜æœŸæœ›ï¼ŒAIè¿›å…¥äº†æ‰€è°“çš„\"AIå†¬å¤©\"ã€‚\n",
      "\n",
      "    21ä¸–çºªä»¥æ¥ï¼Œéšç€å¤§æ•°æ®ã€äº‘è®¡ç®—å’Œæ·±åº¦å­¦ä¹ çš„å‘å±•ï¼ŒAIè¿æ¥äº†æ–°çš„æ˜¥å¤©ã€‚\n",
      "\n",
      "    ä»Šå¤©ï¼ŒAIå·²ç»åœ¨å›¾åƒè¯†åˆ«ã€è‡ª...\n",
      "\n",
      "å¸¦åˆ†æ•°çš„æœç´¢ç»“æœ:\n",
      "1. åˆ†æ•°: 0.4337 - äººå·¥æ™ºèƒ½çš„å‘å±•å†ç¨‹å¯ä»¥è¿½æº¯åˆ°20ä¸–çºª50å¹´ä»£ã€‚å½“æ—¶ï¼Œè®¡ç®—æœºç§‘å­¦å®¶å¼€å§‹æ¢ç´¢è®©æœºå™¨æ¨¡æ‹Ÿäººç±»æ™ºèƒ½çš„å¯èƒ½æ€§ã€‚\n",
      "\n",
      "    åœ¨1956å¹´çš„è¾¾ç‰¹èŒ…æ–¯ä¼šè®®ä¸Šï¼Œäººå·¥æ™ºèƒ½è¿™ä¸ªæœ¯è¯­é¦–...\n",
      "2. åˆ†æ•°: 0.7495 - 80å¹´ä»£æœ«åˆ°90å¹´ä»£åˆï¼Œç”±äºæŠ€æœ¯é™åˆ¶å’Œè¿‡é«˜æœŸæœ›ï¼ŒAIè¿›å…¥äº†æ‰€è°“çš„\"AIå†¬å¤©\"ã€‚\n",
      "\n",
      "    21ä¸–çºªä»¥æ¥ï¼Œéšç€å¤§æ•°æ®ã€äº‘è®¡ç®—å’Œæ·±åº¦å­¦ä¹ çš„å‘å±•ï¼ŒAIè¿æ¥äº†æ–°çš„æ˜¥å¤©ã€‚...\n",
      "\n",
      "4.2 Chromaå‘é‡å­˜å‚¨\n",
      "âœ… Chromaæ•°æ®åº“å·²æŒä¹…åŒ–\n",
      "Chromaæœç´¢ç»“æœæ•°é‡: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\34769\\AppData\\Local\\Temp\\ipykernel_20760\\3854282456.py:51: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  chroma_vectorstore.persist()\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 5. Retrievers ç¤ºä¾‹",
   "id": "ad86b09d47e42ea4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T16:08:59.479200Z",
     "start_time": "2025-07-22T16:08:52.140594Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "# 5. Retrievers ç¤ºä¾‹\n",
    "def retrievers_example(vectorstore, chunks: List[Document]):\n",
    "    \"\"\"æ£€ç´¢å™¨ç¤ºä¾‹\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"5. Retrievers æ£€ç´¢å™¨ç¤ºä¾‹\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # 5.1 å‘é‡å­˜å‚¨æ£€ç´¢å™¨\n",
    "    print(\"\\n5.1 å‘é‡å­˜å‚¨æ£€ç´¢å™¨\")\n",
    "    if vectorstore:\n",
    "        vector_retriever = vectorstore.as_retriever(\n",
    "            search_type=\"similarity\",\n",
    "            search_kwargs={\"k\": 3}\n",
    "        )\n",
    "\n",
    "        results = vector_retriever.invoke(\"äººå·¥æ™ºèƒ½çš„åº”ç”¨\")\n",
    "        print(f\"å‘é‡æ£€ç´¢ç»“æœæ•°é‡: {len(results)}\")\n",
    "        for i, doc in enumerate(results):\n",
    "            print(f\"{i + 1}. {doc.page_content[:100]}...\")\n",
    "\n",
    "    # 5.2 BM25æ£€ç´¢å™¨\n",
    "    print(\"\\n5.2 BM25æ£€ç´¢å™¨\")\n",
    "    try:\n",
    "        bm25_retriever = BM25Retriever.from_documents(chunks)\n",
    "        bm25_retriever.k = 3\n",
    "\n",
    "        bm25_results = bm25_retriever.invoke(\"äººå·¥æ™ºèƒ½å‘å±•\")\n",
    "        print(f\"BM25æ£€ç´¢ç»“æœæ•°é‡: {len(bm25_results)}\")\n",
    "        for i, doc in enumerate(bm25_results):\n",
    "            print(f\"{i + 1}. {doc.page_content[:100]}...\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"BM25æ£€ç´¢å™¨åˆ›å»ºå¤±è´¥: {e}\")\n",
    "        bm25_retriever = None\n",
    "\n",
    "    # 5.3 é›†æˆæ£€ç´¢å™¨\n",
    "    print(\"\\n5.3 é›†æˆæ£€ç´¢å™¨\")\n",
    "    if vectorstore and bm25_retriever:\n",
    "        try:\n",
    "            ensemble_retriever = EnsembleRetriever(\n",
    "                retrievers=[vector_retriever, bm25_retriever],\n",
    "                weights=[0.7, 0.3]  # å‘é‡æœç´¢æƒé‡0.7ï¼ŒBM25æƒé‡0.3\n",
    "            )\n",
    "\n",
    "            ensemble_results = ensemble_retriever.invoke(\"æœºå™¨å­¦ä¹ æŠ€æœ¯\")\n",
    "            print(f\"é›†æˆæ£€ç´¢ç»“æœæ•°é‡: {len(ensemble_results)}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"é›†æˆæ£€ç´¢å™¨åˆ›å»ºå¤±è´¥: {e}\")\n",
    "\n",
    "    # 5.4 å¤šæŸ¥è¯¢æ£€ç´¢å™¨\n",
    "    print(\"\\n5.4 å¤šæŸ¥è¯¢æ£€ç´¢å™¨\")\n",
    "    if vectorstore:\n",
    "        try:\n",
    "            llm = ChatOllama(\n",
    "                base_url=\"http://localhost:11434\",\n",
    "                model=\"gemma3:4b\"\n",
    "            )\n",
    "\n",
    "            multi_query_retriever = MultiQueryRetriever.from_llm(\n",
    "                retriever=vector_retriever,\n",
    "                llm=llm\n",
    "            )\n",
    "\n",
    "            multi_results = multi_query_retriever.invoke(\"AIçš„æœªæ¥å‘å±•è¶‹åŠ¿\")\n",
    "            print(f\"å¤šæŸ¥è¯¢æ£€ç´¢ç»“æœæ•°é‡: {len(multi_results)}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"å¤šæŸ¥è¯¢æ£€ç´¢å™¨åˆ›å»ºå¤±è´¥: {e}\")\n",
    "# 5. æ£€ç´¢å™¨\n",
    "retrievers_example(faiss_store, chunks)"
   ],
   "id": "f14c88e8a32df855",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "5. Retrievers æ£€ç´¢å™¨ç¤ºä¾‹\n",
      "============================================================\n",
      "\n",
      "5.1 å‘é‡å­˜å‚¨æ£€ç´¢å™¨\n",
      "å‘é‡æ£€ç´¢ç»“æœæ•°é‡: 2\n",
      "1. äººå·¥æ™ºèƒ½çš„å‘å±•å†ç¨‹å¯ä»¥è¿½æº¯åˆ°20ä¸–çºª50å¹´ä»£ã€‚å½“æ—¶ï¼Œè®¡ç®—æœºç§‘å­¦å®¶å¼€å§‹æ¢ç´¢è®©æœºå™¨æ¨¡æ‹Ÿäººç±»æ™ºèƒ½çš„å¯èƒ½æ€§ã€‚\n",
      "\n",
      "    åœ¨1956å¹´çš„è¾¾ç‰¹èŒ…æ–¯ä¼šè®®ä¸Šï¼Œäººå·¥æ™ºèƒ½è¿™ä¸ªæœ¯è¯­é¦–æ¬¡è¢«æ­£å¼æå‡ºã€‚è¿™æ ‡å¿—ç€AIä½œä¸ºä¸€ä¸ªç‹¬ç«‹å­¦...\n",
      "2. 80å¹´ä»£æœ«åˆ°90å¹´ä»£åˆï¼Œç”±äºæŠ€æœ¯é™åˆ¶å’Œè¿‡é«˜æœŸæœ›ï¼ŒAIè¿›å…¥äº†æ‰€è°“çš„\"AIå†¬å¤©\"ã€‚\n",
      "\n",
      "    21ä¸–çºªä»¥æ¥ï¼Œéšç€å¤§æ•°æ®ã€äº‘è®¡ç®—å’Œæ·±åº¦å­¦ä¹ çš„å‘å±•ï¼ŒAIè¿æ¥äº†æ–°çš„æ˜¥å¤©ã€‚\n",
      "\n",
      "    ä»Šå¤©ï¼ŒAIå·²ç»åœ¨å›¾åƒè¯†åˆ«ã€è‡ª...\n",
      "\n",
      "5.2 BM25æ£€ç´¢å™¨\n",
      "BM25æ£€ç´¢ç»“æœæ•°é‡: 2\n",
      "1. 80å¹´ä»£æœ«åˆ°90å¹´ä»£åˆï¼Œç”±äºæŠ€æœ¯é™åˆ¶å’Œè¿‡é«˜æœŸæœ›ï¼ŒAIè¿›å…¥äº†æ‰€è°“çš„\"AIå†¬å¤©\"ã€‚\n",
      "\n",
      "    21ä¸–çºªä»¥æ¥ï¼Œéšç€å¤§æ•°æ®ã€äº‘è®¡ç®—å’Œæ·±åº¦å­¦ä¹ çš„å‘å±•ï¼ŒAIè¿æ¥äº†æ–°çš„æ˜¥å¤©ã€‚\n",
      "\n",
      "    ä»Šå¤©ï¼ŒAIå·²ç»åœ¨å›¾åƒè¯†åˆ«ã€è‡ª...\n",
      "2. äººå·¥æ™ºèƒ½çš„å‘å±•å†ç¨‹å¯ä»¥è¿½æº¯åˆ°20ä¸–çºª50å¹´ä»£ã€‚å½“æ—¶ï¼Œè®¡ç®—æœºç§‘å­¦å®¶å¼€å§‹æ¢ç´¢è®©æœºå™¨æ¨¡æ‹Ÿäººç±»æ™ºèƒ½çš„å¯èƒ½æ€§ã€‚\n",
      "\n",
      "    åœ¨1956å¹´çš„è¾¾ç‰¹èŒ…æ–¯ä¼šè®®ä¸Šï¼Œäººå·¥æ™ºèƒ½è¿™ä¸ªæœ¯è¯­é¦–æ¬¡è¢«æ­£å¼æå‡ºã€‚è¿™æ ‡å¿—ç€AIä½œä¸ºä¸€ä¸ªç‹¬ç«‹å­¦...\n",
      "\n",
      "5.3 é›†æˆæ£€ç´¢å™¨\n",
      "é›†æˆæ£€ç´¢ç»“æœæ•°é‡: 2\n",
      "\n",
      "5.4 å¤šæŸ¥è¯¢æ£€ç´¢å™¨\n",
      "å¤šæŸ¥è¯¢æ£€ç´¢ç»“æœæ•°é‡: 2\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 6. å®Œæ•´RAGæµç¨‹ç¤ºä¾‹",
   "id": "f90a79c3cfcb7331"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T16:09:36.054903Z",
     "start_time": "2025-07-22T16:09:27.884710Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# 6. å®Œæ•´RAGæµç¨‹ç¤ºä¾‹\n",
    "def complete_rag_example():\n",
    "    \"\"\"å®Œæ•´çš„RAGæµç¨‹ç¤ºä¾‹\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"6. å®Œæ•´RAGæµç¨‹ç¤ºä¾‹\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    try:\n",
    "        # 6.1 å‡†å¤‡æ•°æ®\n",
    "        documents = [\n",
    "            Document(page_content=\"LangChainæ˜¯ä¸€ä¸ªç”¨äºæ„å»ºLLMåº”ç”¨çš„æ¡†æ¶\", metadata={\"source\": \"doc1\"}),\n",
    "            Document(page_content=\"å‘é‡æ•°æ®åº“å¯ä»¥å­˜å‚¨å’Œæ£€ç´¢é«˜ç»´å‘é‡\", metadata={\"source\": \"doc2\"}),\n",
    "            Document(page_content=\"RAGç»“åˆäº†æ£€ç´¢å’Œç”Ÿæˆï¼Œæé«˜äº†AIå›ç­”çš„å‡†ç¡®æ€§\", metadata={\"source\": \"doc3\"}),\n",
    "            Document(page_content=\"åµŒå…¥æ¨¡å‹å°†æ–‡æœ¬è½¬æ¢ä¸ºæ•°å€¼å‘é‡è¡¨ç¤º\", metadata={\"source\": \"doc4\"})\n",
    "        ]\n",
    "\n",
    "        # 6.2 æ–‡æœ¬åˆ†å‰²\n",
    "        splitter = RecursiveCharacterTextSplitter(chunk_size=100, chunk_overlap=20)\n",
    "        chunks = splitter.split_documents(documents)\n",
    "\n",
    "        # 6.3 åˆ›å»ºåµŒå…¥å’Œå‘é‡å­˜å‚¨\n",
    "        embeddings = OllamaEmbeddings(\n",
    "            base_url=\"http://localhost:11434\",\n",
    "            model=\"nomic-embed-text\"\n",
    "        )\n",
    "\n",
    "        vectorstore = FAISS.from_documents(chunks, embeddings)\n",
    "        retriever = vectorstore.as_retriever(k=2)\n",
    "\n",
    "        # 6.4 åˆ›å»ºRAGé“¾\n",
    "        from langchain_core.prompts import ChatPromptTemplate\n",
    "        from langchain_core.output_parsers import StrOutputParser\n",
    "        from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "        llm = ChatOllama(\n",
    "            base_url=\"http://localhost:11434\",\n",
    "            model=\"gemma3:4b\"\n",
    "        )\n",
    "\n",
    "        prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "        åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡å›ç­”é—®é¢˜ï¼š\n",
    "\n",
    "        ä¸Šä¸‹æ–‡ï¼š{context}\n",
    "\n",
    "        é—®é¢˜ï¼š{question}\n",
    "\n",
    "        è¯·æä¾›å‡†ç¡®ã€ç®€æ´çš„å›ç­”ï¼š\n",
    "        \"\"\")\n",
    "\n",
    "        def format_docs(docs):\n",
    "            return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "        rag_chain = (\n",
    "                {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "                | prompt\n",
    "                | llm\n",
    "                | StrOutputParser()\n",
    "        )\n",
    "\n",
    "        # 6.5 æµ‹è¯•RAGç³»ç»Ÿ\n",
    "        questions = [\n",
    "            \"ä»€ä¹ˆæ˜¯LangChainï¼Ÿ\",\n",
    "            \"å‘é‡æ•°æ®åº“çš„ä½œç”¨æ˜¯ä»€ä¹ˆï¼Ÿ\",\n",
    "            \"RAGæŠ€æœ¯æœ‰ä»€ä¹ˆä¼˜åŠ¿ï¼Ÿ\"\n",
    "        ]\n",
    "\n",
    "        for question in questions:\n",
    "            print(f\"\\né—®é¢˜: {question}\")\n",
    "            answer = rag_chain.invoke(question)\n",
    "            print(f\"å›ç­”: {answer}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"RAGæµç¨‹æ‰§è¡Œå¤±è´¥: {e}\")\n",
    "complete_rag_example()"
   ],
   "id": "e78b5eb261c8ae41",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "6. å®Œæ•´RAGæµç¨‹ç¤ºä¾‹\n",
      "============================================================\n",
      "\n",
      "é—®é¢˜: ä»€ä¹ˆæ˜¯LangChainï¼Ÿ\n",
      "å›ç­”: LangChainæ˜¯ä¸€ä¸ªç”¨äºæ„å»ºLLMåº”ç”¨çš„æ¡†æ¶ã€‚\n",
      "\n",
      "\n",
      "é—®é¢˜: å‘é‡æ•°æ®åº“çš„ä½œç”¨æ˜¯ä»€ä¹ˆï¼Ÿ\n",
      "å›ç­”: å‘é‡æ•°æ®åº“çš„ä½œç”¨æ˜¯å­˜å‚¨å’Œæ£€ç´¢é«˜ç»´å‘é‡ã€‚\n",
      "\n",
      "\n",
      "é—®é¢˜: RAGæŠ€æœ¯æœ‰ä»€ä¹ˆä¼˜åŠ¿ï¼Ÿ\n",
      "å›ç­”: RAGæŠ€æœ¯çš„ä¼˜åŠ¿åœ¨äºå®ƒæé«˜äº†AIå›ç­”çš„å‡†ç¡®æ€§ã€‚\n",
      "\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 7. é«˜çº§åŠŸèƒ½ç¤ºä¾‹",
   "id": "7af8f010e7932d07"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T16:09:51.206635Z",
     "start_time": "2025-07-22T16:09:51.200341Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# 7. é«˜çº§åŠŸèƒ½ç¤ºä¾‹\n",
    "def advanced_features_example():\n",
    "    \"\"\"é«˜çº§åŠŸèƒ½ç¤ºä¾‹\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"7. é«˜çº§åŠŸèƒ½ç¤ºä¾‹\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # 7.1 è‡ªå®šä¹‰æ–‡æ¡£åŠ è½½å™¨\n",
    "    print(\"\\n7.1 è‡ªå®šä¹‰æ–‡æ¡£åŠ è½½å™¨\")\n",
    "\n",
    "    class CustomLoader:\n",
    "        def __init__(self, data_source):\n",
    "            self.data_source = data_source\n",
    "\n",
    "        def load(self):\n",
    "            # æ¨¡æ‹Ÿä»APIæˆ–æ•°æ®åº“åŠ è½½æ•°æ®\n",
    "            documents = []\n",
    "            for i, item in enumerate(self.data_source):\n",
    "                doc = Document(\n",
    "                    page_content=item[\"content\"],\n",
    "                    metadata={\"id\": i, \"type\": item[\"type\"]}\n",
    "                )\n",
    "                documents.append(doc)\n",
    "            return documents\n",
    "\n",
    "    # ä½¿ç”¨è‡ªå®šä¹‰åŠ è½½å™¨\n",
    "    custom_data = [\n",
    "        {\"content\": \"Pythonæ˜¯ä¸€ç§ç¼–ç¨‹è¯­è¨€\", \"type\": \"æŠ€æœ¯\"},\n",
    "        {\"content\": \"æ•°æ®ç§‘å­¦éœ€è¦ç»Ÿè®¡çŸ¥è¯†\", \"type\": \"ç§‘å­¦\"},\n",
    "        {\"content\": \"æœºå™¨å­¦ä¹ ç®—æ³•å¾ˆé‡è¦\", \"type\": \"AI\"}\n",
    "    ]\n",
    "\n",
    "    custom_loader = CustomLoader(custom_data)\n",
    "    custom_docs = custom_loader.load()\n",
    "    print(f\"è‡ªå®šä¹‰åŠ è½½å™¨æ–‡æ¡£æ•°é‡: {len(custom_docs)}\")\n",
    "\n",
    "    # 7.2 æ–‡æ¡£è¿‡æ»¤å’Œé¢„å¤„ç†\n",
    "    print(\"\\n7.2 æ–‡æ¡£è¿‡æ»¤å’Œé¢„å¤„ç†\")\n",
    "\n",
    "    def preprocess_documents(documents):\n",
    "        \"\"\"æ–‡æ¡£é¢„å¤„ç†å‡½æ•°\"\"\"\n",
    "        processed_docs = []\n",
    "        for doc in documents:\n",
    "            # æ¸…ç†æ–‡æœ¬\n",
    "            content = doc.page_content.strip()\n",
    "            content = content.replace(\"\\n\", \" \").replace(\"\\t\", \" \")\n",
    "\n",
    "            # è¿‡æ»¤çŸ­æ–‡æ¡£\n",
    "            if len(content) > 10:\n",
    "                doc.page_content = content\n",
    "                processed_docs.append(doc)\n",
    "\n",
    "        return processed_docs\n",
    "\n",
    "    processed_docs = preprocess_documents(custom_docs)\n",
    "    print(f\"é¢„å¤„ç†åæ–‡æ¡£æ•°é‡: {len(processed_docs)}\")\n",
    "advanced_features_example()"
   ],
   "id": "1fd34ff050068f21",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "7. é«˜çº§åŠŸèƒ½ç¤ºä¾‹\n",
      "============================================================\n",
      "\n",
      "7.1 è‡ªå®šä¹‰æ–‡æ¡£åŠ è½½å™¨\n",
      "è‡ªå®šä¹‰åŠ è½½å™¨æ–‡æ¡£æ•°é‡: 3\n",
      "\n",
      "7.2 æ–‡æ¡£è¿‡æ»¤å’Œé¢„å¤„ç†\n",
      "é¢„å¤„ç†åæ–‡æ¡£æ•°é‡: 1\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 8. æ€§èƒ½ä¼˜åŒ–ç¤ºä¾‹",
   "id": "7bddd0a43c7a49f4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T16:10:06.180453Z",
     "start_time": "2025-07-22T16:10:06.170023Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 8. æ€§èƒ½ä¼˜åŒ–ç¤ºä¾‹\n",
    "async def performance_optimization_example():\n",
    "    \"\"\"æ€§èƒ½ä¼˜åŒ–ç¤ºä¾‹\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"8. æ€§èƒ½ä¼˜åŒ–ç¤ºä¾‹\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # 8.1 æ‰¹é‡å¤„ç†\n",
    "    print(\"\\n8.1 æ‰¹é‡åµŒå…¥å¤„ç†\")\n",
    "\n",
    "    try:\n",
    "        embeddings = OllamaEmbeddings(\n",
    "            base_url=\"http://localhost:11434\",\n",
    "            model=\"nomic-embed-text\"\n",
    "        )\n",
    "\n",
    "        # å¤§é‡æ–‡æœ¬\n",
    "        texts = [f\"è¿™æ˜¯ç¬¬{i}ä¸ªæ–‡æ¡£çš„å†…å®¹\" for i in range(10)]\n",
    "\n",
    "        # æ‰¹é‡ç”ŸæˆåµŒå…¥\n",
    "        batch_embeddings = embeddings.embed_documents(texts)\n",
    "        print(f\"æ‰¹é‡å¤„ç†æ–‡æ¡£æ•°é‡: {len(batch_embeddings)}\")\n",
    "\n",
    "        # 8.2 å¼‚æ­¥å¤„ç†\n",
    "        print(\"\\n8.2 å¼‚æ­¥å¤„ç†ç¤ºä¾‹\")\n",
    "\n",
    "        async def async_embed_text(text):\n",
    "            # æ¨¡æ‹Ÿå¼‚æ­¥åµŒå…¥\n",
    "            await asyncio.sleep(0.1)\n",
    "            return embeddings.embed_query(text)\n",
    "\n",
    "        # å¹¶å‘å¤„ç†\n",
    "        tasks = [async_embed_text(f\"å¼‚æ­¥æ–‡æœ¬{i}\") for i in range(5)]\n",
    "        results = await asyncio.gather(*tasks)\n",
    "        print(f\"å¼‚æ­¥å¤„ç†ç»“æœæ•°é‡: {len(results)}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"æ€§èƒ½ä¼˜åŒ–ç¤ºä¾‹å¤±è´¥: {e}\")\n",
    "performance_optimization_example()\n"
   ],
   "id": "35a7d46e00e601f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<coroutine object performance_optimization_example at 0x000002743F9A9BE0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## ä¸»å‡½æ•°",
   "id": "2e5e75e1f7ea7e1f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T16:10:14.713908Z",
     "start_time": "2025-07-22T16:10:14.709565Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# ä¸»å‡½æ•°\n",
    "def main():\n",
    "    \"\"\"è¿è¡Œæ‰€æœ‰ç¤ºä¾‹\"\"\"\n",
    "    print(\"ğŸš€ LangChain 0.3 Data Connection å®Œæ•´ç¤ºä¾‹\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # 1. æ–‡æ¡£åŠ è½½\n",
    "    documents = document_loaders_example()\n",
    "\n",
    "    # 2. æ–‡æœ¬åˆ†å‰²\n",
    "    chunks = text_splitters_example(documents)\n",
    "\n",
    "    # 3. åµŒå…¥æ¨¡å‹\n",
    "    embeddings = embedding_models_example()\n",
    "\n",
    "    # 4. å‘é‡å­˜å‚¨\n",
    "    faiss_store, chroma_store = vector_stores_example(chunks, embeddings)\n",
    "\n",
    "    # 5. æ£€ç´¢å™¨\n",
    "    retrievers_example(faiss_store, chunks)\n",
    "\n",
    "    # 6. å®Œæ•´RAGæµç¨‹\n",
    "    complete_rag_example()\n",
    "\n",
    "    # 7. é«˜çº§åŠŸèƒ½\n",
    "    advanced_features_example()\n",
    "\n",
    "    print(\"\\nğŸ‰ æ‰€æœ‰ç¤ºä¾‹è¿è¡Œå®Œæˆï¼\")\n",
    "\n",
    "    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶\n",
    "    cleanup_files()\n",
    "\n",
    "\n",
    "def cleanup_files():\n",
    "    \"\"\"æ¸…ç†ä¸´æ—¶æ–‡ä»¶\"\"\"\n",
    "    import shutil\n",
    "\n",
    "    files_to_remove = [\"sample.txt\", \"sample.csv\", \"sample.json\"]\n",
    "    dirs_to_remove = [\"docs\", \"faiss_index\", \"chroma_db\"]\n",
    "\n",
    "    for file in files_to_remove:\n",
    "        if os.path.exists(file):\n",
    "            os.remove(file)\n",
    "\n",
    "    for dir in dirs_to_remove:\n",
    "        if os.path.exists(dir):\n",
    "            shutil.rmtree(dir)\n",
    "\n",
    "    print(\"ğŸ§¹ ä¸´æ—¶æ–‡ä»¶å·²æ¸…ç†\")\n"
   ],
   "id": "7f6e6f544e1599ac",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T16:10:35.612852Z",
     "start_time": "2025-07-22T16:10:17.081402Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # è¿è¡ŒåŒæ­¥ç¤ºä¾‹\n",
    "    main()\n",
    "\n",
    "    # è¿è¡Œå¼‚æ­¥ç¤ºä¾‹\n",
    "    # asyncio.run(performance_optimization_example())"
   ],
   "id": "1588268b0cb2662",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ LangChain 0.3 Data Connection å®Œæ•´ç¤ºä¾‹\n",
      "================================================================================\n",
      "\n",
      "============================================================\n",
      "1. Document Loaders æ–‡æ¡£åŠ è½½å™¨ç¤ºä¾‹\n",
      "============================================================\n",
      "\n",
      "1.1 æ–‡æœ¬æ–‡ä»¶åŠ è½½\n",
      "åŠ è½½çš„æ–‡æ¡£æ•°é‡: 1\n",
      "æ–‡æ¡£å†…å®¹é¢„è§ˆ: \n",
      "        äººå·¥æ™ºèƒ½ï¼ˆAIï¼‰æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œè‡´åŠ›äºåˆ›å»ºèƒ½å¤Ÿæ‰§è¡Œé€šå¸¸éœ€è¦äººç±»æ™ºèƒ½çš„ä»»åŠ¡çš„ç³»ç»Ÿã€‚\n",
      "        æœºå™¨å­¦ä¹ æ˜¯AIçš„ä¸€ä¸ªå­é›†ï¼Œå®ƒä½¿è®¡ç®—æœºèƒ½å¤Ÿä»æ•°æ®ä¸­å­¦ä¹ è€Œæ— éœ€æ˜ç¡®ç¼–ç¨‹ã€‚\n",
      "   ...\n",
      "\n",
      "1.2 CSVæ–‡ä»¶åŠ è½½\n",
      "CSVæ–‡æ¡£æ•°é‡: 3\n",
      "CSVæ–‡æ¡£ç¤ºä¾‹: name: å¼ ä¸‰\n",
      "age: 25\n",
      "city: åŒ—äº¬\n",
      "description: è½¯ä»¶å·¥ç¨‹å¸ˆ\n",
      "\n",
      "1.3 JSONæ–‡ä»¶åŠ è½½\n",
      "JSONæ–‡æ¡£æ•°é‡: 2\n",
      "JSONæ–‡æ¡£ç¤ºä¾‹: Pythonæ˜¯ä¸€ç§é«˜çº§ç¼–ç¨‹è¯­è¨€\n",
      "\n",
      "1.4 ç›®å½•æ‰¹é‡åŠ è½½\n",
      "ç›®å½•æ–‡æ¡£æ•°é‡: 3\n",
      "\n",
      "============================================================\n",
      "2. Text Splitters æ–‡æœ¬åˆ†å‰²å™¨ç¤ºä¾‹\n",
      "============================================================\n",
      "\n",
      "2.1 RecursiveCharacterTextSplitter\n",
      "é€’å½’åˆ†å‰²å—æ•°: 2\n",
      "å— 1: äººå·¥æ™ºèƒ½çš„å‘å±•å†ç¨‹å¯ä»¥è¿½æº¯åˆ°20ä¸–çºª50å¹´ä»£ã€‚å½“æ—¶ï¼Œè®¡ç®—æœºç§‘å­¦å®¶å¼€å§‹æ¢ç´¢è®©æœºå™¨æ¨¡æ‹Ÿäººç±»æ™ºèƒ½çš„å¯èƒ½æ€§ã€‚\n",
      "\n",
      "    åœ¨1956å¹´çš„è¾¾ç‰¹èŒ…æ–¯ä¼šè®®ä¸Šï¼Œäººå·¥æ™ºèƒ½è¿™ä¸ªæœ¯è¯­é¦–æ¬¡è¢«æ­£å¼æå‡ºã€‚è¿™æ ‡å¿—ç€AIä½œä¸ºä¸€ä¸ªç‹¬ç«‹å­¦...\n",
      "å— 2: 80å¹´ä»£æœ«åˆ°90å¹´ä»£åˆï¼Œç”±äºæŠ€æœ¯é™åˆ¶å’Œè¿‡é«˜æœŸæœ›ï¼ŒAIè¿›å…¥äº†æ‰€è°“çš„\"AIå†¬å¤©\"ã€‚\n",
      "\n",
      "    21ä¸–çºªä»¥æ¥ï¼Œéšç€å¤§æ•°æ®ã€äº‘è®¡ç®—å’Œæ·±åº¦å­¦ä¹ çš„å‘å±•ï¼ŒAIè¿æ¥äº†æ–°çš„æ˜¥å¤©ã€‚\n",
      "\n",
      "    ä»Šå¤©ï¼ŒAIå·²ç»åœ¨å›¾åƒè¯†åˆ«ã€è‡ª...\n",
      "\n",
      "2.2 CharacterTextSplitter\n",
      "å­—ç¬¦åˆ†å‰²å—æ•°: 1\n",
      "\n",
      "2.3 TokenTextSplitter\n",
      "Tokenåˆ†å‰²å—æ•°: 7\n",
      "\n",
      "2.4 MarkdownHeaderTextSplitter\n",
      "Markdownåˆ†å‰²å—æ•°: 4\n",
      "\n",
      "============================================================\n",
      "3. Embedding Models åµŒå…¥æ¨¡å‹ç¤ºä¾‹\n",
      "============================================================\n",
      "\n",
      "3.1 OllamaåµŒå…¥æ¨¡å‹\n",
      "æ–‡æ¡£åµŒå…¥æ•°é‡: 4\n",
      "åµŒå…¥å‘é‡ç»´åº¦: 768\n",
      "æŸ¥è¯¢åµŒå…¥ç»´åº¦: 768\n",
      "\n",
      "ç›¸ä¼¼åº¦è®¡ç®—:\n",
      "'äººå·¥æ™ºèƒ½æ˜¯è®¡ç®—æœºç§‘å­¦çš„åˆ†æ”¯' ç›¸ä¼¼åº¦: 0.8551\n",
      "'æœºå™¨å­¦ä¹ æ˜¯AIçš„å­é›†' ç›¸ä¼¼åº¦: 0.6135\n",
      "'æ·±åº¦å­¦ä¹ ä½¿ç”¨ç¥ç»ç½‘ç»œ' ç›¸ä¼¼åº¦: 0.5818\n",
      "'ä»Šå¤©å¤©æ°”å¾ˆå¥½' ç›¸ä¼¼åº¦: 0.5851\n",
      "\n",
      "============================================================\n",
      "4. Vector Stores å‘é‡å­˜å‚¨ç¤ºä¾‹\n",
      "============================================================\n",
      "\n",
      "4.1 FAISSå‘é‡å­˜å‚¨\n",
      "âœ… FAISSç´¢å¼•å·²ä¿å­˜\n",
      "\n",
      "æŸ¥è¯¢: 'äººå·¥æ™ºèƒ½çš„å‘å±•'\n",
      "ç›¸ä¼¼æ–‡æ¡£:\n",
      "1. äººå·¥æ™ºèƒ½çš„å‘å±•å†ç¨‹å¯ä»¥è¿½æº¯åˆ°20ä¸–çºª50å¹´ä»£ã€‚å½“æ—¶ï¼Œè®¡ç®—æœºç§‘å­¦å®¶å¼€å§‹æ¢ç´¢è®©æœºå™¨æ¨¡æ‹Ÿäººç±»æ™ºèƒ½çš„å¯èƒ½æ€§ã€‚\n",
      "\n",
      "    åœ¨1956å¹´çš„è¾¾ç‰¹èŒ…æ–¯ä¼šè®®ä¸Šï¼Œäººå·¥æ™ºèƒ½è¿™ä¸ªæœ¯è¯­é¦–æ¬¡è¢«æ­£å¼æå‡ºã€‚è¿™æ ‡å¿—ç€AIä½œä¸ºä¸€ä¸ªç‹¬ç«‹å­¦...\n",
      "2. 80å¹´ä»£æœ«åˆ°90å¹´ä»£åˆï¼Œç”±äºæŠ€æœ¯é™åˆ¶å’Œè¿‡é«˜æœŸæœ›ï¼ŒAIè¿›å…¥äº†æ‰€è°“çš„\"AIå†¬å¤©\"ã€‚\n",
      "\n",
      "    21ä¸–çºªä»¥æ¥ï¼Œéšç€å¤§æ•°æ®ã€äº‘è®¡ç®—å’Œæ·±åº¦å­¦ä¹ çš„å‘å±•ï¼ŒAIè¿æ¥äº†æ–°çš„æ˜¥å¤©ã€‚\n",
      "\n",
      "    ä»Šå¤©ï¼ŒAIå·²ç»åœ¨å›¾åƒè¯†åˆ«ã€è‡ª...\n",
      "\n",
      "å¸¦åˆ†æ•°çš„æœç´¢ç»“æœ:\n",
      "1. åˆ†æ•°: 0.4337 - äººå·¥æ™ºèƒ½çš„å‘å±•å†ç¨‹å¯ä»¥è¿½æº¯åˆ°20ä¸–çºª50å¹´ä»£ã€‚å½“æ—¶ï¼Œè®¡ç®—æœºç§‘å­¦å®¶å¼€å§‹æ¢ç´¢è®©æœºå™¨æ¨¡æ‹Ÿäººç±»æ™ºèƒ½çš„å¯èƒ½æ€§ã€‚\n",
      "\n",
      "    åœ¨1956å¹´çš„è¾¾ç‰¹èŒ…æ–¯ä¼šè®®ä¸Šï¼Œäººå·¥æ™ºèƒ½è¿™ä¸ªæœ¯è¯­é¦–...\n",
      "2. åˆ†æ•°: 0.7495 - 80å¹´ä»£æœ«åˆ°90å¹´ä»£åˆï¼Œç”±äºæŠ€æœ¯é™åˆ¶å’Œè¿‡é«˜æœŸæœ›ï¼ŒAIè¿›å…¥äº†æ‰€è°“çš„\"AIå†¬å¤©\"ã€‚\n",
      "\n",
      "    21ä¸–çºªä»¥æ¥ï¼Œéšç€å¤§æ•°æ®ã€äº‘è®¡ç®—å’Œæ·±åº¦å­¦ä¹ çš„å‘å±•ï¼ŒAIè¿æ¥äº†æ–°çš„æ˜¥å¤©ã€‚...\n",
      "\n",
      "4.2 Chromaå‘é‡å­˜å‚¨\n",
      "âœ… Chromaæ•°æ®åº“å·²æŒä¹…åŒ–\n",
      "Chromaæœç´¢ç»“æœæ•°é‡: 2\n",
      "\n",
      "============================================================\n",
      "5. Retrievers æ£€ç´¢å™¨ç¤ºä¾‹\n",
      "============================================================\n",
      "\n",
      "5.1 å‘é‡å­˜å‚¨æ£€ç´¢å™¨\n",
      "å‘é‡æ£€ç´¢ç»“æœæ•°é‡: 2\n",
      "1. äººå·¥æ™ºèƒ½çš„å‘å±•å†ç¨‹å¯ä»¥è¿½æº¯åˆ°20ä¸–çºª50å¹´ä»£ã€‚å½“æ—¶ï¼Œè®¡ç®—æœºç§‘å­¦å®¶å¼€å§‹æ¢ç´¢è®©æœºå™¨æ¨¡æ‹Ÿäººç±»æ™ºèƒ½çš„å¯èƒ½æ€§ã€‚\n",
      "\n",
      "    åœ¨1956å¹´çš„è¾¾ç‰¹èŒ…æ–¯ä¼šè®®ä¸Šï¼Œäººå·¥æ™ºèƒ½è¿™ä¸ªæœ¯è¯­é¦–æ¬¡è¢«æ­£å¼æå‡ºã€‚è¿™æ ‡å¿—ç€AIä½œä¸ºä¸€ä¸ªç‹¬ç«‹å­¦...\n",
      "2. 80å¹´ä»£æœ«åˆ°90å¹´ä»£åˆï¼Œç”±äºæŠ€æœ¯é™åˆ¶å’Œè¿‡é«˜æœŸæœ›ï¼ŒAIè¿›å…¥äº†æ‰€è°“çš„\"AIå†¬å¤©\"ã€‚\n",
      "\n",
      "    21ä¸–çºªä»¥æ¥ï¼Œéšç€å¤§æ•°æ®ã€äº‘è®¡ç®—å’Œæ·±åº¦å­¦ä¹ çš„å‘å±•ï¼ŒAIè¿æ¥äº†æ–°çš„æ˜¥å¤©ã€‚\n",
      "\n",
      "    ä»Šå¤©ï¼ŒAIå·²ç»åœ¨å›¾åƒè¯†åˆ«ã€è‡ª...\n",
      "\n",
      "5.2 BM25æ£€ç´¢å™¨\n",
      "BM25æ£€ç´¢ç»“æœæ•°é‡: 2\n",
      "1. 80å¹´ä»£æœ«åˆ°90å¹´ä»£åˆï¼Œç”±äºæŠ€æœ¯é™åˆ¶å’Œè¿‡é«˜æœŸæœ›ï¼ŒAIè¿›å…¥äº†æ‰€è°“çš„\"AIå†¬å¤©\"ã€‚\n",
      "\n",
      "    21ä¸–çºªä»¥æ¥ï¼Œéšç€å¤§æ•°æ®ã€äº‘è®¡ç®—å’Œæ·±åº¦å­¦ä¹ çš„å‘å±•ï¼ŒAIè¿æ¥äº†æ–°çš„æ˜¥å¤©ã€‚\n",
      "\n",
      "    ä»Šå¤©ï¼ŒAIå·²ç»åœ¨å›¾åƒè¯†åˆ«ã€è‡ª...\n",
      "2. äººå·¥æ™ºèƒ½çš„å‘å±•å†ç¨‹å¯ä»¥è¿½æº¯åˆ°20ä¸–çºª50å¹´ä»£ã€‚å½“æ—¶ï¼Œè®¡ç®—æœºç§‘å­¦å®¶å¼€å§‹æ¢ç´¢è®©æœºå™¨æ¨¡æ‹Ÿäººç±»æ™ºèƒ½çš„å¯èƒ½æ€§ã€‚\n",
      "\n",
      "    åœ¨1956å¹´çš„è¾¾ç‰¹èŒ…æ–¯ä¼šè®®ä¸Šï¼Œäººå·¥æ™ºèƒ½è¿™ä¸ªæœ¯è¯­é¦–æ¬¡è¢«æ­£å¼æå‡ºã€‚è¿™æ ‡å¿—ç€AIä½œä¸ºä¸€ä¸ªç‹¬ç«‹å­¦...\n",
      "\n",
      "5.3 é›†æˆæ£€ç´¢å™¨\n",
      "é›†æˆæ£€ç´¢ç»“æœæ•°é‡: 2\n",
      "\n",
      "5.4 å¤šæŸ¥è¯¢æ£€ç´¢å™¨\n",
      "å¤šæŸ¥è¯¢æ£€ç´¢ç»“æœæ•°é‡: 2\n",
      "\n",
      "============================================================\n",
      "6. å®Œæ•´RAGæµç¨‹ç¤ºä¾‹\n",
      "============================================================\n",
      "\n",
      "é—®é¢˜: ä»€ä¹ˆæ˜¯LangChainï¼Ÿ\n",
      "å›ç­”: LangChainæ˜¯ä¸€ä¸ªç”¨äºæ„å»ºLLMåº”ç”¨çš„æ¡†æ¶ã€‚\n",
      "\n",
      "\n",
      "é—®é¢˜: å‘é‡æ•°æ®åº“çš„ä½œç”¨æ˜¯ä»€ä¹ˆï¼Ÿ\n",
      "å›ç­”: å‘é‡æ•°æ®åº“çš„ä½œç”¨æ˜¯å­˜å‚¨å’Œæ£€ç´¢é«˜ç»´å‘é‡ã€‚\n",
      "\n",
      "\n",
      "é—®é¢˜: RAGæŠ€æœ¯æœ‰ä»€ä¹ˆä¼˜åŠ¿ï¼Ÿ\n",
      "å›ç­”: RAGæŠ€æœ¯é€šè¿‡ç»“åˆæ£€ç´¢å’Œç”Ÿæˆï¼Œæé«˜äº†AIå›ç­”çš„å‡†ç¡®æ€§ã€‚\n",
      "\n",
      "\n",
      "============================================================\n",
      "7. é«˜çº§åŠŸèƒ½ç¤ºä¾‹\n",
      "============================================================\n",
      "\n",
      "7.1 è‡ªå®šä¹‰æ–‡æ¡£åŠ è½½å™¨\n",
      "è‡ªå®šä¹‰åŠ è½½å™¨æ–‡æ¡£æ•°é‡: 3\n",
      "\n",
      "7.2 æ–‡æ¡£è¿‡æ»¤å’Œé¢„å¤„ç†\n",
      "é¢„å¤„ç†åæ–‡æ¡£æ•°é‡: 1\n",
      "\n",
      "ğŸ‰ æ‰€æœ‰ç¤ºä¾‹è¿è¡Œå®Œæˆï¼\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[WinError 32] å¦ä¸€ä¸ªç¨‹åºæ­£åœ¨ä½¿ç”¨æ­¤æ–‡ä»¶ï¼Œè¿›ç¨‹æ— æ³•è®¿é—®ã€‚: 'chroma_db\\\\44933678-68e8-40b1-b8d1-9afc146a6630\\\\data_level0.bin'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mPermissionError\u001B[39m                           Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[15]\u001B[39m\u001B[32m, line 3\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[34m__name__\u001B[39m == \u001B[33m\"\u001B[39m\u001B[33m__main__\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m      2\u001B[39m     \u001B[38;5;66;03m# è¿è¡ŒåŒæ­¥ç¤ºä¾‹\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m3\u001B[39m     \u001B[43mmain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m      5\u001B[39m     \u001B[38;5;66;03m# è¿è¡Œå¼‚æ­¥ç¤ºä¾‹\u001B[39;00m\n\u001B[32m      6\u001B[39m     \u001B[38;5;66;03m# asyncio.run(performance_optimization_example())\u001B[39;00m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[14]\u001B[39m\u001B[32m, line 31\u001B[39m, in \u001B[36mmain\u001B[39m\u001B[34m()\u001B[39m\n\u001B[32m     28\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33mğŸ‰ æ‰€æœ‰ç¤ºä¾‹è¿è¡Œå®Œæˆï¼\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m     30\u001B[39m \u001B[38;5;66;03m# æ¸…ç†ä¸´æ—¶æ–‡ä»¶\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m31\u001B[39m \u001B[43mcleanup_files\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[14]\u001B[39m\u001B[32m, line 47\u001B[39m, in \u001B[36mcleanup_files\u001B[39m\u001B[34m()\u001B[39m\n\u001B[32m     45\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m \u001B[38;5;28mdir\u001B[39m \u001B[38;5;129;01min\u001B[39;00m dirs_to_remove:\n\u001B[32m     46\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m os.path.exists(\u001B[38;5;28mdir\u001B[39m):\n\u001B[32m---> \u001B[39m\u001B[32m47\u001B[39m         \u001B[43mshutil\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrmtree\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mdir\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m     49\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mğŸ§¹ ä¸´æ—¶æ–‡ä»¶å·²æ¸…ç†\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\shutil.py:758\u001B[39m, in \u001B[36mrmtree\u001B[39m\u001B[34m(path, ignore_errors, onerror, dir_fd)\u001B[39m\n\u001B[32m    756\u001B[39m     \u001B[38;5;66;03m# can't continue even if onerror hook returns\u001B[39;00m\n\u001B[32m    757\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m758\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_rmtree_unsafe\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43monerror\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\shutil.py:616\u001B[39m, in \u001B[36m_rmtree_unsafe\u001B[39m\u001B[34m(path, onerror)\u001B[39m\n\u001B[32m    614\u001B[39m         onerror(os.path.islink, fullname, sys.exc_info())\n\u001B[32m    615\u001B[39m         \u001B[38;5;28;01mcontinue\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m616\u001B[39m     \u001B[43m_rmtree_unsafe\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfullname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43monerror\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    617\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    618\u001B[39m     \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\shutil.py:621\u001B[39m, in \u001B[36m_rmtree_unsafe\u001B[39m\u001B[34m(path, onerror)\u001B[39m\n\u001B[32m    619\u001B[39m             os.unlink(fullname)\n\u001B[32m    620\u001B[39m         \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m621\u001B[39m             \u001B[43monerror\u001B[49m\u001B[43m(\u001B[49m\u001B[43mos\u001B[49m\u001B[43m.\u001B[49m\u001B[43munlink\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfullname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msys\u001B[49m\u001B[43m.\u001B[49m\u001B[43mexc_info\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    622\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m    623\u001B[39m     os.rmdir(path)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\shutil.py:619\u001B[39m, in \u001B[36m_rmtree_unsafe\u001B[39m\u001B[34m(path, onerror)\u001B[39m\n\u001B[32m    617\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    618\u001B[39m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m619\u001B[39m         os.unlink(fullname)\n\u001B[32m    620\u001B[39m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m:\n\u001B[32m    621\u001B[39m         onerror(os.unlink, fullname, sys.exc_info())\n",
      "\u001B[31mPermissionError\u001B[39m: [WinError 32] å¦ä¸€ä¸ªç¨‹åºæ­£åœ¨ä½¿ç”¨æ­¤æ–‡ä»¶ï¼Œè¿›ç¨‹æ— æ³•è®¿é—®ã€‚: 'chroma_db\\\\44933678-68e8-40b1-b8d1-9afc146a6630\\\\data_level0.bin'"
     ]
    }
   ],
   "execution_count": 15
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
