{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2. Text Splitters 示例",
   "id": "d04204e0aa4c610e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\"\"\"\n",
    "LangChain 0.3 Text Splitters 完整示例\n",
    "包含所有主要分割器类型和高级用法\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "from typing import List, Dict, Any\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.text_splitter import (\n",
    "    RecursiveCharacterTextSplitter,\n",
    "    CharacterTextSplitter,\n",
    "    TokenTextSplitter,\n",
    "    MarkdownHeaderTextSplitter,\n",
    "    HTMLHeaderTextSplitter,\n",
    "    PythonCodeTextSplitter,\n",
    "    LatexTextSplitter\n",
    ")\n",
    "from langchain_core.documents import Document"
   ],
   "id": "e286d0f29d242f0b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 创建示例文档用于测试",
   "id": "f31cadfdbdc1df48"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T04:37:15.626366Z",
     "start_time": "2025-07-23T04:37:15.620363Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'ai_history'}, page_content='人工智能的发展历程可以追溯到20世纪50年代。当时，计算机科学家开始探索让机器模拟人类智能的可能性。\\n\\n在1956年的达特茅斯会议上，人工智能这个术语首次被正式提出。这标志着AI作为一个独立学科的诞生。\\n\\n随后的几十年里，AI经历了多次起伏。60-70年代是第一个AI春天，专家系统得到了广泛应用。\\n\\n80年代末到90年代初，由于技术限制和过高期望，AI进入了所谓的\"AI冬天\"。\\n\\n21世纪以来，随着大数据、云计算和深度学习的发展，AI迎来了新的春天。\\n\\n今天，AI已经在图像识别、自然语言处理、推荐系统等领域取得了突破性进展。\\n\\n机器学习作为AI的核心技术，包括监督学习、无监督学习和强化学习三大类。深度学习则是机器学习的一个重要分支。\\n\\n自然语言处理（NLP）让计算机能够理解和生成人类语言。计算机视觉让机器能够\"看见\"和理解图像。\\n\\n未来，AI将在更多领域发挥重要作用，包括医疗、教育、交通、金融等。同时，AI的伦理和安全问题也需要得到重视。')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24,
   "source": [
    "\n",
    "def create_sample_documents():\n",
    "    \"\"\"创建示例文档用于测试\"\"\"\n",
    "\n",
    "    # 长文本示例\n",
    "    long_text = \"\"\"\n",
    "人工智能的发展历程可以追溯到20世纪50年代。当时，计算机科学家开始探索让机器模拟人类智能的可能性。\n",
    "\n",
    "在1956年的达特茅斯会议上，人工智能这个术语首次被正式提出。这标志着AI作为一个独立学科的诞生。\n",
    "\n",
    "随后的几十年里，AI经历了多次起伏。60-70年代是第一个AI春天，专家系统得到了广泛应用。\n",
    "\n",
    "80年代末到90年代初，由于技术限制和过高期望，AI进入了所谓的\"AI冬天\"。\n",
    "\n",
    "21世纪以来，随着大数据、云计算和深度学习的发展，AI迎来了新的春天。\n",
    "\n",
    "今天，AI已经在图像识别、自然语言处理、推荐系统等领域取得了突破性进展。\n",
    "\n",
    "机器学习作为AI的核心技术，包括监督学习、无监督学习和强化学习三大类。深度学习则是机器学习的一个重要分支。\n",
    "\n",
    "自然语言处理（NLP）让计算机能够理解和生成人类语言。计算机视觉让机器能够\"看见\"和理解图像。\n",
    "\n",
    "未来，AI将在更多领域发挥重要作用，包括医疗、教育、交通、金融等。同时，AI的伦理和安全问题也需要得到重视。\n",
    "    \"\"\"\n",
    "\n",
    "    return Document(page_content=long_text.strip(), metadata={\"source\": \"ai_history\"})\n",
    "create_sample_documents()"
   ],
   "id": "7e2b94334daef2c3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 递归字符分割器示例 - 推荐使用",
   "id": "bd9a1f6daabf84f6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T04:38:06.056307Z",
     "start_time": "2025-07-23T04:38:06.048370Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "1. RecursiveCharacterTextSplitter（推荐）\n",
      "============================================================\n",
      "\n",
      "1.1 基础递归分割\n",
      "基础分割块数: 3\n",
      "块 1 (长度: 190): 人工智能的发展历程可以追溯到20世纪50年代。当时，计算机科学家开始探索让机器模拟人类智能的可能性。\n",
      "\n",
      "在1956年的达特茅斯会议上，人工智能这个术语首次被正式...\n",
      "块 2 (长度: 169): 80年代末到90年代初，由于技术限制和过高期望，AI进入了所谓的\"AI冬天\"。\n",
      "\n",
      "21世纪以来，随着大数据、云计算和深度学习的发展，AI迎来了新的春天。\n",
      "\n",
      "今天...\n",
      "块 3 (长度: 103): 自然语言处理（NLP）让计算机能够理解和生成人类语言。计算机视觉让机器能够\"看见\"和理解图像。\n",
      "\n",
      "未来，AI将在更多领域发挥重要作用，包括医疗、教育、交通、金融...\n",
      "\n",
      "1.2 自定义分隔符优先级\n",
      "自定义分割块数: 4\n",
      "\n",
      "1.3 段落优先分割\n",
      "段落分割块数: 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'ai_history'}, page_content='人工智能的发展历程可以追溯到20世纪50年代。当时，计算机科学家开始探索让机器模拟人类智能的可能性。\\n\\n在1956年的达特茅斯会议上，人工智能这个术语首次被正式提出。这标志着AI作为一个独立学科的诞生。\\n\\n随后的几十年里，AI经历了多次起伏。60-70年代是第一个AI春天，专家系统得到了广泛应用。\\n\\n80年代末到90年代初，由于技术限制和过高期望，AI进入了所谓的\"AI冬天\"。'),\n",
       " Document(metadata={'source': 'ai_history'}, page_content='80年代末到90年代初，由于技术限制和过高期望，AI进入了所谓的\"AI冬天\"。\\n\\n21世纪以来，随着大数据、云计算和深度学习的发展，AI迎来了新的春天。\\n\\n今天，AI已经在图像识别、自然语言处理、推荐系统等领域取得了突破性进展。\\n\\n机器学习作为AI的核心技术，包括监督学习、无监督学习和强化学习三大类。深度学习则是机器学习的一个重要分支。'),\n",
       " Document(metadata={'source': 'ai_history'}, page_content='自然语言处理（NLP）让计算机能够理解和生成人类语言。计算机视觉让机器能够\"看见\"和理解图像。\\n\\n未来，AI将在更多领域发挥重要作用，包括医疗、教育、交通、金融等。同时，AI的伦理和安全问题也需要得到重视。')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25,
   "source": [
    "\n",
    "def recursive_character_splitter_example():\n",
    "    \"\"\"递归字符分割器示例 - 推荐使用\"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"1. RecursiveCharacterTextSplitter（推荐）\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    doc = create_sample_documents()\n",
    "\n",
    "    # 1.1 基础用法\n",
    "    print(\"\\n1.1 基础递归分割\")\n",
    "    basic_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=200,           # 块大小\n",
    "        chunk_overlap=50,         # 重叠大小\n",
    "        length_function=len,      # 长度计算函数\n",
    "        is_separator_regex=False  # 分隔符是否为正则表达式\n",
    "    )\n",
    "\n",
    "    basic_chunks = basic_splitter.split_documents([doc])\n",
    "    print(f\"基础分割块数: {len(basic_chunks)}\")\n",
    "    for i, chunk in enumerate(basic_chunks[:3]):\n",
    "        print(f\"块 {i+1} (长度: {len(chunk.page_content)}): {chunk.page_content[:80]}...\")\n",
    "\n",
    "    # 1.2 自定义分隔符\n",
    "    print(\"\\n1.2 自定义分隔符优先级\")\n",
    "    custom_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=150,\n",
    "        chunk_overlap=30,\n",
    "        separators=[\n",
    "            \"\\n\\n\",    # 段落分隔符（最高优先级）\n",
    "            \"\\n\",      # 行分隔符\n",
    "            \"。\",      # 中文句号\n",
    "            \"！\",      # 中文感叹号\n",
    "            \"？\",      # 中文问号\n",
    "            \"，\",      # 中文逗号\n",
    "            \" \",       # 空格\n",
    "            \"\"         # 字符级分割（最后手段）\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    custom_chunks = custom_splitter.split_documents([doc])\n",
    "    print(f\"自定义分割块数: {len(custom_chunks)}\")\n",
    "\n",
    "    # 1.3 保持段落完整性\n",
    "    print(\"\\n1.3 段落优先分割\")\n",
    "    paragraph_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=300,\n",
    "        chunk_overlap=50,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \"。\", \" \", \"\"]\n",
    "    )\n",
    "\n",
    "    para_chunks = paragraph_splitter.split_documents([doc])\n",
    "    print(f\"段落分割块数: {len(para_chunks)}\")\n",
    "\n",
    "    return basic_chunks\n",
    "recursive_character_splitter_example()"
   ],
   "id": "a7b4a9bf5d897bed"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 字符文本分割器示例",
   "id": "9bf3be8b9e58d707"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "def character_text_splitter_example():\n",
    "    \"\"\"字符文本分割器示例\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"2. CharacterTextSplitter\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    doc = create_sample_documents()\n",
    "\n",
    "    # 2.1 按段落分割\n",
    "    print(\"\\n2.1 按段落分割\")\n",
    "    para_splitter = CharacterTextSplitter(\n",
    "        chunk_size=300,\n",
    "        chunk_overlap=50,\n",
    "        separator=\"\\n\\n\"  # 只使用段落分隔符\n",
    "    )\n",
    "\n",
    "    para_chunks = para_splitter.split_documents([doc])\n",
    "    print(f\"段落分割块数: {len(para_chunks)}\")\n",
    "\n",
    "    # 2.2 按句子分割\n",
    "    print(\"\\n2.2 按句子分割\")\n",
    "    sentence_splitter = CharacterTextSplitter(\n",
    "        chunk_size=100,\n",
    "        chunk_overlap=20,\n",
    "        separator=\"。\"  # 按中文句号分割\n",
    "    )\n",
    "\n",
    "    sentence_chunks = sentence_splitter.split_documents([doc])\n",
    "    print(f\"句子分割块数: {len(sentence_chunks)}\")\n",
    "\n",
    "    # 2.3 自定义分隔符\n",
    "    print(\"\\n2.3 自定义分隔符\")\n",
    "    custom_text = \"项目A|项目B|项目C|项目D|项目E的详细描述和分析报告\"\n",
    "    custom_doc = Document(page_content=custom_text)\n",
    "\n",
    "    custom_splitter = CharacterTextSplitter(\n",
    "        chunk_size=20,\n",
    "        chunk_overlap=0,\n",
    "        separator=\"|\"\n",
    "    )\n",
    "\n",
    "    custom_chunks = custom_splitter.split_documents([custom_doc])\n",
    "    print(f\"自定义分割块数: {len(custom_chunks)}\")\n",
    "    for chunk in custom_chunks:\n",
    "        print(f\"  - {chunk.page_content}\")\n",
    "\n",
    "    return para_chunks\n",
    "character_text_splitter_example()"
   ],
   "id": "cc22a799d634b47c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Token文本分割器示例",
   "id": "5c6cf3ff17d8e3ef"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T04:39:44.020099Z",
     "start_time": "2025-07-23T04:39:44.010096Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "3. TokenTextSplitter\n",
      "============================================================\n",
      "\n",
      "3.1 基础Token分割\n",
      "Token分割块数: 6\n",
      "块 1 Token数: 100, 内容: 人工智能的发展历程可以追溯到20世纪50年代。当时，计算机科学家开始探索让机器模拟人类智能的可能性。\n",
      "\n",
      "在1956年的达...\n",
      "块 2 Token数: 100, 内容: 次被正式提出。这标志着AI作为一个独立学科的诞生。\n",
      "\n",
      "随后的几十年里，AI经历了多次起伏。60-70年代是第一个AI春天...\n",
      "块 3 Token数: 100, 内容: 年代初，由于技术限制和过高期望，AI进入了所谓的\"AI冬天\"。\n",
      "\n",
      "21世纪以来，随着大数据、云计算和深度学习的发展，AI...\n",
      "\n",
      "3.2 不同模型Token分割对比\n",
      "gpt-3.5-turbo: 11 块\n",
      "text-davinci-003: 21 块\n",
      "gpt-4: 11 块\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'ai_history'}, page_content='人工智能的发展历程可以追溯到20世纪50年代。当时，计算机科学家开始探索让机器模拟人类智能的可能性。\\n\\n在1956年的达特茅斯会议上，人工智能这个术语首次被正式提出。这标志着AI作为一个独'),\n",
       " Document(metadata={'source': 'ai_history'}, page_content='次被正式提出。这标志着AI作为一个独立学科的诞生。\\n\\n随后的几十年里，AI经历了多次起伏。60-70年代是第一个AI春天，专家系统得到了广泛应用。\\n\\n80年代末到90年代初，由于技术限制和过高期望，AI进'),\n",
       " Document(metadata={'source': 'ai_history'}, page_content='年代初，由于技术限制和过高期望，AI进入了所谓的\"AI冬天\"。\\n\\n21世纪以来，随着大数据、云计算和深度学习的发展，AI迎来了新的春天。\\n\\n今天，AI已经在图像识别、自然语言处理、推荐系统等领'),\n",
       " Document(metadata={'source': 'ai_history'}, page_content='在图像识别、自然语言处理、推荐系统等领域取得了突破性进展。\\n\\n机器学习作为AI的核心技术，包括监督学习、无监督学习和强化学习三大类。深度学习则是机器学习的一个重要分支。\\n\\n自然语'),\n",
       " Document(metadata={'source': 'ai_history'}, page_content='学习则是机器学习的一个重要分支。\\n\\n自然语言处理（NLP）让计算机能够理解和生成人类语言。计算机视觉让机器能够\"看见\"和理解图像。\\n\\n未来，AI将在更多领域发挥重要作用，包括医疗、教育、'),\n",
       " Document(metadata={'source': 'ai_history'}, page_content='�重要作用，包括医疗、教育、交通、金融等。同时，AI的伦理和安全问题也需要得到重视。')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26,
   "source": [
    "\n",
    "def token_text_splitter_example():\n",
    "    \"\"\"Token文本分割器示例\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"3. TokenTextSplitter\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    doc = create_sample_documents()\n",
    "\n",
    "    # 3.1 基础Token分割\n",
    "    print(\"\\n3.1 基础Token分割\")\n",
    "    token_splitter = TokenTextSplitter(\n",
    "        chunk_size=100,      # Token数量\n",
    "        chunk_overlap=20,    # 重叠Token数\n",
    "        model_name=\"gpt-3.5-turbo\"  # 指定tokenizer模型\n",
    "    )\n",
    "\n",
    "    token_chunks = token_splitter.split_documents([doc])\n",
    "    print(f\"Token分割块数: {len(token_chunks)}\")\n",
    "\n",
    "    # 显示每块的实际token数\n",
    "    for i, chunk in enumerate(token_chunks[:3]):\n",
    "        token_count = token_splitter._tokenizer.encode(chunk.page_content)\n",
    "        print(f\"块 {i+1} Token数: {len(token_count)}, 内容: {chunk.page_content[:60]}...\")\n",
    "\n",
    "    # 3.2 不同模型的Token分割\n",
    "    print(\"\\n3.2 不同模型Token分割对比\")\n",
    "    models = [\"gpt-3.5-turbo\", \"text-davinci-003\", \"gpt-4\"]\n",
    "\n",
    "    for model in models:\n",
    "        try:\n",
    "            model_splitter = TokenTextSplitter(\n",
    "                chunk_size=50,\n",
    "                chunk_overlap=10,\n",
    "                model_name=model\n",
    "            )\n",
    "            model_chunks = model_splitter.split_documents([doc])\n",
    "            print(f\"{model}: {len(model_chunks)} 块\")\n",
    "        except Exception as e:\n",
    "            print(f\"{model}: 不支持 ({e})\")\n",
    "\n",
    "    return token_chunks\n",
    "token_text_splitter_example()"
   ],
   "id": "4e215287c2e041bc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Markdown标题分割器示例",
   "id": "9eee378b0c928b20"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T04:39:47.529630Z",
     "start_time": "2025-07-23T04:39:47.521482Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "4. MarkdownHeaderTextSplitter\n",
      "============================================================\n",
      "\n",
      "4.1 基础标题分割\n",
      "Markdown分割块数: 8\n",
      "\n",
      "块 1:\n",
      "内容: 监督学习是机器学习的一个重要分支，使用标记的训练数据来学习输入到输出的映射。  \n",
      "常见算法包括：\n",
      "- 线性回归\n",
      "- 逻辑回归\n",
      "- 决策树\n",
      "- 随机森林...\n",
      "元数据: {'Header 1': '人工智能技术指南', 'Header 2': '1. 机器学习基础', 'Header 3': '1.1 监督学习'}\n",
      "\n",
      "块 2:\n",
      "内容: 无监督学习从未标记的数据中发现隐藏的模式。  \n",
      "主要方法：\n",
      "- 聚类分析\n",
      "- 降维技术\n",
      "- 关联规则挖掘...\n",
      "元数据: {'Header 1': '人工智能技术指南', 'Header 2': '1. 机器学习基础', 'Header 3': '1.2 无监督学习'}\n",
      "\n",
      "块 3:\n",
      "内容: 神经网络是深度学习的基础，模拟人脑神经元的工作方式。...\n",
      "元数据: {'Header 1': '人工智能技术指南', 'Header 2': '2. 深度学习', 'Header 3': '2.1 神经网络基础'}\n",
      "\n",
      "块 4:\n",
      "内容: CNN主要用于图像处理和计算机视觉任务。...\n",
      "元数据: {'Header 1': '人工智能技术指南', 'Header 2': '2. 深度学习', 'Header 3': '2.2 卷积神经网络'}\n",
      "\n",
      "块 5:\n",
      "内容: RNN适合处理序列数据，如文本和时间序列。...\n",
      "元数据: {'Header 1': '人工智能技术指南', 'Header 2': '2. 深度学习', 'Header 3': '2.3 循环神经网络'}\n",
      "\n",
      "4.2 结合递归分割器进行二次分割\n",
      "二次分割后块数: 8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'Header 1': '人工智能技术指南', 'Header 2': '1. 机器学习基础', 'Header 3': '1.1 监督学习'}, page_content='监督学习是机器学习的一个重要分支，使用标记的训练数据来学习输入到输出的映射。  \\n常见算法包括：\\n- 线性回归\\n- 逻辑回归\\n- 决策树\\n- 随机森林'),\n",
       " Document(metadata={'Header 1': '人工智能技术指南', 'Header 2': '1. 机器学习基础', 'Header 3': '1.2 无监督学习'}, page_content='无监督学习从未标记的数据中发现隐藏的模式。  \\n主要方法：\\n- 聚类分析\\n- 降维技术\\n- 关联规则挖掘'),\n",
       " Document(metadata={'Header 1': '人工智能技术指南', 'Header 2': '2. 深度学习', 'Header 3': '2.1 神经网络基础'}, page_content='神经网络是深度学习的基础，模拟人脑神经元的工作方式。'),\n",
       " Document(metadata={'Header 1': '人工智能技术指南', 'Header 2': '2. 深度学习', 'Header 3': '2.2 卷积神经网络'}, page_content='CNN主要用于图像处理和计算机视觉任务。'),\n",
       " Document(metadata={'Header 1': '人工智能技术指南', 'Header 2': '2. 深度学习', 'Header 3': '2.3 循环神经网络'}, page_content='RNN适合处理序列数据，如文本和时间序列。'),\n",
       " Document(metadata={'Header 1': '人工智能技术指南', 'Header 2': '3. 自然语言处理', 'Header 3': '3.1 文本预处理'}, page_content='包括分词、词性标注、命名实体识别等步骤。'),\n",
       " Document(metadata={'Header 1': '人工智能技术指南', 'Header 2': '3. 自然语言处理', 'Header 3': '3.2 语言模型'}, page_content='从统计语言模型到现代的Transformer模型。'),\n",
       " Document(metadata={'Header 1': '总结'}, page_content='人工智能技术正在快速发展，各个领域都有重要突破。')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 27,
   "source": [
    "\n",
    "def markdown_header_splitter_example():\n",
    "    \"\"\"Markdown标题分割器示例\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"4. MarkdownHeaderTextSplitter\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # 创建Markdown文档\n",
    "    markdown_text = \"\"\"\n",
    "# 人工智能技术指南\n",
    "\n",
    "## 1. 机器学习基础\n",
    "\n",
    "### 1.1 监督学习\n",
    "监督学习是机器学习的一个重要分支，使用标记的训练数据来学习输入到输出的映射。\n",
    "\n",
    "常见算法包括：\n",
    "- 线性回归\n",
    "- 逻辑回归\n",
    "- 决策树\n",
    "- 随机森林\n",
    "\n",
    "### 1.2 无监督学习\n",
    "无监督学习从未标记的数据中发现隐藏的模式。\n",
    "\n",
    "主要方法：\n",
    "- 聚类分析\n",
    "- 降维技术\n",
    "- 关联规则挖掘\n",
    "\n",
    "## 2. 深度学习\n",
    "\n",
    "### 2.1 神经网络基础\n",
    "神经网络是深度学习的基础，模拟人脑神经元的工作方式。\n",
    "\n",
    "### 2.2 卷积神经网络\n",
    "CNN主要用于图像处理和计算机视觉任务。\n",
    "\n",
    "### 2.3 循环神经网络\n",
    "RNN适合处理序列数据，如文本和时间序列。\n",
    "\n",
    "## 3. 自然语言处理\n",
    "\n",
    "### 3.1 文本预处理\n",
    "包括分词、词性标注、命名实体识别等步骤。\n",
    "\n",
    "### 3.2 语言模型\n",
    "从统计语言模型到现代的Transformer模型。\n",
    "\n",
    "# 总结\n",
    "\n",
    "人工智能技术正在快速发展，各个领域都有重要突破。\n",
    "\"\"\"\n",
    "\n",
    "    # 4.1 基础标题分割\n",
    "    print(\"\\n4.1 基础标题分割\")\n",
    "    md_splitter = MarkdownHeaderTextSplitter(\n",
    "        headers_to_split_on=[\n",
    "            (\"#\", \"Header 1\"),\n",
    "            (\"##\", \"Header 2\"),\n",
    "            (\"###\", \"Header 3\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    md_chunks = md_splitter.split_text(markdown_text)\n",
    "    print(f\"Markdown分割块数: {len(md_chunks)}\")\n",
    "\n",
    "    for i, chunk in enumerate(md_chunks[:5]):\n",
    "        print(f\"\\n块 {i+1}:\")\n",
    "        print(f\"内容: {chunk.page_content[:100]}...\")\n",
    "        print(f\"元数据: {chunk.metadata}\")\n",
    "\n",
    "    # 4.2 结合递归分割器\n",
    "    print(\"\\n4.2 结合递归分割器进行二次分割\")\n",
    "\n",
    "    # 先按标题分割\n",
    "    md_docs = md_splitter.split_text(markdown_text)\n",
    "\n",
    "    # 再对长块进行递归分割\n",
    "    recursive_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=200,\n",
    "        chunk_overlap=50\n",
    "    )\n",
    "\n",
    "    final_chunks = []\n",
    "    for doc in md_docs:\n",
    "        if len(doc.page_content) > 200:\n",
    "            sub_chunks = recursive_splitter.split_documents([doc])\n",
    "            final_chunks.extend(sub_chunks)\n",
    "        else:\n",
    "            final_chunks.append(doc)\n",
    "\n",
    "    print(f\"二次分割后块数: {len(final_chunks)}\")\n",
    "\n",
    "    return md_chunks\n",
    "markdown_header_splitter_example()"
   ],
   "id": "fa4e721a4a0bae66"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### HTML标题分割器示例",
   "id": "393bdb3954618913"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T04:40:33.308628Z",
     "start_time": "2025-07-23T04:40:33.300629Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "5. HTMLHeaderTextSplitter\n",
      "============================================================\n",
      "HTML分割块数: 14\n",
      "\n",
      "块 1:\n",
      "内容: 人工智能概述...\n",
      "元数据: {'Header 1': '人工智能概述'}\n",
      "\n",
      "块 2:\n",
      "内容: 人工智能是计算机科学的一个分支。...\n",
      "元数据: {'Header 1': '人工智能概述'}\n",
      "\n",
      "块 3:\n",
      "内容: 机器学习...\n",
      "元数据: {'Header 1': '人工智能概述', 'Header 2': '机器学习'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'Header 1': '人工智能概述'}, page_content='人工智能概述'),\n",
       " Document(metadata={'Header 1': '人工智能概述'}, page_content='人工智能是计算机科学的一个分支。'),\n",
       " Document(metadata={'Header 1': '人工智能概述', 'Header 2': '机器学习'}, page_content='机器学习'),\n",
       " Document(metadata={'Header 1': '人工智能概述', 'Header 2': '机器学习'}, page_content='机器学习是AI的重要组成部分。'),\n",
       " Document(metadata={'Header 1': '人工智能概述', 'Header 2': '机器学习', 'Header 3': '监督学习'}, page_content='监督学习'),\n",
       " Document(metadata={'Header 1': '人工智能概述', 'Header 2': '机器学习', 'Header 3': '监督学习'}, page_content='使用标记数据进行训练。'),\n",
       " Document(metadata={'Header 1': '人工智能概述', 'Header 2': '机器学习', 'Header 3': '无监督学习'}, page_content='无监督学习'),\n",
       " Document(metadata={'Header 1': '人工智能概述', 'Header 2': '机器学习', 'Header 3': '无监督学习'}, page_content='从未标记数据中发现模式。'),\n",
       " Document(metadata={'Header 1': '人工智能概述', 'Header 2': '深度学习'}, page_content='深度学习'),\n",
       " Document(metadata={'Header 1': '人工智能概述', 'Header 2': '深度学习'}, page_content='基于神经网络的学习方法。'),\n",
       " Document(metadata={'Header 1': '人工智能概述', 'Header 2': '深度学习', 'Header 3': 'CNN'}, page_content='CNN'),\n",
       " Document(metadata={'Header 1': '人工智能概述', 'Header 2': '深度学习', 'Header 3': 'CNN'}, page_content='卷积神经网络用于图像处理。'),\n",
       " Document(metadata={'Header 1': '人工智能概述', 'Header 2': '深度学习', 'Header 3': 'RNN'}, page_content='RNN'),\n",
       " Document(metadata={'Header 1': '人工智能概述', 'Header 2': '深度学习', 'Header 3': 'RNN'}, page_content='循环神经网络处理序列数据。')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28,
   "source": [
    "\n",
    "def html_header_splitter_example():\n",
    "    \"\"\"HTML标题分割器示例\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"5. HTMLHeaderTextSplitter\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    html_text = \"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "    <title>AI技术文档</title>\n",
    "</head>\n",
    "<body>\n",
    "    <h1>人工智能概述</h1>\n",
    "    <p>人工智能是计算机科学的一个分支。</p>\n",
    "\n",
    "    <h2>机器学习</h2>\n",
    "    <p>机器学习是AI的重要组成部分。</p>\n",
    "\n",
    "    <h3>监督学习</h3>\n",
    "    <p>使用标记数据进行训练。</p>\n",
    "\n",
    "    <h3>无监督学习</h3>\n",
    "    <p>从未标记数据中发现模式。</p>\n",
    "\n",
    "    <h2>深度学习</h2>\n",
    "    <p>基于神经网络的学习方法。</p>\n",
    "\n",
    "    <h3>CNN</h3>\n",
    "    <p>卷积神经网络用于图像处理。</p>\n",
    "\n",
    "    <h3>RNN</h3>\n",
    "    <p>循环神经网络处理序列数据。</p>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "    html_splitter = HTMLHeaderTextSplitter(\n",
    "        headers_to_split_on=[\n",
    "            (\"h1\", \"Header 1\"),\n",
    "            (\"h2\", \"Header 2\"),\n",
    "            (\"h3\", \"Header 3\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    html_chunks = html_splitter.split_text(html_text)\n",
    "    print(f\"HTML分割块数: {len(html_chunks)}\")\n",
    "\n",
    "    for i, chunk in enumerate(html_chunks[:3]):\n",
    "        print(f\"\\n块 {i+1}:\")\n",
    "        print(f\"内容: {chunk.page_content[:80]}...\")\n",
    "        print(f\"元数据: {chunk.metadata}\")\n",
    "\n",
    "    return html_chunks\n",
    "html_header_splitter_example()"
   ],
   "id": "c8d069647f48b948"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 代码分割器示例",
   "id": "5d63884764c29957"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T04:40:54.517430Z",
     "start_time": "2025-07-23T04:40:54.508407Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "6. PythonCodeTextSplitter\n",
      "============================================================\n",
      "Python代码分割块数: 5\n",
      "\n",
      "代码块 1 (长度: 188):\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "from sklearn.model_selection import train_test_split\n",
      "from sklearn.linear_model import LinearRegression\n",
      "from sklearn.metrics import mean_squared_error\n",
      "\n",
      "代码块 2 (长度: 352):\n",
      "class DataProcessor:\n",
      "    \"\"\"数据处理类\"\"\"\n",
      "\n",
      "    def __init__(self, data_path):\n",
      "        self.data_path = data_path\n",
      "        self.data = None\n",
      "\n",
      "    def load_data(self):\n",
      "        \"\"\"加载数据\"\"\"\n",
      "        self.data = pd...\n",
      "\n",
      "代码块 3 (长度: 288):\n",
      "# 特征缩放\n",
      "        from sklearn.preprocessing import StandardScaler\n",
      "        scaler = StandardScaler()\n",
      "        numeric_columns = self.data.select_dtypes(include=[np.number]).columns\n",
      "        self.data[numer...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['import numpy as np\\nimport pandas as pd\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.linear_model import LinearRegression\\nfrom sklearn.metrics import mean_squared_error',\n",
       " 'class DataProcessor:\\n    \"\"\"数据处理类\"\"\"\\n\\n    def __init__(self, data_path):\\n        self.data_path = data_path\\n        self.data = None\\n\\n    def load_data(self):\\n        \"\"\"加载数据\"\"\"\\n        self.data = pd.read_csv(self.data_path)\\n        return self.data\\n\\n    def preprocess(self):\\n        \"\"\"数据预处理\"\"\"\\n        # 处理缺失值\\n        self.data = self.data.dropna()',\n",
       " '# 特征缩放\\n        from sklearn.preprocessing import StandardScaler\\n        scaler = StandardScaler()\\n        numeric_columns = self.data.select_dtypes(include=[np.number]).columns\\n        self.data[numeric_columns] = scaler.fit_transform(self.data[numeric_columns])\\n\\n        return self.data',\n",
       " 'def train_model(X, y):\\n    \"\"\"训练模型\"\"\"\\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\\n\\n    model = LinearRegression()\\n    model.fit(X_train, y_train)\\n\\n    y_pred = model.predict(X_test)\\n    mse = mean_squared_error(y_test, y_pred)\\n\\n    print(f\"Mean Squared Error: {mse}\")\\n    return model',\n",
       " 'def main():\\n    \"\"\"主函数\"\"\"\\n    processor = DataProcessor(\"data.csv\")\\n    data = processor.load_data()\\n    processed_data = processor.preprocess()\\n\\n    X = processed_data.drop(\\'target\\', axis=1)\\n    y = processed_data[\\'target\\']\\n\\n    model = train_model(X, y)\\n    print(\"模型训练完成\")\\n\\nif __name__ == \"__main__\":\\n    main()']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29,
   "source": [
    "\n",
    "def code_splitter_example():\n",
    "    \"\"\"代码分割器示例\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"6. PythonCodeTextSplitter\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    python_code = '''\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "class DataProcessor:\n",
    "    \"\"\"数据处理类\"\"\"\n",
    "\n",
    "    def __init__(self, data_path):\n",
    "        self.data_path = data_path\n",
    "        self.data = None\n",
    "\n",
    "    def load_data(self):\n",
    "        \"\"\"加载数据\"\"\"\n",
    "        self.data = pd.read_csv(self.data_path)\n",
    "        return self.data\n",
    "\n",
    "    def preprocess(self):\n",
    "        \"\"\"数据预处理\"\"\"\n",
    "        # 处理缺失值\n",
    "        self.data = self.data.dropna()\n",
    "\n",
    "        # 特征缩放\n",
    "        from sklearn.preprocessing import StandardScaler\n",
    "        scaler = StandardScaler()\n",
    "        numeric_columns = self.data.select_dtypes(include=[np.number]).columns\n",
    "        self.data[numeric_columns] = scaler.fit_transform(self.data[numeric_columns])\n",
    "\n",
    "        return self.data\n",
    "\n",
    "def train_model(X, y):\n",
    "    \"\"\"训练模型\"\"\"\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "    print(f\"Mean Squared Error: {mse}\")\n",
    "    return model\n",
    "\n",
    "def main():\n",
    "    \"\"\"主函数\"\"\"\n",
    "    processor = DataProcessor(\"data.csv\")\n",
    "    data = processor.load_data()\n",
    "    processed_data = processor.preprocess()\n",
    "\n",
    "    X = processed_data.drop('target', axis=1)\n",
    "    y = processed_data['target']\n",
    "\n",
    "    model = train_model(X, y)\n",
    "    print(\"模型训练完成\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "'''\n",
    "\n",
    "    # Python代码分割\n",
    "    python_splitter = PythonCodeTextSplitter(\n",
    "        chunk_size=500,\n",
    "        chunk_overlap=50\n",
    "    )\n",
    "\n",
    "    code_chunks = python_splitter.split_text(python_code)\n",
    "    print(f\"Python代码分割块数: {len(code_chunks)}\")\n",
    "\n",
    "    for i, chunk in enumerate(code_chunks[:3]):\n",
    "        print(f\"\\n代码块 {i+1} (长度: {len(chunk)}):\")\n",
    "        print(chunk[:200] + \"...\" if len(chunk) > 200 else chunk)\n",
    "\n",
    "    return code_chunks\n",
    "code_splitter_example()"
   ],
   "id": "c66ba3b6cb46fdde"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### LaTeX分割器示例",
   "id": "d8dbc71007f9c6b6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T04:41:10.518491Z",
     "start_time": "2025-07-23T04:41:10.512148Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "7. LatexTextSplitter\n",
      "============================================================\n",
      "LaTeX分割块数: 4\n",
      "\n",
      "LaTeX块 1:\n",
      "\\documentclass{article}\n",
      "\\usepackage{amsmath}\n",
      "\\title{机器学习数学基础}\n",
      "\\author{AI研究团队}\n",
      "\n",
      "\\begin{document}\n",
      "\\maketitle\n",
      "\n",
      "\\section{线性代数}\n",
      "线性代数是机器学习的数学基础之一。\n",
      "\n",
      "\\subsect...\n",
      "\n",
      "LaTeX块 2:\n",
      "$ 个分量。\n",
      "\n",
      "\\subsection{矩阵}\n",
      "矩阵是二维数组，用于表示线性变换。\n",
      "\n",
      "矩阵乘法定义为：\n",
      "\\begin{equation}\n",
      "(\\mathbf{AB})_{ij} = \\sum_{k=1}^{n} a_{ik}b_{kj}\n",
      "\\end{equation}\n",
      "\n",
      "\\section{概率论}\n",
      "概率...\n",
      "\n",
      "LaTeX块 3:\n",
      "= \\frac{P(B|A)P(A)}{P(B)}\n",
      "\\end{equation}\n",
      "\n",
      "\\section{优化理论}\n",
      "优化理论用于寻找模型的最优参数。\n",
      "\n",
      "\\subsection{梯度下降}\n",
      "梯度下降是最常用的优化算法：\n",
      "\\begin{equation}\n",
      "\\theta_{t+1} = \\theta_t -...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['\\\\documentclass{article}\\n\\\\usepackage{amsmath}\\n\\\\title{机器学习数学基础}\\n\\\\author{AI研究团队}\\n\\n\\\\begin{document}\\n\\\\maketitle\\n\\n\\\\section{线性代数}\\n线性代数是机器学习的数学基础之一。\\n\\n\\\\subsection{向量}\\n向量是具有大小和方向的量。在机器学习中，特征通常表示为向量。\\n\\n设向量 $\\\\mathbf{v} = [v_1, v_2, \\\\ldots, v_n]^T$，其中 $v_i$ 是第 $i',\n",
       " '$ 个分量。\\n\\n\\\\subsection{矩阵}\\n矩阵是二维数组，用于表示线性变换。\\n\\n矩阵乘法定义为：\\n\\\\begin{equation}\\n(\\\\mathbf{AB})_{ij} = \\\\sum_{k=1}^{n} a_{ik}b_{kj}\\n\\\\end{equation}\\n\\n\\\\section{概率论}\\n概率论为机器学习提供了不确定性建模的工具。\\n\\n\\\\subsection{贝叶斯定理}\\n贝叶斯定理是概率论的核心：\\n\\\\begin{equation}\\nP(A|B) =',\n",
       " '= \\\\frac{P(B|A)P(A)}{P(B)}\\n\\\\end{equation}\\n\\n\\\\section{优化理论}\\n优化理论用于寻找模型的最优参数。\\n\\n\\\\subsection{梯度下降}\\n梯度下降是最常用的优化算法：\\n\\\\begin{equation}\\n\\\\theta_{t+1} = \\\\theta_t - \\\\alpha \\\\nabla_\\\\theta J(\\\\theta)\\n\\\\end{equation}\\n\\n其中',\n",
       " '$\\\\alpha$ 是学习率，$J(\\\\theta)$ 是损失函数。\\n\\n\\\\end{document}']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30,
   "source": [
    "\n",
    "def latex_splitter_example():\n",
    "    \"\"\"LaTeX分割器示例\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"7. LatexTextSplitter\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    latex_text = r\"\"\"\n",
    "\\documentclass{article}\n",
    "\\usepackage{amsmath}\n",
    "\\title{机器学习数学基础}\n",
    "\\author{AI研究团队}\n",
    "\n",
    "\\begin{document}\n",
    "\\maketitle\n",
    "\n",
    "\\section{线性代数}\n",
    "线性代数是机器学习的数学基础之一。\n",
    "\n",
    "\\subsection{向量}\n",
    "向量是具有大小和方向的量。在机器学习中，特征通常表示为向量。\n",
    "\n",
    "设向量 $\\mathbf{v} = [v_1, v_2, \\ldots, v_n]^T$，其中 $v_i$ 是第 $i$ 个分量。\n",
    "\n",
    "\\subsection{矩阵}\n",
    "矩阵是二维数组，用于表示线性变换。\n",
    "\n",
    "矩阵乘法定义为：\n",
    "\\begin{equation}\n",
    "(\\mathbf{AB})_{ij} = \\sum_{k=1}^{n} a_{ik}b_{kj}\n",
    "\\end{equation}\n",
    "\n",
    "\\section{概率论}\n",
    "概率论为机器学习提供了不确定性建模的工具。\n",
    "\n",
    "\\subsection{贝叶斯定理}\n",
    "贝叶斯定理是概率论的核心：\n",
    "\\begin{equation}\n",
    "P(A|B) = \\frac{P(B|A)P(A)}{P(B)}\n",
    "\\end{equation}\n",
    "\n",
    "\\section{优化理论}\n",
    "优化理论用于寻找模型的最优参数。\n",
    "\n",
    "\\subsection{梯度下降}\n",
    "梯度下降是最常用的优化算法：\n",
    "\\begin{equation}\n",
    "\\theta_{t+1} = \\theta_t - \\alpha \\nabla_\\theta J(\\theta)\n",
    "\\end{equation}\n",
    "\n",
    "其中 $\\alpha$ 是学习率，$J(\\theta)$ 是损失函数。\n",
    "\n",
    "\\end{document}\n",
    "\"\"\"\n",
    "\n",
    "    latex_splitter = LatexTextSplitter(\n",
    "        chunk_size=300,\n",
    "        chunk_overlap=50\n",
    "    )\n",
    "\n",
    "    latex_chunks = latex_splitter.split_text(latex_text)\n",
    "    print(f\"LaTeX分割块数: {len(latex_chunks)}\")\n",
    "\n",
    "    for i, chunk in enumerate(latex_chunks[:3]):\n",
    "        print(f\"\\nLaTeX块 {i+1}:\")\n",
    "        print(chunk[:150] + \"...\" if len(chunk) > 150 else chunk)\n",
    "\n",
    "    return latex_chunks\n",
    "latex_splitter_example()"
   ],
   "id": "46f6514d3f553929"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 高级分割技术",
   "id": "219917954ee85ad7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T04:41:51.146275Z",
     "start_time": "2025-07-23T04:41:51.136142Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "8. 高级分割技术\n",
      "============================================================\n",
      "\n",
      "8.1 动态块大小调整\n",
      "自适应分割块数: 4\n",
      "\n",
      "8.2 语义感知分割\n",
      "语义分割块数: 4\n",
      "\n",
      "8.3 智能重叠策略\n",
      "智能重叠分割块数: 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'ai_history'}, page_content='人工智能的发展历程可以追溯到20世纪50年代。当时，计算机科学家开始探索让机器模拟人类智能的可能性。\\n\\n在1956年的达特茅斯会议上，人工智能这个术语首次被正式提出。这标志着AI作为一个独立学科的诞生。\\n\\n随后的几十年里，AI经历了多次起伏。60-70年代是第一个AI春天，专家系统得到了广泛应用。'),\n",
       " Document(metadata={'source': 'ai_history'}, page_content='随后的几十年里，AI经历了多次起伏。60-70年代是第一个AI春天，专家系统得到了广泛应用。\\n\\n80年代末到90年代初，由于技术限制和过高期望，AI进入了所谓的\"AI冬天\"。\\n\\n21世纪以来，随着大数据、云计算和深度学习的发展，AI迎来了新的春天。'),\n",
       " Document(metadata={'source': 'ai_history'}, page_content='21世纪以来，随着大数据、云计算和深度学习的发展，AI迎来了新的春天。\\n\\n今天，AI已经在图像识别、自然语言处理、推荐系统等领域取得了突破性进展。\\n\\n机器学习作为AI的核心技术，包括监督学习、无监督学习和强化学习三大类。深度学习则是机器学习的一个重要分支。'),\n",
       " Document(metadata={'source': 'ai_history'}, page_content='自然语言处理（NLP）让计算机能够理解和生成人类语言。计算机视觉让机器能够\"看见\"和理解图像。\\n\\n未来，AI将在更多领域发挥重要作用，包括医疗、教育、交通、金融等。同时，AI的伦理和安全问题也需要得到重视。')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 31,
   "source": [
    "\n",
    "def advanced_splitting_techniques():\n",
    "    \"\"\"高级分割技术\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"8. 高级分割技术\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    doc = create_sample_documents()\n",
    "\n",
    "    # 8.1 动态块大小\n",
    "    print(\"\\n8.1 动态块大小调整\")\n",
    "\n",
    "    def adaptive_chunk_size(text: str) -> int:\n",
    "        \"\"\"根据文本复杂度动态调整块大小\"\"\"\n",
    "        sentences = text.split('。')\n",
    "        avg_sentence_length = sum(len(s) for s in sentences) / len(sentences) if sentences else 100\n",
    "\n",
    "        if avg_sentence_length > 50:\n",
    "            return 300  # 长句子用大块\n",
    "        elif avg_sentence_length > 30:\n",
    "            return 200  # 中等句子用中块\n",
    "        else:\n",
    "            return 150  # 短句子用小块\n",
    "\n",
    "    adaptive_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=adaptive_chunk_size(doc.page_content),\n",
    "        chunk_overlap=50\n",
    "    )\n",
    "\n",
    "    adaptive_chunks = adaptive_splitter.split_documents([doc])\n",
    "    print(f\"自适应分割块数: {len(adaptive_chunks)}\")\n",
    "\n",
    "    # 8.2 语义感知分割\n",
    "    print(\"\\n8.2 语义感知分割\")\n",
    "\n",
    "    def semantic_splitter(text: str, max_chunk_size: int = 200) -> List[str]:\n",
    "        \"\"\"基于语义的分割（简化版）\"\"\"\n",
    "        sentences = text.split('。')\n",
    "        chunks = []\n",
    "        current_chunk = \"\"\n",
    "\n",
    "        for sentence in sentences:\n",
    "            sentence = sentence.strip()\n",
    "            if not sentence:\n",
    "                continue\n",
    "\n",
    "            # 检查是否包含关键词（新主题开始）\n",
    "            topic_keywords = ['然而', '另外', '此外', '同时', '因此', '总之']\n",
    "            is_new_topic = any(keyword in sentence for keyword in topic_keywords)\n",
    "\n",
    "            if (len(current_chunk) + len(sentence) > max_chunk_size) or is_new_topic:\n",
    "                if current_chunk:\n",
    "                    chunks.append(current_chunk.strip())\n",
    "                current_chunk = sentence + '。'\n",
    "            else:\n",
    "                current_chunk += sentence + '。'\n",
    "\n",
    "        if current_chunk:\n",
    "            chunks.append(current_chunk.strip())\n",
    "\n",
    "        return chunks\n",
    "\n",
    "    semantic_chunks = semantic_splitter(doc.page_content)\n",
    "    print(f\"语义分割块数: {len(semantic_chunks)}\")\n",
    "\n",
    "    # 8.3 重叠策略优化\n",
    "    print(\"\\n8.3 智能重叠策略\")\n",
    "\n",
    "    def smart_overlap_splitter(text: str, chunk_size: int = 200) -> List[Document]:\n",
    "        \"\"\"智能重叠分割\"\"\"\n",
    "        sentences = text.split('。')\n",
    "        chunks = []\n",
    "\n",
    "        for i in range(0, len(sentences), 3):  # 每3句为一块\n",
    "            chunk_sentences = sentences[i:i+4]  # 取4句（包含1句重叠）\n",
    "            chunk_text = '。'.join(chunk_sentences).strip()\n",
    "\n",
    "            if chunk_text:\n",
    "                chunks.append(Document(\n",
    "                    page_content=chunk_text,\n",
    "                    metadata={\"chunk_id\": len(chunks), \"overlap_strategy\": \"sentence_based\"}\n",
    "                ))\n",
    "\n",
    "        return chunks\n",
    "\n",
    "    smart_chunks = smart_overlap_splitter(doc.page_content)\n",
    "    print(f\"智能重叠分割块数: {len(smart_chunks)}\")\n",
    "\n",
    "    return adaptive_chunks\n",
    "advanced_splitting_techniques()"
   ],
   "id": "5ce610a9fc2f1ddd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 分割器性能对比",
   "id": "92fe1c7d076314da"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T04:42:17.512714Z",
     "start_time": "2025-07-23T04:42:17.504253Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "9. 分割器性能对比\n",
      "============================================================\n",
      "\n",
      "性能对比结果:\n",
      "分割器                  块数       时间(s)      平均长度       最小长度       最大长度      \n",
      "--------------------------------------------------------------------------------\n",
      "RecursiveCharacter   3        0.0000     154.0      103        190       \n",
      "Character            3        0.0000     154.0      103        190       \n",
      "Token                21       0.0010     25.9       10         32        \n"
     ]
    }
   ],
   "execution_count": 32,
   "source": [
    "\n",
    "def splitting_performance_comparison():\n",
    "    \"\"\"分割器性能对比\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"9. 分割器性能对比\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    doc = create_sample_documents()\n",
    "\n",
    "    splitters = {\n",
    "        \"RecursiveCharacter\": RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=50),\n",
    "        \"Character\": CharacterTextSplitter(chunk_size=200, chunk_overlap=50, separator=\"\\n\\n\"),\n",
    "        \"Token\": TokenTextSplitter(chunk_size=50, chunk_overlap=10)\n",
    "    }\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    for name, splitter in splitters.items():\n",
    "        try:\n",
    "            import time\n",
    "            start_time = time.time()\n",
    "            chunks = splitter.split_documents([doc])\n",
    "            end_time = time.time()\n",
    "\n",
    "            results[name] = {\n",
    "                \"chunks\": len(chunks),\n",
    "                \"time\": end_time - start_time,\n",
    "                \"avg_length\": sum(len(c.page_content) for c in chunks) / len(chunks),\n",
    "                \"min_length\": min(len(c.page_content) for c in chunks),\n",
    "                \"max_length\": max(len(c.page_content) for c in chunks)\n",
    "            }\n",
    "        except Exception as e:\n",
    "            results[name] = {\"error\": str(e)}\n",
    "\n",
    "    print(\"\\n性能对比结果:\")\n",
    "    print(f\"{'分割器':<20} {'块数':<8} {'时间(s)':<10} {'平均长度':<10} {'最小长度':<10} {'最大长度':<10}\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    for name, result in results.items():\n",
    "        if \"error\" not in result:\n",
    "            print(f\"{name:<20} {result['chunks']:<8} {result['time']:<10.4f} \"\n",
    "                  f\"{result['avg_length']:<10.1f} {result['min_length']:<10} {result['max_length']:<10}\")\n",
    "        else:\n",
    "            print(f\"{name:<20} 错误: {result['error']}\")\n",
    "splitting_performance_comparison()"
   ],
   "id": "c9733276c057cbaf"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 运行所有文本分割器示例",
   "id": "7d906c8f2615c655"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T04:42:52.546641Z",
     "start_time": "2025-07-23T04:42:52.537224Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 LangChain 0.3 Text Splitters 完整示例\n",
      "================================================================================\n",
      "============================================================\n",
      "1. RecursiveCharacterTextSplitter（推荐）\n",
      "============================================================\n",
      "\n",
      "1.1 基础递归分割\n",
      "基础分割块数: 3\n",
      "块 1 (长度: 190): 人工智能的发展历程可以追溯到20世纪50年代。当时，计算机科学家开始探索让机器模拟人类智能的可能性。\n",
      "\n",
      "在1956年的达特茅斯会议上，人工智能这个术语首次被正式...\n",
      "块 2 (长度: 169): 80年代末到90年代初，由于技术限制和过高期望，AI进入了所谓的\"AI冬天\"。\n",
      "\n",
      "21世纪以来，随着大数据、云计算和深度学习的发展，AI迎来了新的春天。\n",
      "\n",
      "今天...\n",
      "块 3 (长度: 103): 自然语言处理（NLP）让计算机能够理解和生成人类语言。计算机视觉让机器能够\"看见\"和理解图像。\n",
      "\n",
      "未来，AI将在更多领域发挥重要作用，包括医疗、教育、交通、金融...\n",
      "\n",
      "1.2 自定义分隔符优先级\n",
      "自定义分割块数: 4\n",
      "\n",
      "1.3 段落优先分割\n",
      "段落分割块数: 2\n",
      "\n",
      "============================================================\n",
      "2. CharacterTextSplitter\n",
      "============================================================\n",
      "\n",
      "2.1 按段落分割\n",
      "段落分割块数: 2\n",
      "\n",
      "2.2 按句子分割\n",
      "句子分割块数: 6\n",
      "\n",
      "2.3 自定义分隔符\n",
      "自定义分割块数: 2\n",
      "  - 项目A|项目B|项目C|项目D\n",
      "  - 项目E的详细描述和分析报告\n",
      "\n",
      "============================================================\n",
      "3. TokenTextSplitter\n",
      "============================================================\n",
      "\n",
      "3.1 基础Token分割\n",
      "Token分割块数: 6\n",
      "块 1 Token数: 100, 内容: 人工智能的发展历程可以追溯到20世纪50年代。当时，计算机科学家开始探索让机器模拟人类智能的可能性。\n",
      "\n",
      "在1956年的达...\n",
      "块 2 Token数: 100, 内容: 次被正式提出。这标志着AI作为一个独立学科的诞生。\n",
      "\n",
      "随后的几十年里，AI经历了多次起伏。60-70年代是第一个AI春天...\n",
      "块 3 Token数: 100, 内容: 年代初，由于技术限制和过高期望，AI进入了所谓的\"AI冬天\"。\n",
      "\n",
      "21世纪以来，随着大数据、云计算和深度学习的发展，AI...\n",
      "\n",
      "3.2 不同模型Token分割对比\n",
      "gpt-3.5-turbo: 11 块\n",
      "text-davinci-003: 21 块\n",
      "gpt-4: 11 块\n",
      "\n",
      "============================================================\n",
      "4. MarkdownHeaderTextSplitter\n",
      "============================================================\n",
      "\n",
      "4.1 基础标题分割\n",
      "Markdown分割块数: 8\n",
      "\n",
      "块 1:\n",
      "内容: 监督学习是机器学习的一个重要分支，使用标记的训练数据来学习输入到输出的映射。  \n",
      "常见算法包括：\n",
      "- 线性回归\n",
      "- 逻辑回归\n",
      "- 决策树\n",
      "- 随机森林...\n",
      "元数据: {'Header 1': '人工智能技术指南', 'Header 2': '1. 机器学习基础', 'Header 3': '1.1 监督学习'}\n",
      "\n",
      "块 2:\n",
      "内容: 无监督学习从未标记的数据中发现隐藏的模式。  \n",
      "主要方法：\n",
      "- 聚类分析\n",
      "- 降维技术\n",
      "- 关联规则挖掘...\n",
      "元数据: {'Header 1': '人工智能技术指南', 'Header 2': '1. 机器学习基础', 'Header 3': '1.2 无监督学习'}\n",
      "\n",
      "块 3:\n",
      "内容: 神经网络是深度学习的基础，模拟人脑神经元的工作方式。...\n",
      "元数据: {'Header 1': '人工智能技术指南', 'Header 2': '2. 深度学习', 'Header 3': '2.1 神经网络基础'}\n",
      "\n",
      "块 4:\n",
      "内容: CNN主要用于图像处理和计算机视觉任务。...\n",
      "元数据: {'Header 1': '人工智能技术指南', 'Header 2': '2. 深度学习', 'Header 3': '2.2 卷积神经网络'}\n",
      "\n",
      "块 5:\n",
      "内容: RNN适合处理序列数据，如文本和时间序列。...\n",
      "元数据: {'Header 1': '人工智能技术指南', 'Header 2': '2. 深度学习', 'Header 3': '2.3 循环神经网络'}\n",
      "\n",
      "4.2 结合递归分割器进行二次分割\n",
      "二次分割后块数: 8\n",
      "\n",
      "============================================================\n",
      "5. HTMLHeaderTextSplitter\n",
      "============================================================\n",
      "HTML分割块数: 14\n",
      "\n",
      "块 1:\n",
      "内容: 人工智能概述...\n",
      "元数据: {'Header 1': '人工智能概述'}\n",
      "\n",
      "块 2:\n",
      "内容: 人工智能是计算机科学的一个分支。...\n",
      "元数据: {'Header 1': '人工智能概述'}\n",
      "\n",
      "块 3:\n",
      "内容: 机器学习...\n",
      "元数据: {'Header 1': '人工智能概述', 'Header 2': '机器学习'}\n",
      "\n",
      "============================================================\n",
      "6. PythonCodeTextSplitter\n",
      "============================================================\n",
      "Python代码分割块数: 5\n",
      "\n",
      "代码块 1 (长度: 188):\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "from sklearn.model_selection import train_test_split\n",
      "from sklearn.linear_model import LinearRegression\n",
      "from sklearn.metrics import mean_squared_error\n",
      "\n",
      "代码块 2 (长度: 352):\n",
      "class DataProcessor:\n",
      "    \"\"\"数据处理类\"\"\"\n",
      "\n",
      "    def __init__(self, data_path):\n",
      "        self.data_path = data_path\n",
      "        self.data = None\n",
      "\n",
      "    def load_data(self):\n",
      "        \"\"\"加载数据\"\"\"\n",
      "        self.data = pd...\n",
      "\n",
      "代码块 3 (长度: 288):\n",
      "# 特征缩放\n",
      "        from sklearn.preprocessing import StandardScaler\n",
      "        scaler = StandardScaler()\n",
      "        numeric_columns = self.data.select_dtypes(include=[np.number]).columns\n",
      "        self.data[numer...\n",
      "\n",
      "============================================================\n",
      "7. LatexTextSplitter\n",
      "============================================================\n",
      "LaTeX分割块数: 4\n",
      "\n",
      "LaTeX块 1:\n",
      "\\documentclass{article}\n",
      "\\usepackage{amsmath}\n",
      "\\title{机器学习数学基础}\n",
      "\\author{AI研究团队}\n",
      "\n",
      "\\begin{document}\n",
      "\\maketitle\n",
      "\n",
      "\\section{线性代数}\n",
      "线性代数是机器学习的数学基础之一。\n",
      "\n",
      "\\subsect...\n",
      "\n",
      "LaTeX块 2:\n",
      "$ 个分量。\n",
      "\n",
      "\\subsection{矩阵}\n",
      "矩阵是二维数组，用于表示线性变换。\n",
      "\n",
      "矩阵乘法定义为：\n",
      "\\begin{equation}\n",
      "(\\mathbf{AB})_{ij} = \\sum_{k=1}^{n} a_{ik}b_{kj}\n",
      "\\end{equation}\n",
      "\n",
      "\\section{概率论}\n",
      "概率...\n",
      "\n",
      "LaTeX块 3:\n",
      "= \\frac{P(B|A)P(A)}{P(B)}\n",
      "\\end{equation}\n",
      "\n",
      "\\section{优化理论}\n",
      "优化理论用于寻找模型的最优参数。\n",
      "\n",
      "\\subsection{梯度下降}\n",
      "梯度下降是最常用的优化算法：\n",
      "\\begin{equation}\n",
      "\\theta_{t+1} = \\theta_t -...\n",
      "\n",
      "============================================================\n",
      "8. 高级分割技术\n",
      "============================================================\n",
      "\n",
      "8.1 动态块大小调整\n",
      "自适应分割块数: 4\n",
      "\n",
      "8.2 语义感知分割\n",
      "语义分割块数: 4\n",
      "\n",
      "8.3 智能重叠策略\n",
      "智能重叠分割块数: 5\n",
      "\n",
      "============================================================\n",
      "9. 分割器性能对比\n",
      "============================================================\n",
      "\n",
      "性能对比结果:\n",
      "分割器                  块数       时间(s)      平均长度       最小长度       最大长度      \n",
      "--------------------------------------------------------------------------------\n",
      "RecursiveCharacter   3        0.0000     154.0      103        190       \n",
      "Character            3        0.0000     154.0      103        190       \n",
      "Token                21       0.0000     25.9       10         32        \n",
      "\n",
      "🎉 所有文本分割器示例运行完成！\n",
      "\n",
      "📋 最佳实践建议:\n",
      "1. 通用文本：使用 RecursiveCharacterTextSplitter\n",
      "2. 结构化文档：使用对应的Header分割器\n",
      "3. 代码文档：使用 PythonCodeTextSplitter\n",
      "4. Token限制：使用 TokenTextSplitter\n",
      "5. 简单需求：使用 CharacterTextSplitter\n"
     ]
    }
   ],
   "execution_count": 33,
   "source": [
    "\n",
    "def main():\n",
    "    \"\"\"运行所有文本分割器示例\"\"\"\n",
    "    print(\"🚀 LangChain 0.3 Text Splitters 完整示例\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # 运行所有示例\n",
    "    recursive_character_splitter_example()\n",
    "    character_text_splitter_example()\n",
    "    token_text_splitter_example()\n",
    "    markdown_header_splitter_example()\n",
    "    html_header_splitter_example()\n",
    "    code_splitter_example()\n",
    "    latex_splitter_example()\n",
    "    advanced_splitting_techniques()\n",
    "    splitting_performance_comparison()\n",
    "\n",
    "    print(\"\\n🎉 所有文本分割器示例运行完成！\")\n",
    "\n",
    "    # 最佳实践建议\n",
    "    print(\"\\n📋 最佳实践建议:\")\n",
    "    print(\"1. 通用文本：使用 RecursiveCharacterTextSplitter\")\n",
    "    print(\"2. 结构化文档：使用对应的Header分割器\")\n",
    "    print(\"3. 代码文档：使用 PythonCodeTextSplitter\")\n",
    "    print(\"4. Token限制：使用 TokenTextSplitter\")\n",
    "    print(\"5. 简单需求：使用 CharacterTextSplitter\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "id": "e53138b9e4d80c03"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T03:08:17.593085Z",
     "start_time": "2025-07-23T03:08:17.414855Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "2. Text Splitters 文本分割器示例\n",
      "============================================================\n",
      "\n",
      "2.1 RecursiveCharacterTextSplitter\n",
      "递归分割块数: 2\n",
      "块 1: 人工智能的发展历程可以追溯到20世纪50年代。当时，计算机科学家开始探索让机器模拟人类智能的可能性。\n",
      "\n",
      "    在1956年的达特茅斯会议上，人工智能这个术语首次被正式提出。这标志着AI作为一个独立学...\n",
      "块 2: 80年代末到90年代初，由于技术限制和过高期望，AI进入了所谓的\"AI冬天\"。\n",
      "\n",
      "    21世纪以来，随着大数据、云计算和深度学习的发展，AI迎来了新的春天。\n",
      "\n",
      "    今天，AI已经在图像识别、自...\n",
      "\n",
      "2.2 CharacterTextSplitter\n",
      "字符分割块数: 1\n",
      "\n",
      "2.3 TokenTextSplitter\n",
      "Token分割块数: 7\n",
      "\n",
      "2.4 MarkdownHeaderTextSplitter\n",
      "Markdown分割块数: 4\n"
     ]
    }
   ],
   "execution_count": 3,
   "source": [
    "# 2. Text Splitters 示例\n",
    "def text_splitters_example(documents: List[Document]):\n",
    "    \"\"\"文本分割器示例\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"2. Text Splitters 文本分割器示例\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # 创建长文本用于分割\n",
    "    long_text = \"\"\"\n",
    "    人工智能的发展历程可以追溯到20世纪50年代。当时，计算机科学家开始探索让机器模拟人类智能的可能性。\n",
    "\n",
    "    在1956年的达特茅斯会议上，人工智能这个术语首次被正式提出。这标志着AI作为一个独立学科的诞生。\n",
    "\n",
    "    随后的几十年里，AI经历了多次起伏。60-70年代是第一个AI春天，专家系统得到了广泛应用。\n",
    "\n",
    "    80年代末到90年代初，由于技术限制和过高期望，AI进入了所谓的\"AI冬天\"。\n",
    "\n",
    "    21世纪以来，随着大数据、云计算和深度学习的发展，AI迎来了新的春天。\n",
    "\n",
    "    今天，AI已经在图像识别、自然语言处理、推荐系统等领域取得了突破性进展。\n",
    "    \"\"\"\n",
    "\n",
    "    long_doc = Document(page_content=long_text, metadata={\"source\": \"ai_history\"})\n",
    "\n",
    "    # 2.1 递归字符分割器（推荐）\n",
    "    print(\"\\n2.1 RecursiveCharacterTextSplitter\")\n",
    "    recursive_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=200,\n",
    "        chunk_overlap=50,\n",
    "        length_function=len,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \"。\", \"，\", \" \", \"\"]\n",
    "    )\n",
    "\n",
    "    recursive_chunks = recursive_splitter.split_documents([long_doc])\n",
    "    print(f\"递归分割块数: {len(recursive_chunks)}\")\n",
    "    for i, chunk in enumerate(recursive_chunks[:2]):\n",
    "        print(f\"块 {i + 1}: {chunk.page_content[:100]}...\")\n",
    "\n",
    "    # 2.2 字符分割器\n",
    "    print(\"\\n2.2 CharacterTextSplitter\")\n",
    "    char_splitter = CharacterTextSplitter(\n",
    "        chunk_size=300,\n",
    "        chunk_overlap=50,\n",
    "        separator=\"\\n\\n\"\n",
    "    )\n",
    "\n",
    "    char_chunks = char_splitter.split_documents([long_doc])\n",
    "    print(f\"字符分割块数: {len(char_chunks)}\")\n",
    "\n",
    "    # 2.3 Token分割器\n",
    "    print(\"\\n2.3 TokenTextSplitter\")\n",
    "    token_splitter = TokenTextSplitter(\n",
    "        chunk_size=100,\n",
    "        chunk_overlap=20\n",
    "    )\n",
    "\n",
    "    token_chunks = token_splitter.split_documents([long_doc])\n",
    "    print(f\"Token分割块数: {len(token_chunks)}\")\n",
    "\n",
    "    # 2.4 Markdown分割器\n",
    "    print(\"\\n2.4 MarkdownHeaderTextSplitter\")\n",
    "    markdown_text = \"\"\"\n",
    "# 人工智能概述\n",
    "\n",
    "## 什么是人工智能\n",
    "人工智能是计算机科学的一个分支。\n",
    "\n",
    "## AI的应用领域\n",
    "\n",
    "### 自然语言处理\n",
    "NLP是AI的重要分支。\n",
    "\n",
    "### 计算机视觉\n",
    "计算机视觉让机器能够\"看见\"。\n",
    "\n",
    "## 未来发展\n",
    "AI将继续快速发展。\n",
    "\"\"\"\n",
    "\n",
    "    markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "        headers_to_split_on=[\n",
    "            (\"#\", \"Header 1\"),\n",
    "            (\"##\", \"Header 2\"),\n",
    "            (\"###\", \"Header 3\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    md_doc = Document(page_content=markdown_text)\n",
    "    md_chunks = markdown_splitter.split_text(markdown_text)\n",
    "    print(f\"Markdown分割块数: {len(md_chunks)}\")\n",
    "\n",
    "    return recursive_chunks\n",
    "# 2. 文本分割\n",
    "chunks = text_splitters_example(documents)"
   ],
   "id": "9970222bdee367c6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
