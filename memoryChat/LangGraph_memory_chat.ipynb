{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# ä½¿ç”¨ LangGraph å®ç°å¯¹è¯è®°å¿†",
   "id": "7bd573aa446cccd1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# å®‰è£…ä¾èµ–\n",
    "# !pip install langgraph langchain-ollama langchain-core"
   ],
   "id": "170a2b130a89ff45"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T03:50:29.999035Z",
     "start_time": "2025-07-22T03:50:29.985511Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# å¯¼å…¥å¿…è¦çš„åº“\n",
    "from typing import Annotated, Dict, List, Any\n",
    "from typing_extensions import TypedDict\n",
    "import uuid\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.messages import HumanMessage, AIMessage, BaseMessage, SystemMessage\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langgraph.graph import StateGraph, MessagesState, START, END\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "\n",
    "print(\"âœ… åº“å¯¼å…¥å®Œæˆ\")"
   ],
   "id": "69ce93fb80825edd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… åº“å¯¼å…¥å®Œæˆ\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T03:44:49.919977Z",
     "start_time": "2025-07-22T03:44:49.847932Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# åˆå§‹åŒ– Ollama æ¨¡å‹\n",
    "model = ChatOllama(\n",
    "    base_url=\"http://localhost:11434\",\n",
    "    model=\"qwen2.5:3b\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "print(\"âœ… æ¨¡å‹åˆå§‹åŒ–å®Œæˆ\")"
   ],
   "id": "f8f02c51e162cab8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… æ¨¡å‹åˆå§‹åŒ–å®Œæˆ\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## æ–¹å¼1: åŸºç¡€å¯¹è¯è®°å¿† - ä½¿ç”¨ MessagesState",
   "id": "61aa49746945c373"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T03:53:16.141784Z",
     "start_time": "2025-07-22T03:53:16.134707Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## æ–¹å¼1: åŸºç¡€å¯¹è¯è®°å¿† - ä½¿ç”¨ MessagesState\n",
    "def call_model_basic(state: MessagesState) -> dict:\n",
    "    \"\"\"åŸºç¡€æ¨¡å‹è°ƒç”¨\"\"\"\n",
    "    system_msg = SystemMessage(content=\"ä½ æ˜¯ä¸€ä¸ªå‹å¥½çš„AIåŠ©æ‰‹ï¼Œèƒ½å¤Ÿè®°ä½å¯¹è¯å†å²ã€‚\")\n",
    "    messages = [system_msg] + state[\"messages\"]\n",
    "    response = model.invoke(messages)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "# åˆ›å»ºåŸºç¡€å›¾\n",
    "builder_basic = StateGraph(MessagesState)\n",
    "builder_basic.add_node(\"call_model\", call_model_basic)\n",
    "builder_basic.add_edge(START, \"call_model\")\n",
    "builder_basic.add_edge(\"call_model\", END)\n",
    "\n",
    "graph_basic = builder_basic.compile(checkpointer=MemorySaver())\n",
    "print(\"âœ… æ–¹å¼1: åŸºç¡€å¯¹è¯å›¾åˆ›å»ºå®Œæˆ\")"
   ],
   "id": "2d9e3643d8b55366",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… æ–¹å¼1: åŸºç¡€å¯¹è¯å›¾åˆ›å»ºå®Œæˆ\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T04:01:13.307232Z",
     "start_time": "2025-07-22T04:00:36.019445Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# æ–¹å¼1æµ‹è¯•ï¼šåŸºç¡€å¯¹è¯è®°å¿†\n",
    "print(\"ğŸ§ª å¼€å§‹æµ‹è¯•æ–¹å¼1ï¼šåŸºç¡€å¯¹è¯è®°å¿†\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "config1 = {\"configurable\": {\"thread_id\": str(uuid.uuid4())}}\n",
    "\n",
    "print(\"\\nç¬¬1è½®å¯¹è¯:\")\n",
    "user_input1 = \"ä½ å¥½ï¼Œæˆ‘å«å¼ ä¸‰ï¼Œæ˜¯ä¸€åç¨‹åºå‘˜\"\n",
    "print(f\"ç”¨æˆ·: {user_input1}\")\n",
    "result1 = graph_basic.invoke({\"messages\": [HumanMessage(content=user_input1)]}, config1)\n",
    "print(f\"AI: {result1['messages'][-1].content}\")\n",
    "\n",
    "print(\"\\nç¬¬2è½®å¯¹è¯:\")\n",
    "user_input2 = \"ä½ è¿˜è®°å¾—æˆ‘çš„åå­—å’ŒèŒä¸šå—ï¼Ÿ\"\n",
    "print(f\"ç”¨æˆ·: {user_input2}\")\n",
    "result2 = graph_basic.invoke({\"messages\": [HumanMessage(content=user_input2)]}, config1)\n",
    "print(f\"AI: {result2['messages'][-1].content}\")\n",
    "\n",
    "print(\"\\nç¬¬3è½®å¯¹è¯:\")\n",
    "user_input3 = \"æˆ‘ä»Šå¹´30å²ï¼Œä½åœ¨åŒ—äº¬\"\n",
    "print(f\"ç”¨æˆ·: {user_input3}\")\n",
    "result3 = graph_basic.invoke({\"messages\": [HumanMessage(content=user_input3)]}, config1)\n",
    "print(f\"AI: {result3['messages'][-1].content}\")\n",
    "\n",
    "print(\"\\nç¬¬4è½®å¯¹è¯:\")\n",
    "user_input4 = \"è¯·æ€»ç»“ä¸€ä¸‹æˆ‘çš„ä¸ªäººä¿¡æ¯\"\n",
    "print(f\"ç”¨æˆ·: {user_input4}\")\n",
    "result4 = graph_basic.invoke({\"messages\": [HumanMessage(content=user_input4)]}, config1)\n",
    "print(f\"AI: {result4['messages'][-1].content}\")\n",
    "\n",
    "print(\"\\nâœ… æ–¹å¼1æµ‹è¯•å®Œæˆ\")"
   ],
   "id": "130d1292a6f02fb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§ª å¼€å§‹æµ‹è¯•æ–¹å¼1ï¼šåŸºç¡€å¯¹è¯è®°å¿†\n",
      "============================================================\n",
      "\n",
      "ç¬¬1è½®å¯¹è¯:\n",
      "ç”¨æˆ·: ä½ å¥½ï¼Œæˆ‘å«å¼ ä¸‰ï¼Œæ˜¯ä¸€åç¨‹åºå‘˜\n",
      "AI: ä½ å¥½ï¼Œå¼ ä¸‰ï¼å¾ˆé«˜å…´è®¤è¯†ä½ ã€‚ä½œä¸ºç¨‹åºå‘˜å¬èµ·æ¥å¾ˆæœ‰è¶£ä¹Ÿå¾ˆæœ‰æŒ‘æˆ˜æ€§ã€‚ä½ åœ¨ç¼–ç¨‹æ–¹é¢æœ‰ä»€ä¹ˆå…·ä½“çš„é¡¹ç›®æˆ–è€…é—®é¢˜éœ€è¦å¸®åŠ©å—ï¼Ÿæˆ–è€…ä½ æƒ³äº†è§£ä¸€äº›å…³äºç¼–ç¨‹çš„çŸ¥è¯†å’ŒæŠ€å·§ï¼Ÿ\n",
      "\n",
      "ç¬¬2è½®å¯¹è¯:\n",
      "ç”¨æˆ·: ä½ è¿˜è®°å¾—æˆ‘çš„åå­—å’ŒèŒä¸šå—ï¼Ÿ\n",
      "AI: å½“ç„¶è®°å¾—ã€‚ä½ å«å¼ ä¸‰ï¼Œæ˜¯ä¸€åç¨‹åºå‘˜ã€‚å¦‚æœä½ ç°åœ¨æœ‰ä»»ä½•é—®é¢˜æˆ–æƒ³èŠèŠç¼–ç¨‹ç›¸å…³çš„è¯é¢˜ï¼Œæˆ‘éƒ½åœ¨è¿™é‡Œå¸®åŠ©ä½ ã€‚\n",
      "\n",
      "ç¬¬3è½®å¯¹è¯:\n",
      "ç”¨æˆ·: æˆ‘ä»Šå¹´30å²ï¼Œä½åœ¨åŒ—äº¬\n",
      "AI: ä½ å¥½ï¼Œå¼ ä¸‰ï¼å¾ˆé«˜å…´è®¤è¯†ä½ ã€‚ä½ ç°åœ¨30å²ï¼Œå¹¶ä¸”ä½åœ¨åŒ—äº¬ã€‚æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®ä½ äº†è§£æˆ–è€…è§£ç­”çš„é—®é¢˜å—ï¼Ÿæˆ–è€…æ˜¯ä½ æƒ³è®¨è®ºæŸä¸ªç‰¹å®šçš„ç¼–ç¨‹è¯é¢˜æˆ–æŠ€æœ¯é—®é¢˜ï¼Ÿå¦‚æœä½ æœ‰ä»»ä½•ç–‘é—®æˆ–éœ€è¦å»ºè®®ï¼Œéšæ—¶å‘Šè¯‰æˆ‘ï¼\n",
      "\n",
      "ç¬¬4è½®å¯¹è¯:\n",
      "ç”¨æˆ·: è¯·æ€»ç»“ä¸€ä¸‹æˆ‘çš„ä¸ªäººä¿¡æ¯\n",
      "AI: å½“ç„¶å¯ä»¥ï¼Œå¼ ä¸‰ã€‚æ ¹æ®ä½ çš„ä¿¡æ¯ï¼š\n",
      "\n",
      "- å¹´é¾„ï¼š30å²\n",
      "- èŒä¸šï¼šç¨‹åºå‘˜\n",
      "- å±…ä½åœ°ï¼šåŒ—äº¬\n",
      "\n",
      "å¦‚æœæœ‰å…¶ä»–éœ€è¦è¡¥å……çš„ä¿¡æ¯æˆ–è€…æƒ³è®¨è®ºçš„è¯é¢˜ï¼Œè¯·éšæ—¶å‘ŠçŸ¥ã€‚æˆ‘å¾ˆä¹æ„å¸®åŠ©ä½ ï¼\n",
      "\n",
      "âœ… æ–¹å¼1æµ‹è¯•å®Œæˆ\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## æ–¹å¼2: å¸¦æ‘˜è¦çš„å¯¹è¯è®°å¿†",
   "id": "8aeca8a690d4a27d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T04:03:33.517413Z",
     "start_time": "2025-07-22T04:03:33.502466Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SummaryState(TypedDict):\n",
    "    messages: Annotated[List[BaseMessage], \"å¯¹è¯æ¶ˆæ¯\"]\n",
    "    summary: Annotated[str, \"å¯¹è¯æ‘˜è¦\"]\n",
    "\n",
    "\n",
    "def summarize_conversation(state: SummaryState) -> dict:\n",
    "    \"\"\"æ‘˜è¦å¯¹è¯å†å²\"\"\"\n",
    "    if len(state[\"messages\"]) > 2:  # è¶…è¿‡10æ¡æ¶ˆæ¯æ—¶æ‘˜è¦\n",
    "        messages_text = \"\\n\".join([f\"{msg.type}: {msg.content}\" for msg in state[\"messages\"][:-4]])\n",
    "        summary_prompt = f\"è¯·ç®€æ´æ‘˜è¦ä»¥ä¸‹å¯¹è¯å†…å®¹ï¼š\\n{messages_text}\"\n",
    "        summary_response = model.invoke([HumanMessage(content=summary_prompt)])\n",
    "        return {\n",
    "            \"summary\": summary_response.content,\n",
    "            \"messages\": state[\"messages\"][-4:]  # ä¿ç•™æœ€è¿‘4æ¡æ¶ˆæ¯\n",
    "        }\n",
    "    return {\"summary\": state.get(\"summary\", \"\"), \"messages\": state[\"messages\"]}\n",
    "\n",
    "\n",
    "def call_model_with_summary(state: SummaryState) -> dict:\n",
    "    \"\"\"å¸¦æ‘˜è¦çš„æ¨¡å‹è°ƒç”¨\"\"\"\n",
    "    system_content = \"ä½ æ˜¯ä¸€ä¸ªAIåŠ©æ‰‹ã€‚\"\n",
    "    if state.get(\"summary\"):\n",
    "        system_content += f\"\\nå¯¹è¯æ‘˜è¦ï¼š{state['summary']}\"\n",
    "\n",
    "    system_msg = SystemMessage(content=system_content)\n",
    "    messages = [system_msg] + state[\"messages\"]\n",
    "    response = model.invoke(messages)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "# åˆ›å»ºæ‘˜è¦å›¾\n",
    "builder_summary = StateGraph(SummaryState)\n",
    "builder_summary.add_node(\"summarize\", summarize_conversation)\n",
    "builder_summary.add_node(\"call_model\", call_model_with_summary)\n",
    "builder_summary.add_edge(START, \"summarize\")\n",
    "builder_summary.add_edge(\"summarize\", \"call_model\")\n",
    "builder_summary.add_edge(\"call_model\", END)\n",
    "\n",
    "graph_summary = builder_summary.compile(checkpointer=MemorySaver())\n",
    "print(\"âœ… æ–¹å¼2: æ‘˜è¦å¯¹è¯å›¾åˆ›å»ºå®Œæˆ\")\n",
    "\n"
   ],
   "id": "e5d7e9c16892443f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… æ–¹å¼2: æ‘˜è¦å¯¹è¯å›¾åˆ›å»ºå®Œæˆ\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T04:04:01.053895Z",
     "start_time": "2025-07-22T04:03:36.072635Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# æ–¹å¼2æµ‹è¯•ï¼šå¸¦æ‘˜è¦çš„å¯¹è¯è®°å¿†\n",
    "print(\"\\nğŸ§ª å¼€å§‹æµ‹è¯•æ–¹å¼2ï¼šå¸¦æ‘˜è¦çš„å¯¹è¯è®°å¿†\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "config2 = {\"configurable\": {\"thread_id\": str(uuid.uuid4())}}\n",
    "\n",
    "# åˆå§‹çŠ¶æ€\n",
    "initial_state2 = {\n",
    "    \"messages\": [],\n",
    "    \"summary\": \"\"\n",
    "}\n",
    "\n",
    "print(\"\\nç¬¬1è½®å¯¹è¯:\")\n",
    "user_input1 = \"ä½ å¥½ï¼Œæˆ‘å«æå››ï¼Œæ˜¯ä¸€åæ•°æ®ç§‘å­¦å®¶\"\n",
    "print(f\"ç”¨æˆ·: {user_input1}\")\n",
    "state2 = {\"messages\": [HumanMessage(content=user_input1)], \"summary\": \"\"}\n",
    "result1 = graph_summary.invoke(state2, config2)\n",
    "print(f\"AI: {result1['messages'][-1].content}\")\n",
    "print(f\"æ‘˜è¦: {result1.get('summary', 'æ— ')}\")\n",
    "\n",
    "print(\"\\nç¬¬2è½®å¯¹è¯:\")\n",
    "user_input2 = \"æˆ‘ä¸“é—¨ç ”ç©¶æœºå™¨å­¦ä¹ ç®—æ³•\"\n",
    "print(f\"ç”¨æˆ·: {user_input2}\")\n",
    "result2 = graph_summary.invoke({\"messages\": [HumanMessage(content=user_input2)], \"summary\": result1.get('summary', '')}, config2)\n",
    "print(f\"AI: {result2['messages'][-1].content}\")\n",
    "print(f\"æ‘˜è¦: {result2.get('summary', 'æ— ')}\")\n",
    "\n",
    "# æ¨¡æ‹Ÿé•¿å¯¹è¯è§¦å‘æ‘˜è¦\n",
    "print(\"\\næ¨¡æ‹Ÿé•¿å¯¹è¯ï¼ˆæ·»åŠ å¤šæ¡æ¶ˆæ¯ï¼‰:\")\n",
    "long_messages = []\n",
    "for i in range(12):  # è¶…è¿‡10æ¡æ¶ˆæ¯è§¦å‘æ‘˜è¦\n",
    "    long_messages.append(HumanMessage(content=f\"è¿™æ˜¯ç¬¬{i+1}æ¡æµ‹è¯•æ¶ˆæ¯\"))\n",
    "    long_messages.append(AIMessage(content=f\"æ”¶åˆ°ç¬¬{i+1}æ¡æ¶ˆæ¯\"))\n",
    "\n",
    "state_long = {\"messages\": long_messages, \"summary\": \"\"}\n",
    "result_long = graph_summary.invoke(state_long, config2)\n",
    "print(f\"é•¿å¯¹è¯åçš„æ‘˜è¦: {result_long.get('summary', 'æ— ')}\")\n",
    "print(f\"ä¿ç•™çš„æ¶ˆæ¯æ•°é‡: {len(result_long['messages'])}\")\n",
    "\n",
    "print(\"\\nâœ… æ–¹å¼2æµ‹è¯•å®Œæˆ\")"
   ],
   "id": "b30813208744d4a6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ§ª å¼€å§‹æµ‹è¯•æ–¹å¼2ï¼šå¸¦æ‘˜è¦çš„å¯¹è¯è®°å¿†\n",
      "============================================================\n",
      "\n",
      "ç¬¬1è½®å¯¹è¯:\n",
      "ç”¨æˆ·: ä½ å¥½ï¼Œæˆ‘å«æå››ï¼Œæ˜¯ä¸€åæ•°æ®ç§‘å­¦å®¶\n",
      "AI: ä½ å¥½ï¼Œæå››ï¼å¾ˆé«˜å…´é‡åˆ°ä¸€ä½æ•°æ®ç§‘å­¦é¢†åŸŸçš„ä¸“å®¶ã€‚ä½œä¸ºæ•°æ®ç§‘å­¦å®¶ï¼Œæ‚¨è‚¯å®šåœ¨å¤„ç†å’Œåˆ†æå¤§é‡æ•°æ®æ–¹é¢æœ‰ç€ä¸°å¯Œçš„ç»éªŒå’ŒæŠ€æœ¯çŸ¥è¯†å§ï¼Ÿæœ‰ä»€ä¹ˆå…·ä½“çš„é—®é¢˜æˆ–è®¨è®ºä¸»é¢˜æƒ³è¦æ¢è®¨å—ï¼Ÿæ— è®ºæ˜¯æŠ€æœ¯é—®é¢˜ã€è¡Œä¸šè¶‹åŠ¿è¿˜æ˜¯é¡¹ç›®åˆä½œçš„æœºä¼šï¼Œæˆ‘éƒ½å¾ˆæ„¿æ„å¸®åŠ©è§£ç­”æˆ–äº¤æµã€‚\n",
      "æ‘˜è¦: \n",
      "\n",
      "ç¬¬2è½®å¯¹è¯:\n",
      "ç”¨æˆ·: æˆ‘ä¸“é—¨ç ”ç©¶æœºå™¨å­¦ä¹ ç®—æ³•\n",
      "AI: å¾ˆé«˜å…´å¬åˆ°æ‚¨åœ¨ç ”ç©¶æœºå™¨å­¦ä¹ ç®—æ³•æ–¹é¢æœ‰ç€ä¸“é•¿ï¼å¦‚æœæ‚¨æœ‰ä»»ä½•å…³äºç‰¹å®šæœºå™¨å­¦ä¹ ç®—æ³•çš„é—®é¢˜ã€éœ€è¦å»ºè®®å‚è€ƒèµ„æ–™ï¼Œæˆ–è€…æƒ³è¦è®¨è®ºæŸä¸ªå…·ä½“çš„åº”ç”¨æ¡ˆä¾‹å’ŒæŠ€æœ¯ç»†èŠ‚ï¼Œè¯·éšæ—¶å‘Šè¯‰æˆ‘ã€‚æˆ‘å¯ä»¥æä¾›å¸®åŠ©æˆ–åˆ†äº«æˆ‘çš„çŸ¥è¯†æ¥åŠ æ·±æ‚¨çš„ç†è§£ã€‚æ— è®ºæ˜¯ç†è®ºæ¢è®¨è¿˜æ˜¯å®è·µåº”ç”¨ï¼Œæˆ‘éƒ½ä¹æ„å‚ä¸å…¶ä¸­ã€‚\n",
      "æ‘˜è¦: \n",
      "\n",
      "æ¨¡æ‹Ÿé•¿å¯¹è¯ï¼ˆæ·»åŠ å¤šæ¡æ¶ˆæ¯ï¼‰:\n",
      "é•¿å¯¹è¯åçš„æ‘˜è¦: è¿™æ®µå¯¹è¯ä¸­ï¼Œä¸€æ–¹ä¸æ–­å‘é€ä¸åŒç¼–å·çš„æµ‹è¯•æ¶ˆæ¯ç»™å¦ä¸€æ–¹ã€‚å¦ä¸€æ–¹æ¯æ¬¡æ”¶åˆ°æ¶ˆæ¯åéƒ½ä¼šå›å¤â€œæ”¶åˆ°XXå·æ¶ˆæ¯â€ã€‚æœ€ç»ˆï¼Œè¯¥æ–¹æˆåŠŸæ¥æ”¶äº†ä»ç¬¬1æ¡åˆ°ç¬¬10æ¡çš„æ‰€æœ‰æµ‹è¯•æ¶ˆæ¯ã€‚\n",
      "ä¿ç•™çš„æ¶ˆæ¯æ•°é‡: 1\n",
      "\n",
      "âœ… æ–¹å¼2æµ‹è¯•å®Œæˆ\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## æ–¹å¼3: å¤šå±‚è®°å¿†ç³»ç»Ÿ",
   "id": "ae4f1ea27fb5e9c2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T03:53:58.090171Z",
     "start_time": "2025-07-22T03:53:58.044667Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "class MultiLayerMemoryState(TypedDict):\n",
    "    messages: Annotated[List[BaseMessage], \"å½“å‰å¯¹è¯\"]\n",
    "    short_term: Annotated[List[BaseMessage], \"çŸ­æœŸè®°å¿†\"]\n",
    "    long_term: Annotated[List[str], \"é•¿æœŸè®°å¿†æ‘˜è¦\"]\n",
    "    user_profile: Annotated[Dict[str, Any], \"ç”¨æˆ·æ¡£æ¡ˆ\"]\n",
    "\n",
    "\n",
    "def update_memory_layers(state: MultiLayerMemoryState) -> dict:\n",
    "    \"\"\"æ›´æ–°å¤šå±‚è®°å¿†\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    short_term = state.get(\"short_term\", [])\n",
    "    long_term = state.get(\"long_term\", [])\n",
    "    user_profile = state.get(\"user_profile\", {})\n",
    "\n",
    "    # æ›´æ–°çŸ­æœŸè®°å¿†\n",
    "    short_term.extend(messages)\n",
    "    if len(short_term) > 20:  # çŸ­æœŸè®°å¿†è¶…é™æ—¶è½¬ç§»åˆ°é•¿æœŸ\n",
    "        old_messages = short_term[:10]\n",
    "        summary_text = \"\\n\".join([f\"{msg.type}: {msg.content}\" for msg in old_messages])\n",
    "        summary_prompt = f\"æ‘˜è¦è¿™æ®µå¯¹è¯ï¼š\\n{summary_text}\"\n",
    "        summary = model.invoke([HumanMessage(content=summary_prompt)]).content\n",
    "        long_term.append(summary)\n",
    "        short_term = short_term[10:]\n",
    "\n",
    "    # æ›´æ–°ç”¨æˆ·æ¡£æ¡ˆ\n",
    "    last_message = messages[-1].content if messages else \"\"\n",
    "    if any(keyword in last_message.lower() for keyword in [\"æˆ‘å«\", \"æˆ‘æ˜¯\", \"æˆ‘çš„åå­—\", \"æˆ‘ä½åœ¨\"]):\n",
    "        profile_prompt = f\"ä»è¿™å¥è¯æå–ç”¨æˆ·ä¿¡æ¯ï¼ˆJSONæ ¼å¼ï¼‰ï¼š{last_message}\"\n",
    "        try:\n",
    "            profile_response = model.invoke([HumanMessage(content=profile_prompt)]).content\n",
    "            # ç®€åŒ–å¤„ç†ï¼Œå®é™…åº”ç”¨ä¸­éœ€è¦æ›´å¥½çš„JSONè§£æ\n",
    "            if \"å§“å\" in last_message or \"åå­—\" in last_message:\n",
    "                user_profile[\"name\"] = last_message\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    return {\n",
    "        \"short_term\": short_term,\n",
    "        \"long_term\": long_term[-5:],  # ä¿ç•™æœ€è¿‘5ä¸ªé•¿æœŸè®°å¿†\n",
    "        \"user_profile\": user_profile\n",
    "    }\n",
    "\n",
    "\n",
    "def call_model_multilayer(state: MultiLayerMemoryState) -> dict:\n",
    "    \"\"\"å¤šå±‚è®°å¿†æ¨¡å‹è°ƒç”¨\"\"\"\n",
    "    system_parts = [\"ä½ æ˜¯ä¸€ä¸ªAIåŠ©æ‰‹ã€‚\"]\n",
    "\n",
    "    if state.get(\"user_profile\"):\n",
    "        system_parts.append(f\"ç”¨æˆ·ä¿¡æ¯ï¼š{state['user_profile']}\")\n",
    "\n",
    "    if state.get(\"long_term\"):\n",
    "        system_parts.append(f\"å†å²æ‘˜è¦ï¼š{'; '.join(state['long_term'])}\")\n",
    "\n",
    "    system_msg = SystemMessage(content=\"\\n\".join(system_parts))\n",
    "    recent_messages = state.get(\"short_term\", [])[-6:]  # æœ€è¿‘3è½®å¯¹è¯\n",
    "    messages = [system_msg] + recent_messages + state[\"messages\"]\n",
    "\n",
    "    response = model.invoke(messages)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "# åˆ›å»ºå¤šå±‚è®°å¿†å›¾\n",
    "builder_multilayer = StateGraph(MultiLayerMemoryState)\n",
    "builder_multilayer.add_node(\"update_memory\", update_memory_layers)\n",
    "builder_multilayer.add_node(\"call_model\", call_model_multilayer)\n",
    "builder_multilayer.add_edge(START, \"update_memory\")\n",
    "builder_multilayer.add_edge(\"update_memory\", \"call_model\")\n",
    "builder_multilayer.add_edge(\"call_model\", END)\n",
    "\n",
    "graph_multilayer = builder_multilayer.compile(checkpointer=MemorySaver())\n",
    "print(\"âœ… æ–¹å¼3: å¤šå±‚è®°å¿†å›¾åˆ›å»ºå®Œæˆ\")"
   ],
   "id": "40b66eafbb183eb1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… æ–¹å¼3: å¤šå±‚è®°å¿†å›¾åˆ›å»ºå®Œæˆ\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T04:04:51.298363Z",
     "start_time": "2025-07-22T04:04:19.527660Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# æ–¹å¼3æµ‹è¯•ï¼šå¤šå±‚è®°å¿†ç³»ç»Ÿ\n",
    "print(\"\\nğŸ§ª å¼€å§‹æµ‹è¯•æ–¹å¼3ï¼šå¤šå±‚è®°å¿†ç³»ç»Ÿ\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "config3 = {\"configurable\": {\"thread_id\": str(uuid.uuid4())}}\n",
    "\n",
    "print(\"\\nç¬¬1è½®å¯¹è¯:\")\n",
    "user_input1 = \"ä½ å¥½ï¼Œæˆ‘å«ç‹äº”ï¼Œæ˜¯ä¸€ååŒ»ç”Ÿ\"\n",
    "print(f\"ç”¨æˆ·: {user_input1}\")\n",
    "state3 = {\n",
    "    \"messages\": [HumanMessage(content=user_input1)],\n",
    "    \"short_term\": [],\n",
    "    \"long_term\": [],\n",
    "    \"user_profile\": {}\n",
    "}\n",
    "result1 = graph_multilayer.invoke(state3, config3)\n",
    "print(f\"AI: {result1['messages'][-1].content}\")\n",
    "print(f\"ç”¨æˆ·æ¡£æ¡ˆ: {result1.get('user_profile', {})}\")\n",
    "\n",
    "print(\"\\nç¬¬2è½®å¯¹è¯:\")\n",
    "user_input2 = \"æˆ‘åœ¨åŒ—äº¬åå’ŒåŒ»é™¢å·¥ä½œ\"\n",
    "print(f\"ç”¨æˆ·: {user_input2}\")\n",
    "result2 = graph_multilayer.invoke({\"messages\": [HumanMessage(content=user_input2)], **result1}, config3)\n",
    "print(f\"AI: {result2['messages'][-1].content}\")\n",
    "print(f\"çŸ­æœŸè®°å¿†æ•°é‡: {len(result2.get('short_term', []))}\")\n",
    "\n",
    "print(\"\\nç¬¬3è½®å¯¹è¯:\")\n",
    "user_input3 = \"ä½ çŸ¥é“æˆ‘çš„èŒä¸šå’Œå·¥ä½œåœ°ç‚¹å—ï¼Ÿ\"\n",
    "print(f\"ç”¨æˆ·: {user_input3}\")\n",
    "result3 = graph_multilayer.invoke({\"messages\": [HumanMessage(content=user_input3)], **result2}, config3)\n",
    "print(f\"AI: {result3['messages'][-1].content}\")\n",
    "\n",
    "# æ¨¡æ‹Ÿå¤§é‡å¯¹è¯è§¦å‘é•¿æœŸè®°å¿†\n",
    "print(\"\\næ¨¡æ‹Ÿå¤§é‡å¯¹è¯è§¦å‘é•¿æœŸè®°å¿†:\")\n",
    "many_messages = []\n",
    "for i in range(25):  # è¶…è¿‡20æ¡è§¦å‘é•¿æœŸè®°å¿†\n",
    "    many_messages.append(HumanMessage(content=f\"å¯¹è¯{i+1}\"))\n",
    "\n",
    "state_many = {\n",
    "    \"messages\": [HumanMessage(content=\"æœ€æ–°æ¶ˆæ¯\")],\n",
    "    \"short_term\": many_messages,\n",
    "    \"long_term\": [],\n",
    "    \"user_profile\": {\"name\": \"ç‹äº”\", \"job\": \"åŒ»ç”Ÿ\"}\n",
    "}\n",
    "result_many = graph_multilayer.invoke(state_many, config3)\n",
    "print(f\"é•¿æœŸè®°å¿†æ•°é‡: {len(result_many.get('long_term', []))}\")\n",
    "print(f\"çŸ­æœŸè®°å¿†æ•°é‡: {len(result_many.get('short_term', []))}\")\n",
    "\n",
    "print(\"\\nâœ… æ–¹å¼3æµ‹è¯•å®Œæˆ\")"
   ],
   "id": "b964b25fc72c5010",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ§ª å¼€å§‹æµ‹è¯•æ–¹å¼3ï¼šå¤šå±‚è®°å¿†ç³»ç»Ÿ\n",
      "============================================================\n",
      "\n",
      "ç¬¬1è½®å¯¹è¯:\n",
      "ç”¨æˆ·: ä½ å¥½ï¼Œæˆ‘å«ç‹äº”ï¼Œæ˜¯ä¸€ååŒ»ç”Ÿ\n",
      "AI: æ‚¨å¥½ï¼Œç‹äº”åŒ»ç”Ÿï¼å¾ˆé«˜å…´ä¸ºæ‚¨æœåŠ¡ã€‚å¦‚æœåœ¨ä¸æ‚¨çš„æ‚£è€…äº¤æµæ—¶é‡åˆ°ä»»ä½•é—®é¢˜æˆ–éœ€è¦å»ºè®®ï¼Œè¯·éšæ—¶å‘Šè¯‰æˆ‘ã€‚æ‚¨æœ‰ä»€ä¹ˆå…·ä½“çš„é—®é¢˜æˆ–è€…è¯é¢˜æƒ³è¦è®¨è®ºå—ï¼Ÿæˆ‘å¯ä»¥æä¾›ä¸€äº›å¸®åŠ©å’Œä¿¡æ¯ã€‚\n",
      "ç”¨æˆ·æ¡£æ¡ˆ: {}\n",
      "\n",
      "ç¬¬2è½®å¯¹è¯:\n",
      "ç”¨æˆ·: æˆ‘åœ¨åŒ—äº¬åå’ŒåŒ»é™¢å·¥ä½œ\n",
      "AI: \n",
      "çŸ­æœŸè®°å¿†æ•°é‡: 2\n",
      "\n",
      "ç¬¬3è½®å¯¹è¯:\n",
      "ç”¨æˆ·: ä½ çŸ¥é“æˆ‘çš„èŒä¸šå’Œå·¥ä½œåœ°ç‚¹å—ï¼Ÿ\n",
      "AI: å¦å¤–ï¼Œå¦‚æœæ‚¨æƒ³äº†è§£æœ€æ–°çš„åŒ»ç–—ç ”ç©¶æˆæœã€åŒ»å­¦çŸ¥è¯†æ›´æ–°æˆ–æ˜¯å…³äºç‰¹å®šç–¾ç—…çš„æ²»ç–—æ–¹æ¡ˆç­‰ï¼Œä¹Ÿå¯ä»¥é—®æˆ‘ï¼Œæˆ‘ä¼šå°½åŠ›ä¸ºæ‚¨æä¾›ç›¸å…³ä¿¡æ¯ã€‚è¯·éšæ—¶å‘ŠçŸ¥ï¼\n",
      "\n",
      "æ¨¡æ‹Ÿå¤§é‡å¯¹è¯è§¦å‘é•¿æœŸè®°å¿†:\n",
      "é•¿æœŸè®°å¿†æ•°é‡: 1\n",
      "çŸ­æœŸè®°å¿†æ•°é‡: 16\n",
      "\n",
      "âœ… æ–¹å¼3æµ‹è¯•å®Œæˆ\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## æ–¹å¼4: è·¨çº¿ç¨‹æŒä¹…åŒ–è®°å¿† (ä½¿ç”¨Store)",
   "id": "b0014ba756f520aa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T03:54:17.785734Z",
     "start_time": "2025-07-22T03:54:17.774981Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def call_model_with_store(state: MessagesState, config: RunnableConfig, *, store) -> dict:\n",
    "    \"\"\"ä½¿ç”¨Storeçš„è·¨çº¿ç¨‹è®°å¿†\"\"\"\n",
    "    user_id = config[\"configurable\"].get(\"user_id\", \"default\")\n",
    "    namespace = (\"memories\", user_id)\n",
    "\n",
    "    # æœç´¢ç›¸å…³è®°å¿†\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    memories = store.search(namespace, query=str(last_message.content))\n",
    "    memory_info = \"\\n\".join([d.value.get(\"data\", \"\") for d in memories])\n",
    "\n",
    "    # æ„å»ºç³»ç»Ÿæ¶ˆæ¯\n",
    "    system_content = \"ä½ æ˜¯ä¸€ä¸ªAIåŠ©æ‰‹ã€‚\"\n",
    "    if memory_info:\n",
    "        system_content += f\"\\nç›¸å…³è®°å¿†ï¼š{memory_info}\"\n",
    "\n",
    "    # å­˜å‚¨æ–°è®°å¿†\n",
    "    if \"è®°ä½\" in last_message.content or \"æˆ‘å«\" in last_message.content:\n",
    "        memory_data = {\"data\": last_message.content, \"timestamp\": datetime.now().isoformat()}\n",
    "        store.put(namespace, str(uuid.uuid4()), memory_data)\n",
    "\n",
    "    system_msg = SystemMessage(content=system_content)\n",
    "    messages = [system_msg] + state[\"messages\"]\n",
    "    response = model.invoke(messages)\n",
    "\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "# åˆ›å»ºStoreå›¾\n",
    "store = InMemoryStore()\n",
    "builder_store = StateGraph(MessagesState)\n",
    "builder_store.add_node(\"call_model\", call_model_with_store)\n",
    "builder_store.add_edge(START, \"call_model\")\n",
    "builder_store.add_edge(\"call_model\", END)\n",
    "\n",
    "graph_store = builder_store.compile(checkpointer=MemorySaver(), store=store)\n",
    "print(\"âœ… æ–¹å¼4: Storeè®°å¿†å›¾åˆ›å»ºå®Œæˆ\")"
   ],
   "id": "3cd9417983e443bb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… æ–¹å¼4: Storeè®°å¿†å›¾åˆ›å»ºå®Œæˆ\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T04:05:28.977942Z",
     "start_time": "2025-07-22T04:05:10.762488Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# æ–¹å¼4æµ‹è¯•ï¼šè·¨çº¿ç¨‹æŒä¹…åŒ–è®°å¿†\n",
    "print(\"\\nğŸ§ª å¼€å§‹æµ‹è¯•æ–¹å¼4ï¼šè·¨çº¿ç¨‹æŒä¹…åŒ–è®°å¿†\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "config4 = {\"configurable\": {\"thread_id\": str(uuid.uuid4()), \"user_id\": \"test_user_001\"}}\n",
    "\n",
    "print(\"\\nç¬¬1è½®å¯¹è¯ï¼ˆå­˜å‚¨è®°å¿†ï¼‰:\")\n",
    "user_input1 = \"è®°ä½æˆ‘å«èµµå…­ï¼Œæˆ‘æ˜¯ä¸€åæ•™å¸ˆ\"\n",
    "print(f\"ç”¨æˆ·: {user_input1}\")\n",
    "result1 = graph_store.invoke({\"messages\": [HumanMessage(content=user_input1)]}, config4)\n",
    "print(f\"AI: {result1['messages'][-1].content}\")\n",
    "\n",
    "print(\"\\nç¬¬2è½®å¯¹è¯:\")\n",
    "user_input2 = \"è®°ä½æˆ‘æ•™æ•°å­¦ï¼Œåœ¨æ¸…åå¤§å­¦å·¥ä½œ\"\n",
    "print(f\"ç”¨æˆ·: {user_input2}\")\n",
    "result2 = graph_store.invoke({\"messages\": [HumanMessage(content=user_input2)]}, config4)\n",
    "print(f\"AI: {result2['messages'][-1].content}\")\n",
    "\n",
    "print(\"\\nç¬¬3è½®å¯¹è¯ï¼ˆæµ‹è¯•è®°å¿†æ£€ç´¢ï¼‰:\")\n",
    "user_input3 = \"æˆ‘çš„èŒä¸šæ˜¯ä»€ä¹ˆï¼Ÿ\"\n",
    "print(f\"ç”¨æˆ·: {user_input3}\")\n",
    "result3 = graph_store.invoke({\"messages\": [HumanMessage(content=user_input3)]}, config4)\n",
    "print(f\"AI: {result3['messages'][-1].content}\")\n",
    "\n",
    "# æµ‹è¯•è·¨çº¿ç¨‹è®°å¿†\n",
    "print(\"\\næµ‹è¯•è·¨çº¿ç¨‹è®°å¿†ï¼ˆæ–°çº¿ç¨‹ï¼ŒåŒç”¨æˆ·ï¼‰:\")\n",
    "config4_new = {\"configurable\": {\"thread_id\": str(uuid.uuid4()), \"user_id\": \"test_user_001\"}}\n",
    "user_input4 = \"ä½ è¿˜è®°å¾—æˆ‘çš„åå­—å—ï¼Ÿ\"\n",
    "print(f\"ç”¨æˆ·: {user_input4}\")\n",
    "result4 = graph_store.invoke({\"messages\": [HumanMessage(content=user_input4)]}, config4_new)\n",
    "print(f\"AI: {result4['messages'][-1].content}\")\n",
    "\n",
    "print(\"\\nâœ… æ–¹å¼4æµ‹è¯•å®Œæˆ\")"
   ],
   "id": "7e8721504fb4aefc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ§ª å¼€å§‹æµ‹è¯•æ–¹å¼4ï¼šè·¨çº¿ç¨‹æŒä¹…åŒ–è®°å¿†\n",
      "============================================================\n",
      "\n",
      "ç¬¬1è½®å¯¹è¯ï¼ˆå­˜å‚¨è®°å¿†ï¼‰:\n",
      "ç”¨æˆ·: è®°ä½æˆ‘å«èµµå…­ï¼Œæˆ‘æ˜¯ä¸€åæ•™å¸ˆ\n",
      "AI: å¥½çš„ï¼Œæˆ‘ä¼šè®°ä½ä½ çš„åå­—æ˜¯èµµå…­ï¼Œå¹¶ä¸”ä½ ç°åœ¨æ˜¯ä¸€åæ•™å¸ˆã€‚å¦‚æœæœ‰ä»»ä½•å…³äºæ•™å­¦æˆ–è€…ä¸æ•™å¸ˆç›¸å…³çš„é—®é¢˜ï¼Œæˆ‘ä¼šå°½åŠ›å¸®åŠ©ä½ ã€‚ä½ å¯ä»¥éšæ—¶å‘æˆ‘æé—®æˆ–è®¨è®ºæ•™è‚²ç›¸å…³çš„ä¸»é¢˜ã€‚\n",
      "\n",
      "ç¬¬2è½®å¯¹è¯:\n",
      "ç”¨æˆ·: è®°ä½æˆ‘æ•™æ•°å­¦ï¼Œåœ¨æ¸…åå¤§å­¦å·¥ä½œ\n",
      "AI: å¥½çš„ï¼Œæˆ‘å·²ç»è®°ä½äº†è¿™äº›ä¿¡æ¯ï¼šä½ æ˜¯èµµå…­ï¼Œç›®å‰åœ¨æ¸…åå¤§å­¦æ‹…ä»»æ•°å­¦æ•™å¸ˆçš„èŒåŠ¡ã€‚å¦‚æœä½ æœ‰ä»»ä½•å…³äºæ•°å­¦æ•™å­¦ã€å­¦æœ¯ç ”ç©¶æˆ–è€…ä¸æ•™å­¦ç›¸å…³çš„é—®é¢˜ï¼Œæˆ‘ä¼šå°½åŠ›å¸®åŠ©ä½ ã€‚éšæ—¶å¯ä»¥å‘æˆ‘æé—®ã€‚\n",
      "\n",
      "ç¬¬3è½®å¯¹è¯ï¼ˆæµ‹è¯•è®°å¿†æ£€ç´¢ï¼‰:\n",
      "ç”¨æˆ·: æˆ‘çš„èŒä¸šæ˜¯ä»€ä¹ˆï¼Ÿ\n",
      "AI: æ ¹æ®ä½ ä¹‹å‰æä¾›çš„ä¿¡æ¯ï¼Œä½ çš„èŒä¸šæ˜¯æ•™å¸ˆï¼Œå¹¶ä¸”ä½ ç°åœ¨æ˜¯ä¸€åæ•°å­¦æ•™å¸ˆï¼Œåœ¨æ¸…åå¤§å­¦å·¥ä½œã€‚æ‰€ä»¥ï¼Œå¯ä»¥è¯´ä½ çš„èŒä¸šæ˜¯åœ¨æ¸…åå¤§å­¦æ‹…ä»»æ•°å­¦æ•™å¸ˆã€‚å¦‚æœä½ æœ‰å…¶ä»–é—®é¢˜æˆ–éœ€è¦è¿›ä¸€æ­¥çš„å¸®åŠ©ï¼Œè¯·å‘Šè¯‰æˆ‘ï¼\n",
      "\n",
      "æµ‹è¯•è·¨çº¿ç¨‹è®°å¿†ï¼ˆæ–°çº¿ç¨‹ï¼ŒåŒç”¨æˆ·ï¼‰:\n",
      "ç”¨æˆ·: ä½ è¿˜è®°å¾—æˆ‘çš„åå­—å—ï¼Ÿ\n",
      "AI: æ‚¨è¿˜æ²¡æœ‰æåˆ°æ‚¨çš„åå­—ï¼Œæ‰€ä»¥æˆ‘å¹¶ä¸çŸ¥é“æ‚¨çš„åå­—æ˜¯ä½•è®¸äººä¹Ÿã€‚ä¸è¿‡å¦‚æœæ‚¨æ„¿æ„å‘Šè¯‰æˆ‘ï¼Œæˆ‘ä¼šå¾ˆé«˜å…´åœ°è®°ä½æ‚¨ã€‚\n",
      "\n",
      "âœ… æ–¹å¼4æµ‹è¯•å®Œæˆ\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## æ–¹å¼5: æ™ºèƒ½è·¯ç”±è®°å¿†ç³»ç»Ÿ",
   "id": "3ab9d5336b6ae776"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T03:54:47.918868Z",
     "start_time": "2025-07-22T03:54:47.848307Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## æ–¹å¼5: æ™ºèƒ½è·¯ç”±è®°å¿†ç³»ç»Ÿ\n",
    "class RoutedMemoryState(TypedDict):\n",
    "    messages: Annotated[List[BaseMessage], \"å¯¹è¯æ¶ˆæ¯\"]\n",
    "    memory_type: Annotated[str, \"è®°å¿†ç±»å‹\"]\n",
    "    context: Annotated[Dict[str, Any], \"ä¸Šä¸‹æ–‡ä¿¡æ¯\"]\n",
    "\n",
    "\n",
    "def classify_message(state: RoutedMemoryState) -> dict:\n",
    "    \"\"\"åˆ†ç±»æ¶ˆæ¯ç±»å‹\"\"\"\n",
    "    last_message = state[\"messages\"][-1].content.lower()\n",
    "\n",
    "    if any(word in last_message for word in [\"è®°ä½\", \"æˆ‘å«\", \"æˆ‘æ˜¯\", \"æˆ‘çš„\"]):\n",
    "        memory_type = \"personal\"\n",
    "    elif any(word in last_message for word in [\"ä»€ä¹ˆ\", \"æ€ä¹ˆ\", \"ä¸ºä»€ä¹ˆ\", \"å¦‚ä½•\"]):\n",
    "        memory_type = \"question\"\n",
    "    else:\n",
    "        memory_type = \"casual\"\n",
    "\n",
    "    return {\"memory_type\": memory_type}\n",
    "\n",
    "\n",
    "def handle_personal_memory(state: RoutedMemoryState) -> dict:\n",
    "    \"\"\"å¤„ç†ä¸ªäººä¿¡æ¯è®°å¿†\"\"\"\n",
    "    context = state.get(\"context\", {})\n",
    "    last_message = state[\"messages\"][-1].content\n",
    "\n",
    "    # æå–ä¸ªäººä¿¡æ¯\n",
    "    if \"æˆ‘å«\" in last_message or \"æˆ‘æ˜¯\" in last_message:\n",
    "        context[\"personal_info\"] = last_message\n",
    "\n",
    "    system_msg = SystemMessage(content=f\"ä½ æ˜¯AIåŠ©æ‰‹ã€‚ç”¨æˆ·ä¿¡æ¯ï¼š{context.get('personal_info', 'æ— ')}\")\n",
    "    messages = [system_msg] + state[\"messages\"]\n",
    "    response = model.invoke(messages)\n",
    "\n",
    "    return {\"messages\": [response], \"context\": context}\n",
    "\n",
    "\n",
    "def handle_question_memory(state: RoutedMemoryState) -> dict:\n",
    "    \"\"\"å¤„ç†é—®é¢˜è®°å¿†\"\"\"\n",
    "    context = state.get(\"context\", {})\n",
    "\n",
    "    system_content = \"ä½ æ˜¯AIåŠ©æ‰‹ï¼Œæ“…é•¿å›ç­”é—®é¢˜ã€‚\"\n",
    "    if context.get(\"personal_info\"):\n",
    "        system_content += f\"\\nç”¨æˆ·ä¿¡æ¯ï¼š{context['personal_info']}\"\n",
    "\n",
    "    system_msg = SystemMessage(content=system_content)\n",
    "    messages = [system_msg] + state[\"messages\"]\n",
    "    response = model.invoke(messages)\n",
    "\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "def handle_casual_memory(state: RoutedMemoryState) -> dict:\n",
    "    \"\"\"å¤„ç†æ—¥å¸¸å¯¹è¯è®°å¿†\"\"\"\n",
    "    system_msg = SystemMessage(content=\"ä½ æ˜¯ä¸€ä¸ªå‹å¥½çš„AIåŠ©æ‰‹ã€‚\")\n",
    "    messages = [system_msg] + state[\"messages\"][-6:]  # åªä¿ç•™æœ€è¿‘å¯¹è¯\n",
    "    response = model.invoke(messages)\n",
    "\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "def route_memory_type(state: RoutedMemoryState) -> str:\n",
    "    \"\"\"è·¯ç”±åˆ°ä¸åŒçš„è®°å¿†å¤„ç†èŠ‚ç‚¹\"\"\"\n",
    "    return state[\"memory_type\"]\n",
    "\n",
    "\n",
    "# åˆ›å»ºè·¯ç”±å›¾\n",
    "builder_routed = StateGraph(RoutedMemoryState)\n",
    "builder_routed.add_node(\"classify\", classify_message)\n",
    "builder_routed.add_node(\"personal\", handle_personal_memory)\n",
    "builder_routed.add_node(\"question\", handle_question_memory)\n",
    "builder_routed.add_node(\"casual\", handle_casual_memory)\n",
    "\n",
    "builder_routed.add_edge(START, \"classify\")\n",
    "builder_routed.add_conditional_edges(\n",
    "    \"classify\",\n",
    "    route_memory_type,\n",
    "    {\n",
    "        \"personal\": \"personal\",\n",
    "        \"question\": \"question\",\n",
    "        \"casual\": \"casual\"\n",
    "    }\n",
    ")\n",
    "builder_routed.add_edge(\"personal\", END)\n",
    "builder_routed.add_edge(\"question\", END)\n",
    "builder_routed.add_edge(\"casual\", END)\n",
    "\n",
    "graph_routed = builder_routed.compile(checkpointer=MemorySaver())\n",
    "print(\"âœ… æ–¹å¼5: è·¯ç”±è®°å¿†å›¾åˆ›å»ºå®Œæˆ\")"
   ],
   "id": "46efb313862916fb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… æ–¹å¼5: è·¯ç”±è®°å¿†å›¾åˆ›å»ºå®Œæˆ\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T04:06:37.336989Z",
     "start_time": "2025-07-22T04:06:22.181823Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# æ–¹å¼5æµ‹è¯•ï¼šæ™ºèƒ½è·¯ç”±è®°å¿†ç³»ç»Ÿ\n",
    "print(\"\\nğŸ§ª å¼€å§‹æµ‹è¯•æ–¹å¼5ï¼šæ™ºèƒ½è·¯ç”±è®°å¿†ç³»ç»Ÿ\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "config5 = {\"configurable\": {\"thread_id\": str(uuid.uuid4())}}\n",
    "\n",
    "print(\"\\nç¬¬1è½®å¯¹è¯ï¼ˆä¸ªäººä¿¡æ¯ç±»å‹ï¼‰:\")\n",
    "user_input1 = \"ä½ å¥½ï¼Œæˆ‘å«å­™ä¸ƒï¼Œæˆ‘æ˜¯ä¸€åå·¥ç¨‹å¸ˆ\"\n",
    "print(f\"ç”¨æˆ·: {user_input1}\")\n",
    "state5 = {\n",
    "    \"messages\": [HumanMessage(content=user_input1)],\n",
    "    \"memory_type\": \"\",\n",
    "    \"context\": {}\n",
    "}\n",
    "result1 = graph_routed.invoke(state5, config5)\n",
    "print(f\"AI: {result1['messages'][-1].content}\")\n",
    "print(f\"åˆ†ç±»ç±»å‹: {result1.get('memory_type', 'æœªçŸ¥')}\")\n",
    "print(f\"ä¸Šä¸‹æ–‡: {result1.get('context', {})}\")\n",
    "\n",
    "print(\"\\nç¬¬2è½®å¯¹è¯ï¼ˆé—®é¢˜ç±»å‹ï¼‰:\")\n",
    "user_input2 = \"ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ\"\n",
    "print(f\"ç”¨æˆ·: {user_input2}\")\n",
    "state5_2 = {\n",
    "    \"messages\": [HumanMessage(content=user_input2)],\n",
    "    \"memory_type\": \"\",\n",
    "    \"context\": result1.get('context', {})\n",
    "}\n",
    "result2 = graph_routed.invoke(state5_2, config5)\n",
    "print(f\"AI: {result2['messages'][-1].content}\")\n",
    "print(f\"åˆ†ç±»ç±»å‹: {result2.get('memory_type', 'æœªçŸ¥')}\")\n",
    "\n",
    "print(\"\\nç¬¬3è½®å¯¹è¯ï¼ˆæ—¥å¸¸å¯¹è¯ç±»å‹ï¼‰:\")\n",
    "user_input3 = \"ä»Šå¤©å¤©æ°”ä¸é”™\"\n",
    "print(f\"ç”¨æˆ·: {user_input3}\")\n",
    "state5_3 = {\n",
    "    \"messages\": [HumanMessage(content=user_input3)],\n",
    "    \"memory_type\": \"\",\n",
    "    \"context\": result1.get('context', {})\n",
    "}\n",
    "result3 = graph_routed.invoke(state5_3, config5)\n",
    "print(f\"AI: {result3['messages'][-1].content}\")\n",
    "print(f\"åˆ†ç±»ç±»å‹: {result3.get('memory_type', 'æœªçŸ¥')}\")\n",
    "\n",
    "print(\"\\nç¬¬4è½®å¯¹è¯ï¼ˆæµ‹è¯•ä¸ªäººä¿¡æ¯è®°å¿†ï¼‰:\")\n",
    "user_input4 = \"ä½ è¿˜è®°å¾—æˆ‘çš„åå­—å’ŒèŒä¸šå—ï¼Ÿ\"\n",
    "print(f\"ç”¨æˆ·: {user_input4}\")\n",
    "state5_4 = {\n",
    "    \"messages\": [HumanMessage(content=user_input4)],\n",
    "    \"memory_type\": \"\",\n",
    "    \"context\": result1.get('context', {})\n",
    "}\n",
    "result4 = graph_routed.invoke(state5_4, config5)\n",
    "print(f\"AI: {result4['messages'][-1].content}\")\n",
    "print(f\"åˆ†ç±»ç±»å‹: {result4.get('memory_type', 'æœªçŸ¥')}\")\n",
    "\n",
    "print(\"\\nâœ… æ–¹å¼5æµ‹è¯•å®Œæˆ\")"
   ],
   "id": "79e396292089a66f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ§ª å¼€å§‹æµ‹è¯•æ–¹å¼5ï¼šæ™ºèƒ½è·¯ç”±è®°å¿†ç³»ç»Ÿ\n",
      "============================================================\n",
      "\n",
      "ç¬¬1è½®å¯¹è¯ï¼ˆä¸ªäººä¿¡æ¯ç±»å‹ï¼‰:\n",
      "ç”¨æˆ·: ä½ å¥½ï¼Œæˆ‘å«å­™ä¸ƒï¼Œæˆ‘æ˜¯ä¸€åå·¥ç¨‹å¸ˆ\n",
      "AI: ä½ å¥½ï¼å¾ˆé«˜å…´è®¤è¯†ä½ ï¼Œå­™ä¸ƒã€‚ä½œä¸ºä¸€åå·¥ç¨‹å¸ˆï¼Œä½ è§‰å¾—ä½ çš„å·¥ä½œç»™ç¤¾ä¼šå¸¦æ¥äº†å“ªäº›ç§¯æçš„å½±å“å‘¢ï¼Ÿæˆ–è€…æœ‰ä»€ä¹ˆç‰¹åˆ«çš„æŒ‘æˆ˜å—ï¼Ÿ\n",
      "åˆ†ç±»ç±»å‹: personal\n",
      "ä¸Šä¸‹æ–‡: {'personal_info': 'ä½ å¥½ï¼Œæˆ‘å«å­™ä¸ƒï¼Œæˆ‘æ˜¯ä¸€åå·¥ç¨‹å¸ˆ'}\n",
      "\n",
      "ç¬¬2è½®å¯¹è¯ï¼ˆé—®é¢˜ç±»å‹ï¼‰:\n",
      "ç”¨æˆ·: ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ\n",
      "AI: äººå·¥æ™ºèƒ½ï¼ˆArtificial Intelligenceï¼Œç®€ç§°AIï¼‰æ˜¯æŒ‡åˆ©ç”¨è®¡ç®—æœºæ¨¡æ‹Ÿã€å»¶ä¼¸å’Œæ‰©å±•äººçš„æ™ºèƒ½çš„æŠ€æœ¯ã€‚å®ƒä½¿æœºå™¨èƒ½å¤Ÿåœ¨æ²¡æœ‰äººç±»æ˜ç¡®ç¼–ç¨‹çš„æƒ…å†µä¸‹æ‰§è¡Œæ™ºèƒ½ä»»åŠ¡ï¼Œæ¶µç›–äº†è®¸å¤šé¢†åŸŸï¼ŒåŒ…æ‹¬å­¦ä¹ ã€æ¨ç†ã€è§„åˆ’ã€é—®é¢˜æ±‚è§£ã€æ„ŸçŸ¥ä»¥åŠè¯­è¨€ç†è§£ç­‰ã€‚\n",
      "\n",
      "ç®€å•æ¥è¯´ï¼Œå°±æ˜¯é€šè¿‡ç®—æ³•å’ŒæŠ€æœ¯è®©è®¡ç®—æœºèƒ½å¤Ÿæ¨¡ä»¿æˆ–å®ç°äººç±»çš„æ™ºèƒ½è¡Œä¸ºï¼Œæ¯”å¦‚è¯†åˆ«å›¾åƒã€å¤„ç†è¯­éŸ³ã€ç©æ¸¸æˆç”šè‡³åˆ›ä½œè‰ºæœ¯ä½œå“ã€‚éšç€æŠ€æœ¯çš„è¿›æ­¥ï¼Œäººå·¥æ™ºèƒ½å·²ç»åœ¨å¾ˆå¤šè¡Œä¸šå’Œæ—¥å¸¸ç”Ÿæ´»ä¸­æ‰®æ¼”ç€è¶Šæ¥è¶Šé‡è¦çš„è§’è‰²ã€‚\n",
      "åˆ†ç±»ç±»å‹: question\n",
      "\n",
      "ç¬¬3è½®å¯¹è¯ï¼ˆæ—¥å¸¸å¯¹è¯ç±»å‹ï¼‰:\n",
      "ç”¨æˆ·: ä»Šå¤©å¤©æ°”ä¸é”™\n",
      "AI: æ˜¯çš„ï¼Œä¸é”™çš„å¤©æ°”ï¼æ‚¨æ‰“ç®—å»åšäº›ä»€ä¹ˆå‘¢ï¼Ÿæœ‰æ—¶å€™å¥½å¤©æ°”ä¼šè®©äººæ„Ÿåˆ°æ›´åŠ æ„‰æ‚¦å’Œæœ‰æ´»åŠ›ã€‚\n",
      "åˆ†ç±»ç±»å‹: casual\n",
      "\n",
      "ç¬¬4è½®å¯¹è¯ï¼ˆæµ‹è¯•ä¸ªäººä¿¡æ¯è®°å¿†ï¼‰:\n",
      "ç”¨æˆ·: ä½ è¿˜è®°å¾—æˆ‘çš„åå­—å’ŒèŒä¸šå—ï¼Ÿ\n",
      "AI: å½“ç„¶è®°å¾—ï¼Œä½ çš„åå­—æ˜¯å­™ä¸ƒï¼Œä½ ç°åœ¨æ˜¯ä¸€åå·¥ç¨‹å¸ˆã€‚\n",
      "åˆ†ç±»ç±»å‹: personal\n",
      "\n",
      "âœ… æ–¹å¼5æµ‹è¯•å®Œæˆ\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T04:07:03.242795Z",
     "start_time": "2025-07-22T04:06:59.311702Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# æ–¹å¼6æµ‹è¯•ï¼šæµå¼å¯¹è¯è®°å¿†\n",
    "print(\"\\nğŸ§ª å¼€å§‹æµ‹è¯•æ–¹å¼6ï¼šæµå¼å¯¹è¯è®°å¿†\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "config6 = {\"configurable\": {\"thread_id\": str(uuid.uuid4())}}\n",
    "\n",
    "print(\"\\nç¬¬1è½®æµå¼å¯¹è¯:\")\n",
    "user_input1 = \"ä½ å¥½ï¼Œæˆ‘æ˜¯å‘¨å…«ï¼Œè¯·ç”¨æµå¼æ–¹å¼å›å¤æˆ‘\"\n",
    "print(f\"ç”¨æˆ·: {user_input1}\")\n",
    "print(\"AI: \", end=\"\", flush=True)\n",
    "\n",
    "full_response = \"\"\n",
    "for chunk in graph_basic.stream(\n",
    "    {\"messages\": [HumanMessage(content=user_input1)]},\n",
    "    config6\n",
    "):\n",
    "    if \"call_model\" in chunk and \"messages\" in chunk[\"call_model\"]:\n",
    "        content = chunk[\"call_model\"][\"messages\"][-1].content\n",
    "        print(content, end=\"\", flush=True)\n",
    "        full_response += content\n",
    "\n",
    "print(f\"\\nå®Œæ•´å›å¤: {full_response}\")\n",
    "\n",
    "print(\"\\nç¬¬2è½®æµå¼å¯¹è¯:\")\n",
    "user_input2 = \"ä½ è¿˜è®°å¾—æˆ‘åˆšæ‰è¯´çš„åå­—å—ï¼Ÿ\"\n",
    "print(f\"ç”¨æˆ·: {user_input2}\")\n",
    "print(\"AI: \", end=\"\", flush=True)\n",
    "\n",
    "full_response2 = \"\"\n",
    "for chunk in graph_basic.stream(\n",
    "    {\"messages\": [HumanMessage(content=user_input2)]},\n",
    "    config6\n",
    "):\n",
    "    if \"call_model\" in chunk and \"messages\" in chunk[\"call_model\"]:\n",
    "        content = chunk[\"call_model\"][\"messages\"][-1].content\n",
    "        print(content, end=\"\", flush=True)\n",
    "        full_response2 += content\n",
    "\n",
    "print(f\"\\nå®Œæ•´å›å¤: {full_response2}\")\n",
    "\n",
    "print(\"\\nâœ… æ–¹å¼6æµ‹è¯•å®Œæˆ\")"
   ],
   "id": "4d14bbb391ea81a2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ§ª å¼€å§‹æµ‹è¯•æ–¹å¼6ï¼šæµå¼å¯¹è¯è®°å¿†\n",
      "============================================================\n",
      "\n",
      "ç¬¬1è½®æµå¼å¯¹è¯:\n",
      "ç”¨æˆ·: ä½ å¥½ï¼Œæˆ‘æ˜¯å‘¨å…«ï¼Œè¯·ç”¨æµå¼æ–¹å¼å›å¤æˆ‘\n",
      "AI: ä½ å¥½å‘¨å…«ï¼Œå¾ˆé«˜å…´ä¸ºä½ æœåŠ¡ã€‚è¯·é—®æˆ‘å¯ä»¥å¸®ä½ åšä»€ä¹ˆï¼Ÿ\n",
      "å®Œæ•´å›å¤: ä½ å¥½å‘¨å…«ï¼Œå¾ˆé«˜å…´ä¸ºä½ æœåŠ¡ã€‚è¯·é—®æˆ‘å¯ä»¥å¸®ä½ åšä»€ä¹ˆï¼Ÿ\n",
      "\n",
      "ç¬¬2è½®æµå¼å¯¹è¯:\n",
      "ç”¨æˆ·: ä½ è¿˜è®°å¾—æˆ‘åˆšæ‰è¯´çš„åå­—å—ï¼Ÿ\n",
      "AI: å½“ç„¶ï¼Œä½ åˆšåˆšè¯´ä½ çš„åå­—æ˜¯å‘¨å…«ã€‚æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ\n",
      "å®Œæ•´å›å¤: å½“ç„¶ï¼Œä½ åˆšåˆšè¯´ä½ çš„åå­—æ˜¯å‘¨å…«ã€‚æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ\n",
      "\n",
      "âœ… æ–¹å¼6æµ‹è¯•å®Œæˆ\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "## æ€»ç»“\n",
    "æœ¬notebookå±•ç¤ºäº†6ç§LangGraphå¯¹è¯è®°å¿†å®ç°æ–¹æ³•ï¼š\n",
    "\n",
    "1. ** åŸºç¡€è®°å¿† ** - ä½¿ç”¨MessagesStateè‡ªåŠ¨ç®¡ç†å¯¹è¯å†å²\n",
    "2. ** æ‘˜è¦è®°å¿† ** - è‡ªåŠ¨æ‘˜è¦é•¿å¯¹è¯ï¼ŒèŠ‚çœå†…å­˜\n",
    "3. ** å¤šå±‚è®°å¿† ** - çŸ­æœŸ / é•¿æœŸè®°å¿†åˆ†å±‚ï¼Œç”¨æˆ·æ¡£æ¡ˆç®¡ç†\n",
    "4. ** Storeè®°å¿† ** - è·¨çº¿ç¨‹æŒä¹…åŒ–ï¼Œæ”¯æŒæœç´¢\n",
    "5. ** è·¯ç”±è®°å¿† ** - æ™ºèƒ½åˆ†ç±»ä¸åŒç±»å‹çš„å¯¹è¯\n",
    "6. ** æµå¼è®°å¿† ** - æ”¯æŒå®æ—¶æµå¼è¾“å‡º\n",
    "\n",
    "é€‰æ‹©å»ºè®®ï¼š\n",
    "- ç®€å•åº”ç”¨ï¼šæ–¹å¼1\n",
    "- é•¿å¯¹è¯ï¼šæ–¹å¼2\n",
    "- å¤æ‚åœºæ™¯ï¼šæ–¹å¼3ã€5\n",
    "- å¤šç”¨æˆ·ï¼šæ–¹å¼4\n",
    "- å®æ—¶äº¤äº’ï¼šæ–¹å¼6\n",
    "\n",
    "LangGraphçš„ä¼˜åŠ¿ï¼š\n",
    "- è‡ªåŠ¨çŠ¶æ€ç®¡ç†\n",
    "- å†…ç½®æ£€æŸ¥ç‚¹æœºåˆ¶\n",
    "- çµæ´»çš„å›¾ç»“æ„\n",
    "- å¼ºå¤§çš„æ¡ä»¶è·¯ç”±"
   ],
   "id": "29ab4079f93d4738"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T03:45:10.263166Z",
     "start_time": "2025-07-22T03:44:51.802118Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# å®šä¹‰è°ƒç”¨æ¨¡å‹çš„èŠ‚ç‚¹å‡½æ•°\n",
    "def call_model(state: MessagesState) -> dict:\n",
    "    \"\"\"è°ƒç”¨æ¨¡å‹å¹¶è¿”å›å“åº”\"\"\"\n",
    "    # æ·»åŠ ç³»ç»Ÿæç¤º\n",
    "    system_msg = {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"ä½ æ˜¯ä¸€ä¸ªå‹å¥½çš„AIåŠ©æ‰‹ï¼Œèƒ½å¤Ÿè®°ä½å¯¹è¯å†å²å¹¶æä¾›æœ‰ç”¨çš„å›ç­”ã€‚\"\n",
    "    }\n",
    "\n",
    "    # æ„å»ºæ¶ˆæ¯åˆ—è¡¨\n",
    "    messages = [system_msg] + state[\"messages\"]\n",
    "\n",
    "    # è°ƒç”¨æ¨¡å‹\n",
    "    response = model.invoke(messages)\n",
    "\n",
    "    # è¿”å›æ–°æ¶ˆæ¯\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "# åˆ›å»ºçŠ¶æ€å›¾\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"call_model\", call_model)\n",
    "builder.add_edge(START, \"call_model\")\n",
    "builder.add_edge(\"call_model\", END)\n",
    "\n",
    "# ç¼–è¯‘å›¾å¹¶æ·»åŠ å†…å­˜æ£€æŸ¥ç‚¹\n",
    "memory = MemorySaver()\n",
    "graph = builder.compile(checkpointer=memory)\n",
    "\n",
    "print(\"âœ… åŸºç¡€å¯¹è¯å›¾åˆ›å»ºå®Œæˆ\")\n",
    "\n",
    "# æµ‹è¯•åŸºç¡€å¯¹è¯è®°å¿†\n",
    "print(\"=\" * 50)\n",
    "print(\"æµ‹è¯•åŸºç¡€å¯¹è¯è®°å¿†\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# åˆ›å»ºä¼šè¯é…ç½®\n",
    "config = {\"configurable\": {\"thread_id\": str(uuid.uuid4())}}\n",
    "\n",
    "# ç¬¬ä¸€è½®å¯¹è¯\n",
    "print(\"\\nç¬¬1è½®å¯¹è¯:\")\n",
    "user_input1 = \"ä½ å¥½ï¼Œæˆ‘å«å¼ ä¸‰ï¼Œæ˜¯ä¸€åç¨‹åºå‘˜\"\n",
    "print(f\"ç”¨æˆ·: {user_input1}\")\n",
    "\n",
    "result1 = graph.invoke(\n",
    "    {\"messages\": [HumanMessage(content=user_input1)]},\n",
    "    config\n",
    ")\n",
    "print(f\"AI: {result1['messages'][-1].content}\")\n",
    "\n",
    "# ç¬¬äºŒè½®å¯¹è¯ - æµ‹è¯•è®°å¿†åŠŸèƒ½\n",
    "print(\"\\nç¬¬2è½®å¯¹è¯:\")\n",
    "user_input2 = \"ä½ è¿˜è®°å¾—æˆ‘çš„åå­—å’ŒèŒä¸šå—ï¼Ÿ\"\n",
    "print(f\"ç”¨æˆ·: {user_input2}\")\n",
    "\n",
    "result2 = graph.invoke(\n",
    "    {\"messages\": [HumanMessage(content=user_input2)]},\n",
    "    config\n",
    ")\n",
    "print(f\"AI: {result2['messages'][-1].content}\")\n",
    "\n",
    "# ç¬¬ä¸‰è½®å¯¹è¯\n",
    "print(\"\\nç¬¬3è½®å¯¹è¯:\")\n",
    "user_input3 = \"æˆ‘ä»Šå¹´30å²ï¼Œä½åœ¨åŒ—äº¬\"\n",
    "print(f\"ç”¨æˆ·: {user_input3}\")\n",
    "\n",
    "result3 = graph.invoke(\n",
    "    {\"messages\": [HumanMessage(content=user_input3)]},\n",
    "    config\n",
    ")\n",
    "print(f\"AI: {result3['messages'][-1].content}\")\n",
    "\n",
    "# ç¬¬å››è½®å¯¹è¯ - æµ‹è¯•å®Œæ•´è®°å¿†\n",
    "print(\"\\nç¬¬4è½®å¯¹è¯:\")\n",
    "user_input4 = \"è¯·æ€»ç»“ä¸€ä¸‹æˆ‘çš„ä¸ªäººä¿¡æ¯\"\n",
    "print(f\"ç”¨æˆ·: {user_input4}\")\n",
    "\n",
    "result4 = graph.invoke(\n",
    "    {\"messages\": [HumanMessage(content=user_input4)]},\n",
    "    config\n",
    ")\n",
    "print(f\"AI: {result4['messages'][-1].content}\")\n"
   ],
   "id": "50c42830dc1070ef",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… åŸºç¡€å¯¹è¯å›¾åˆ›å»ºå®Œæˆ\n",
      "==================================================\n",
      "æµ‹è¯•åŸºç¡€å¯¹è¯è®°å¿†\n",
      "==================================================\n",
      "\n",
      "ç¬¬1è½®å¯¹è¯:\n",
      "ç”¨æˆ·: ä½ å¥½ï¼Œæˆ‘å«å¼ ä¸‰ï¼Œæ˜¯ä¸€åç¨‹åºå‘˜\n",
      "AI: ä½ å¥½ï¼Œå¼ ä¸‰ï¼å¾ˆé«˜å…´è®¤è¯†ä½ ã€‚ä½œä¸ºä¸€åç¨‹åºå‘˜ï¼Œä½ è§‰å¾—ç¼–ç¨‹ä¸­æœ€è®©ä½ æ„Ÿåˆ°å…´å¥‹çš„æ˜¯ä»€ä¹ˆï¼Ÿ\n",
      "\n",
      "ç¬¬2è½®å¯¹è¯:\n",
      "ç”¨æˆ·: ä½ è¿˜è®°å¾—æˆ‘çš„åå­—å’ŒèŒä¸šå—ï¼Ÿ\n",
      "AI: å½“ç„¶è®°å¾—ã€‚ä½ å«å¼ ä¸‰ï¼Œæ˜¯ä¸€åç¨‹åºå‘˜ã€‚æˆ‘ä»¬ä¹‹å‰èŠè¿‡ä½ åœ¨ç¼–ç¨‹æ–¹é¢çš„å…´è¶£ç‚¹æˆ–æ˜¯é‡åˆ°çš„æŒ‘æˆ˜ã€‚æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ\n",
      "\n",
      "ç¬¬3è½®å¯¹è¯:\n",
      "ç”¨æˆ·: æˆ‘ä»Šå¹´30å²ï¼Œä½åœ¨åŒ—äº¬\n",
      "AI: ä½ å¥½ï¼Œå¼ ä¸‰ï¼å¾ˆé«˜å…´çŸ¥é“ä½ è¿˜è¿™ä¹ˆå¹´è½»å°±ä»äº‹ç¼–ç¨‹å·¥ä½œäº†ã€‚åŒ—äº¬æ˜¯ä¸€ä¸ªå……æ»¡æ´»åŠ›å’ŒæŠ€æœ¯åˆ›æ–°çš„åŸå¸‚ï¼Œä½ åœ¨é‚£é‡Œç”Ÿæ´»å’Œå·¥ä½œæ„Ÿè§‰å¦‚ä½•å‘¢ï¼Ÿ\n",
      "\n",
      "é™¤æ­¤ä¹‹å¤–ï¼Œè¿˜æœ‰å…¶ä»–æ–¹é¢æ˜¯ä½ æƒ³èŠçš„å—ï¼Ÿæˆ–è€…ä½ æ˜¯å¦éœ€è¦ä¸€äº›å…³äºç¼–ç¨‹ã€æŠ€æœ¯å‘å±•æˆ–èŒä¸šå‘å±•çš„å»ºè®®å’Œä¿¡æ¯ï¼Ÿ\n",
      "\n",
      "ç¬¬4è½®å¯¹è¯:\n",
      "ç”¨æˆ·: è¯·æ€»ç»“ä¸€ä¸‹æˆ‘çš„ä¸ªäººä¿¡æ¯\n",
      "AI: å¥½çš„ï¼Œå¼ ä¸‰ã€‚æ ¹æ®æˆ‘ä»¬ä¹‹å‰çš„å¯¹è¯ï¼Œä½ å¯ä»¥è¿™æ ·ç®€è¦åœ°æ€»ç»“ä½ çš„ä¸ªäººä¿¡æ¯ï¼š\n",
      "\n",
      "- **å§“å**ï¼šå¼ ä¸‰  \n",
      "- **å¹´é¾„**ï¼š30å²  \n",
      "- **å±…ä½åŸå¸‚**ï¼šåŒ—äº¬  \n",
      "- **èŒä¸š**ï¼šç¨‹åºå‘˜  \n",
      "\n",
      "å¦‚æœä½ æœ‰ä»»ä½•å…·ä½“çš„é—®é¢˜æˆ–éœ€è¦è¿›ä¸€æ­¥è®¨è®ºçš„æ–¹é¢ï¼Œè¯·å‘Šè¯‰æˆ‘ï¼\n"
     ]
    }
   ],
   "execution_count": 3
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
